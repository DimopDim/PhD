{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6671463d-f9c0-4542-b28c-eec0dfb36e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, cohen_kappa_score, matthews_corrcoef, roc_curve, roc_auc_score, auc, precision_recall_curve, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a182eba9-001e-43e2-b928-7bdd96cf667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the stroke_diagnosis.csv file\n",
    "df = pd.read_csv(\"CSV\\imports\\o05_30_percent_filled_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de925e7b-1cdb-43d0-9eb4-b5d91aec3682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder hospital_expire_flag column\n",
    "column_order = list(df.columns)\n",
    "column_order.remove('hospital_expire_flag')  # Remove 'flag' from the original position\n",
    "column_order.append('hospital_expire_flag')  # Add 'flag' to the end\n",
    "\n",
    "# Reindex the DataFrame\n",
    "df = df.reindex(columns=column_order)\n",
    "\n",
    "# Filter icu stay less than 10 days\n",
    "df = df[df['los'] < 10]\n",
    "\n",
    "# Filter Time Zone\n",
    "#df = df[df['Time_Zone'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b47b5051-b8fb-4778-9cc2-a5ecbe315310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimop\\AppData\\Local\\Temp\\ipykernel_5708\\2253970844.py:29: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_df = pd.concat([train_df, subject_data])\n",
      "C:\\Users\\dimop\\AppData\\Local\\Temp\\ipykernel_5708\\2253970844.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  test_df = pd.concat([test_df, subject_data])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Separate automatic training - test set\n",
    "keeping patients independent between sets\n",
    "\"\"\"\n",
    "\n",
    "# Set training percentage. The difference goes to test set\n",
    "training_percentage = 0.7\n",
    "\n",
    "# It's already sorted. Just for precaution. Sort by 'subject_id' and 'Time_Zone')\n",
    "df = df.sort_values(by=['subject_id', 'Time_Zone'])\n",
    "\n",
    "# Calculate the total number of unique subject IDs\n",
    "unique_subject_ids = df['subject_id'].nunique()\n",
    "\n",
    "# Calculate the number of unique subject IDs to include in the training set\n",
    "train_subject_ids_count = int(training_percentage * unique_subject_ids)\n",
    "\n",
    "# Initialize variables to track the number of subject IDs included in the training set\n",
    "subject_ids_in_training = 0\n",
    "\n",
    "# Initialize empty DataFrames for the training and test sets\n",
    "train_df = pd.DataFrame(columns=df.columns)\n",
    "test_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "# Iterate through the sorted DataFrame\n",
    "for subject_id, subject_data in df.groupby('subject_id'):\n",
    "    if subject_ids_in_training < train_subject_ids_count:\n",
    "        # Add this subject's data to the training set\n",
    "        train_df = pd.concat([train_df, subject_data])\n",
    "        subject_ids_in_training += 1\n",
    "    else:\n",
    "        # Add this subject's data to the test set\n",
    "        test_df = pd.concat([test_df, subject_data])\n",
    "\n",
    "# Reset the index of the resulting DataFrames\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8fca156-5fb9-44ab-a73a-49388f4605fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prepaire the training and test set\n",
    "in encoding level and set labels\n",
    "\"\"\"\n",
    "\n",
    "# Concatenate train_df and test_df for consistent encoding of categorical variables\n",
    "combined_df = pd.concat([train_df, test_df], axis=0)\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_cols = ['gender', 'language', 'marital_status', 'race']\n",
    "combined_df_encoded = pd.get_dummies(combined_df, columns=categorical_cols)\n",
    "\n",
    "# Convert 'age' column to numeric type\n",
    "combined_df_encoded['age'] = pd.to_numeric(combined_df_encoded['age'], errors='coerce')\n",
    "\n",
    "# Convert 'hospital_expire_flag' column to boolean type\n",
    "combined_df_encoded['hospital_expire_flag'] = combined_df_encoded['hospital_expire_flag'].astype(bool)\n",
    "\n",
    "\n",
    "# Split the dataframe at the original row index (before concatenation)\n",
    "combined_df_encoded_train = combined_df_encoded.iloc[:len(train_df)]\n",
    "combined_df_encoded_test = combined_df_encoded.iloc[len(train_df):]\n",
    "\n",
    "# Split data into features and target variable again\n",
    "X_train = combined_df_encoded_train.drop(['row_count', 'subject_id', 'hadm_id', 'Time_Zone', 'hospital_expire_flag'], axis=1)\n",
    "y_train = combined_df_encoded_train['hospital_expire_flag']\n",
    "X_test = combined_df_encoded_test.drop(['row_count', 'subject_id', 'hadm_id', 'Time_Zone', 'hospital_expire_flag'], axis=1)\n",
    "y_test = combined_df_encoded_test['hospital_expire_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5f0ffa-63b8-40ba-99a9-6ebe315ac963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 110 candidates, totalling 1100 fits\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "XGBoost HyperParameter\n",
    "\"\"\"\n",
    "\n",
    "# We can optimize choosing between 'accuracy', 'precision', 'recall', 'f1'\n",
    "score_metric = 'accuracy'  \n",
    "\n",
    "# Create a grid search object for XGBoost Classifier\n",
    "param_grid = {\n",
    "    'learning_rate': np.arange(0.01, 1.11, 0.10),\n",
    "    'max_depth': np.arange(1, 11, 1),\n",
    "    #'reg_lambda': np.arange(0.0, 10.1, 0.1),\n",
    "    #'reg_alpha': np.arange(0.0, 10.1, 0.1),\n",
    "    #'gamma': np.arange(0.0, 1.1, 0.1)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb.XGBClassifier(objective='binary:logistic'),\n",
    "                           param_grid=param_grid,\n",
    "                           cv=10,  # Number of folds in cross-validation\n",
    "                           scoring=score_metric,\n",
    "                           verbose=1,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test set using the best model\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using appropriate classification metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_best)\n",
    "precision = precision_score(y_test, y_pred_best)\n",
    "recall = recall_score(y_test, y_pred_best)\n",
    "f1 = f1_score(y_test, y_pred_best)\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9135f7e6-4102-467d-a1bc-30304f0a45a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "XGBoost without HyperParameter\n",
    "\"\"\"\n",
    "\n",
    "# Define XGBoost model\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "kappa = cohen_kappa_score(y_test, predictions)\n",
    "mcc = matthews_corrcoef(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nCohen's Kappa:\", kappa)\n",
    "print(\"\\nMatthews Correlation Coefficient (MCC):\", mcc)\n",
    "\n",
    "# Additional evaluation metrics\n",
    "print(\"\\n\",classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e5ee89-6e54-49fa-8e9b-40c5629f7ee6",
   "metadata": {},
   "source": [
    "# Most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f15d96-8eab-4129-9b21-4932c1701469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "feature_importance = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store feature importances along with their corresponding names\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importance})\n",
    "\n",
    "# Sort the DataFrame by feature importance in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the top N most important features\n",
    "top_n = 20  # set features number\n",
    "print(f\"Top {top_n} most important features:\")\n",
    "print(feature_importance_df.head(top_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39eeefd-7ea4-42fc-b890-c191e5253ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities for the positive class\n",
    "y_probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate the false positive rate (fpr), true positive rate (tpr), and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "\n",
    "# Calculate the area under the curve (AUC)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578e5ed1-a513-4a3f-9c3c-8826f86a502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision and recall\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, color='blue', lw=2, label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f28683-3489-4a7c-82e4-12a8794c06a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract subject_id, hadm_id, and Time_Zone from the test data\n",
    "df_classifier = test_df[['subject_id', 'hadm_id', 'Time_Zone', 'hospital_expire_flag']].copy()\n",
    "\n",
    "# Add predictions column\n",
    "df_classifier['prediction(hospital_expire_flag)'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d0d152-ebb8-4310-8759-fdfe10b46f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ID column by concatenating the values of 'subject_id', 'hadm_id'\n",
    "df_classifier['subject_&_hadm'] = df_classifier['subject_id'].astype(str) + df_classifier['hadm_id'].astype(str)\n",
    "\n",
    "# Create column propability of alive (1 for alive 0 for death)\n",
    "df_classifier['Prediction_of_alive'] = df_classifier['prediction(hospital_expire_flag)'].apply(lambda x: 1 if x == 0 else 0)\n",
    "\n",
    "# Create column propability of death 1 for death 0 for alive\n",
    "df_classifier['Prediction_of_death'] = df_classifier['prediction(hospital_expire_flag)'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "# Replace 0 with 1 and 1 with 0 in the 'hospital_expire_flag' column and rename the column\n",
    "df_classifier['hospital_expire_flag'] = df_classifier['hospital_expire_flag'].replace({0: 1, 1: 0})\n",
    "df_classifier = df_classifier.rename(columns={'hospital_expire_flag': 'Ground_Truth_Alive'})\n",
    "\n",
    "# Remove the 'prediction(hospital_expire_flag)' column\n",
    "df_classifier = df_classifier.drop(columns=['prediction(hospital_expire_flag)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342f2090-96b6-45bc-b51e-2d82e2785362",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate the probability of Alive and Death\n",
    "\"\"\"\n",
    "\n",
    "# Create a new column 'denominator' that counts for each 'subject_&_hadm'\n",
    "df_classifier['Denominator'] = df_classifier.groupby('subject_&_hadm').cumcount() + 1\n",
    "\n",
    "# Create a new column 'numerator' based on the conditions\n",
    "#df_classifier['Numerator'] = df_classifier.groupby('subject_&_hadm')['Prediction_of_alive'].transform(\n",
    "    #lambda x: x.cumsum() if x.iloc[0] != 0 else x.cumsum() - 1\n",
    "#).replace(-1, 0)\n",
    "\n",
    "\n",
    "\n",
    "# Create the 'Numerator' column\n",
    "df_classifier['Numerator'] = df_classifier.groupby('subject_&_hadm')['Prediction_of_alive'].transform(\n",
    "    lambda x: x.cumsum()\n",
    ")\n",
    "\n",
    "# Fill NaN values with 0\n",
    "df_classifier['Numerator'] = df_classifier['Numerator'].fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Probability of Alive\n",
    "df_classifier['Probability_of_Alive'] = df_classifier['Numerator'] / df_classifier['Denominator']\n",
    "\n",
    "# Probability of Death\n",
    "df_classifier['Probability_of_Death'] = 1 - df_classifier['Probability_of_Alive']\n",
    "\n",
    "\n",
    "# Repositioning the columns in the DataFrame\n",
    "columns_to_move = ['subject_&_hadm', 'subject_id', 'hadm_id', 'Time_Zone',\n",
    "                   'Prediction_of_alive', 'Prediction_of_death',\n",
    "                   'Ground_Truth_Alive', 'Numerator','Denominator',\n",
    "                   'Probability_of_Alive', 'Probability_of_Death']\n",
    "df_classifier = df_classifier[columns_to_move + [col for col in df_classifier.columns if col not in columns_to_move]]\n",
    "\n",
    "\n",
    "# Export to csv\n",
    "#df_classifier.to_csv(export_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbc95f4-36a3-4c63-889f-68413b898c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "algorithm_label = 'Mimic IV - XGBoost'\n",
    "xlabel = 'False Positive Rate'\n",
    "ylabel = 'True Positive Rate'\n",
    "\n",
    "\"\"\"\n",
    "Assign to variables the values of the first\n",
    "3, 6, 12 and 24 hour\n",
    "No1 = first 3 hours\n",
    "No2 = first 6 hours\n",
    "...\n",
    "No16 = first 48 hours\n",
    "\"\"\"\n",
    "hour1 = df_classifier.loc[df_classifier['Denominator'] == 1] # first 3 hours\n",
    "hour2 = df_classifier.loc[df_classifier['Denominator'] == 2] # first 6 hours\n",
    "hour3 = df_classifier.loc[df_classifier['Denominator'] == 4] # first 12 hours\n",
    "hour4 = df_classifier.loc[df_classifier['Denominator'] == 8] #first 24 hours\n",
    "\n",
    "\"\"\"\n",
    "Assign to variables values for every hour from\n",
    "the column Ground Truth Alive and convert from\n",
    "dataframe to list.\n",
    "\"\"\"\n",
    "\n",
    "ground_truth_alive1 = hour1[\"Ground_Truth_Alive\"].tolist()\n",
    "ground_truth_alive2 = hour2[\"Ground_Truth_Alive\"].tolist()\n",
    "ground_truth_alive3 = hour3[\"Ground_Truth_Alive\"].tolist()\n",
    "ground_truth_alive4 = hour4[\"Ground_Truth_Alive\"].tolist()\n",
    "\n",
    "\"\"\"\n",
    "Assign to variables values for every hour from\n",
    "the column Prob - Alive and convert from\n",
    "dataframe to list.\n",
    "\"\"\"\n",
    "\n",
    "prob_alive1 = hour1[\"Probability_of_Alive\"].tolist()\n",
    "prob_alive2 = hour2[\"Probability_of_Alive\"].tolist()\n",
    "prob_alive3 = hour3[\"Probability_of_Alive\"].tolist()\n",
    "prob_alive4 = hour4[\"Probability_of_Alive\"].tolist()\n",
    "\n",
    "\"\"\"\n",
    "Assign to variables values for every hour from\n",
    "the column Prob - Dead and convert from\n",
    "dataframe to list.\n",
    "\"\"\"\n",
    "\n",
    "prob_dead1 = hour1[\"Probability_of_Death\"].tolist()\n",
    "prob_dead2 = hour2[\"Probability_of_Death\"].tolist()\n",
    "prob_dead3 = hour3[\"Probability_of_Death\"].tolist()\n",
    "prob_dead4 = hour4[\"Probability_of_Death\"].tolist()\n",
    "\n",
    "\"\"\"\n",
    "To create the Ground Truth Dead per day, I subtract from\n",
    "the ground_truth_alive of each hour the 1. After the subtraction\n",
    "I use the abs in order to get the absolute value of it.\n",
    "So I have the prices without a hitch.\n",
    "With this process the values of Ground Truth Alive and Ground\n",
    "Truth Dead are reversed\n",
    "\"\"\"\n",
    "# Ground Truth Dead per hour\n",
    "# 1st hour (first 3hours)\n",
    "ground_truth_dead1=abs(np.subtract(ground_truth_alive1, 1))\n",
    "\n",
    "# 2nd hour (first 6hours)\n",
    "ground_truth_dead2=abs(np.subtract(ground_truth_alive2, 1))\n",
    "\n",
    "# 3rd hour (first 12hours)\n",
    "ground_truth_dead3=abs(np.subtract(ground_truth_alive3, 1))\n",
    "\n",
    "# 4th hour (first 24hours)\n",
    "ground_truth_dead4=abs(np.subtract(ground_truth_alive4, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48615e78-3a98-492c-a6d9-af68cb9a7109",
   "metadata": {},
   "source": [
    "# Alive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de55767-7ce1-4c36-bfa0-e66d85b4f9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"First 3 hours\"\"\"\n",
    "\n",
    "# Your existing code for ROC curve\n",
    "print(\"AUC = \", roc_auc_score(ground_truth_alive1, prob_alive1))\n",
    "fpr1, tpr1, thresholds1 = roc_curve(ground_truth_alive1, prob_alive1)\n",
    "pyplot.plot(fpr1, tpr1, linestyle='--', label='First 3 Hours')\n",
    "\n",
    "# Scatter plot for thresholds\n",
    "for i, threshold in enumerate(thresholds1):\n",
    "    pyplot.scatter(fpr1[i], tpr1[i], marker='o', color='black', label=f'Threshold = {threshold:.2f}')\n",
    "\n",
    "pyplot.xlabel(xlabel)\n",
    "pyplot.ylabel(ylabel)\n",
    "pyplot.legend()\n",
    "pyplot.grid(True)\n",
    "pyplot.title(algorithm_label + \" (Alive)\")\n",
    "\n",
    "print(\"Thresholds          \", thresholds1)\n",
    "print(\"False Possitive Rate\", fpr1)\n",
    "print(\"True Possitive Rate\", tpr1)\n",
    "\n",
    "# Show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410f896c-7ee6-4b26-9723-7a4fc01345f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"First 6 hours\"\"\"\n",
    "\n",
    "print(\"AUC = \", roc_auc_score(ground_truth_alive2, prob_alive2))\n",
    "fpr2, tpr2, thresholds2 = roc_curve(ground_truth_alive2, prob_alive2)\n",
    "pyplot.plot(fpr2, tpr2, linestyle='--', label='First 6 Hours')\n",
    "\n",
    "# Scatter plot for thresholds\n",
    "for i, threshold in enumerate(thresholds2):\n",
    "    pyplot.scatter(fpr2[i], tpr2[i], marker='o', color='black', label=f'Threshold = {threshold:.2f}')\n",
    "\n",
    "pyplot.xlabel(xlabel)\n",
    "pyplot.ylabel(ylabel)\n",
    "pyplot.legend()\n",
    "pyplot.grid(True)\n",
    "pyplot.title(algorithm_label + \" (Alive)\")\n",
    "\n",
    "print(\"Thresholds          \", thresholds2)\n",
    "print(\"False Possitive Rate\", fpr2)\n",
    "print(\"True Possitive Rate\", tpr2)\n",
    "\n",
    "# Show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f70ea68-f2b9-497f-aec6-7f72db115c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"First 12 hours\"\"\"\n",
    "\n",
    "print(\"AUC = \", roc_auc_score(ground_truth_alive3, prob_alive3))\n",
    "fpr3, tpr3, thresholds3 = roc_curve(ground_truth_alive3, prob_alive3)\n",
    "pyplot.plot(fpr3, tpr3, linestyle='--', label='First 12 Hours')\n",
    "\n",
    "# Scatter plot for thresholds\n",
    "for i, threshold in enumerate(thresholds3):\n",
    "    pyplot.scatter(fpr3[i], tpr3[i], marker='o', color='black', label=f'Threshold = {threshold:.2f}')\n",
    "\n",
    "pyplot.xlabel(xlabel)\n",
    "pyplot.ylabel(ylabel)\n",
    "pyplot.legend()\n",
    "pyplot.grid(True)\n",
    "pyplot.title(algorithm_label + \" (Alive)\")\n",
    "\n",
    "print(\"Thresholds          \", thresholds3)\n",
    "print(\"False Possitive Rate\", fpr3)\n",
    "print(\"True Possitive Rate\", tpr3)\n",
    "\n",
    "# Show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c85b25-96f2-471c-a5e0-136ff5154e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"First 24 hours\"\"\"\n",
    "\n",
    "print(\"AUC = \", roc_auc_score(ground_truth_alive4, prob_alive4))\n",
    "fpr4, tpr4, thresholds4 = roc_curve(ground_truth_alive4, prob_alive4)\n",
    "pyplot.plot(fpr4, tpr4, linestyle='--', label='First 24 Hours')\n",
    "\n",
    "# Scatter plot for thresholds\n",
    "for i, threshold in enumerate(thresholds4):\n",
    "    pyplot.scatter(fpr4[i], tpr4[i], marker='o', color='black', label=f'Threshold = {threshold:.2f}')\n",
    "\n",
    "pyplot.xlabel(xlabel)\n",
    "pyplot.ylabel(ylabel)\n",
    "pyplot.legend()\n",
    "pyplot.grid(True)\n",
    "pyplot.title(algorithm_label + \" (Alive)\")\n",
    "\n",
    "print(\"Thresholds          \", thresholds4)\n",
    "print(\"False Possitive Rate\", fpr4)\n",
    "print(\"True Possitive Rate\", tpr4)\n",
    "\n",
    "# Show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68bcfa-67e2-448c-8866-104c36a0ab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate AUC scores\n",
    "auc_3_hours = roc_auc_score(ground_truth_alive1, prob_alive1)\n",
    "auc_6_hours = roc_auc_score(ground_truth_alive2, prob_alive2)\n",
    "auc_12_hours = roc_auc_score(ground_truth_alive3, prob_alive3)\n",
    "auc_24_hours = roc_auc_score(ground_truth_alive4, prob_alive4)\n",
    "\n",
    "# Create a plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot ROC curves with different line styles and colors\n",
    "plt.plot(fpr1, tpr1, linestyle='-', color='b', label=f'First 3 Hours (AUC = {auc_3_hours:.3f})')\n",
    "plt.plot(fpr2, tpr2, linestyle='--', color='g', label=f'First 6 Hours (AUC = {auc_6_hours:.3f})')\n",
    "plt.plot(fpr3, tpr3, linestyle='-.', color='r', label=f'First 12 Hours (AUC = {auc_12_hours:.3f})')\n",
    "plt.plot(fpr4, tpr4, linestyle=':', color='m', label=f'First 24 Hours (AUC = {auc_24_hours:.3f})')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('False Positive Rate', fontsize=20)\n",
    "plt.ylabel('True Positive Rate', fontsize=20)\n",
    "plt.legend(fontsize=12, loc='best')\n",
    "plt.grid(linestyle='--', alpha=0.7)\n",
    "plt.title(algorithm_label + \" (Alive) for Different Time Intervals\", fontsize=25)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a24119-4c9e-4a85-86fa-43111e0b22ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
