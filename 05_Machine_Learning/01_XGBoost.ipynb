{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6671463d-f9c0-4542-b28c-eec0dfb36e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_error, mean_squared_log_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a182eba9-001e-43e2-b928-7bdd96cf667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the stroke_diagnosis.csv file\n",
    "df = pd.read_csv(\"CSV\\imports\\o05_30_percent_filled_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de925e7b-1cdb-43d0-9eb4-b5d91aec3682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter icu stay less than 10 days\n",
    "df = df[df['los'] < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e07bf1b7-547d-44bf-946e-d8afadc7be5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_count</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>Time_Zone</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>language</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>race</th>\n",
       "      <th>Base Excess</th>\n",
       "      <th>...</th>\n",
       "      <th>CK-MB</th>\n",
       "      <th>Glucose.2</th>\n",
       "      <th>Potassium Whole Blood</th>\n",
       "      <th>Glucose (whole blood)</th>\n",
       "      <th>Potassium (whole blood)</th>\n",
       "      <th>Creatine Kinase MB Isoenzyme</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "      <th>los</th>\n",
       "      <th>GCS</th>\n",
       "      <th>Braden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8.357373</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8.357373</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8.357373</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8.357373</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8.357373</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55787</th>\n",
       "      <td>55788</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>12</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.937847</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55788</th>\n",
       "      <td>55789</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>13</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.937847</td>\n",
       "      <td>8.111111</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55789</th>\n",
       "      <td>55790</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>14</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.937847</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55790</th>\n",
       "      <td>55791</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>15</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.937847</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55791</th>\n",
       "      <td>55792</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.937847</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48992 rows Ã— 232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_count  subject_id   hadm_id  Time_Zone gender  age language  \\\n",
       "0              1    10004733  27411876          1      M   51  ENGLISH   \n",
       "1              2    10004733  27411876          2      M   51  ENGLISH   \n",
       "2              3    10004733  27411876          3      M   51  ENGLISH   \n",
       "3              4    10004733  27411876          4      M   51  ENGLISH   \n",
       "4              5    10004733  27411876          5      M   51  ENGLISH   \n",
       "...          ...         ...       ...        ...    ...  ...      ...   \n",
       "55787      55788    19999987  23865745         12      F   57  ENGLISH   \n",
       "55788      55789    19999987  23865745         13      F   57  ENGLISH   \n",
       "55789      55790    19999987  23865745         14      F   57  ENGLISH   \n",
       "55790      55791    19999987  23865745         15      F   57  ENGLISH   \n",
       "55791      55792    19999987  23865745         16      F   57  ENGLISH   \n",
       "\n",
       "      marital_status     race  Base Excess  ...  CK-MB  Glucose.2  \\\n",
       "0             SINGLE  UNKNOWN          0.0  ...    NaN        NaN   \n",
       "1             SINGLE  UNKNOWN          0.0  ...    NaN        NaN   \n",
       "2             SINGLE  UNKNOWN          0.0  ...    NaN        NaN   \n",
       "3             SINGLE  UNKNOWN          0.0  ...    NaN        NaN   \n",
       "4             SINGLE  UNKNOWN          0.0  ...    NaN        NaN   \n",
       "...              ...      ...          ...  ...    ...        ...   \n",
       "55787            NaN  UNKNOWN          1.0  ...   43.0        NaN   \n",
       "55788            NaN  UNKNOWN          1.0  ...   45.5        NaN   \n",
       "55789            NaN  UNKNOWN          1.0  ...   43.0        NaN   \n",
       "55790            NaN  UNKNOWN          1.0  ...   44.0        NaN   \n",
       "55791            NaN  UNKNOWN          1.0  ...   43.0        NaN   \n",
       "\n",
       "       Potassium Whole Blood  Glucose (whole blood)  Potassium (whole blood)  \\\n",
       "0                        NaN                    NaN                      NaN   \n",
       "1                        NaN                    NaN                      NaN   \n",
       "2                        NaN                    NaN                      NaN   \n",
       "3                        NaN                    NaN                      NaN   \n",
       "4                        NaN                    NaN                      NaN   \n",
       "...                      ...                    ...                      ...   \n",
       "55787                    NaN                    NaN                      NaN   \n",
       "55788                    NaN                    NaN                      NaN   \n",
       "55789                    NaN                    NaN                      NaN   \n",
       "55790                    NaN                    NaN                      NaN   \n",
       "55791                    NaN                    NaN                      NaN   \n",
       "\n",
       "       Creatine Kinase MB Isoenzyme  hospital_expire_flag       los       GCS  \\\n",
       "0                               NaN                     0  8.357373  8.000000   \n",
       "1                               NaN                     0  8.357373  8.500000   \n",
       "2                               NaN                     0  8.357373  8.000000   \n",
       "3                               NaN                     0  8.357373  8.333333   \n",
       "4                               NaN                     0  8.357373  8.333333   \n",
       "...                             ...                   ...       ...       ...   \n",
       "55787                          43.0                     0  1.937847  8.250000   \n",
       "55788                          45.5                     0  1.937847  8.111111   \n",
       "55789                          43.0                     0  1.937847  8.250000   \n",
       "55790                          44.0                     0  1.937847  7.000000   \n",
       "55791                          43.0                     0  1.937847  8.250000   \n",
       "\n",
       "       Braden  \n",
       "0        11.0  \n",
       "1        11.0  \n",
       "2        11.0  \n",
       "3        11.0  \n",
       "4        11.0  \n",
       "...       ...  \n",
       "55787    12.8  \n",
       "55788    12.5  \n",
       "55789    12.8  \n",
       "55790    13.0  \n",
       "55791    12.8  \n",
       "\n",
       "[48992 rows x 232 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b47b5051-b8fb-4778-9cc2-a5ecbe315310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dimopoulos\\AppData\\Local\\Temp\\ipykernel_4868\\121497339.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_df = pd.concat([train_df, subject_data])\n",
      "C:\\Users\\Dimopoulos\\AppData\\Local\\Temp\\ipykernel_4868\\121497339.py:28: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  test_df = pd.concat([test_df, subject_data])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The last row of the training set is -> 39008'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set training percentage. The difference goes to test set\n",
    "training_percentage = 0.7\n",
    "\n",
    "# It's already sorted. Just for precaution. Sort by 'subject_id' and 'Time_Zone')\n",
    "df = df.sort_values(by=['subject_id', 'Time_Zone'])\n",
    "\n",
    "# Calculate the total number of unique subject IDs\n",
    "unique_subject_ids = df['subject_id'].nunique()\n",
    "\n",
    "# Calculate the number of unique subject IDs to include in the training set\n",
    "train_subject_ids_count = int(training_percentage * unique_subject_ids)\n",
    "\n",
    "# Initialize variables to track the number of subject IDs included in the training set\n",
    "subject_ids_in_training = 0\n",
    "\n",
    "# Initialize empty DataFrames for the training and test sets\n",
    "train_df = pd.DataFrame(columns=df.columns)\n",
    "test_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "# Iterate through the sorted DataFrame\n",
    "for subject_id, subject_data in df.groupby('subject_id'):\n",
    "    if subject_ids_in_training < train_subject_ids_count:\n",
    "        # Add this subject's data to the training set\n",
    "        train_df = pd.concat([train_df, subject_data])\n",
    "        subject_ids_in_training += 1\n",
    "    else:\n",
    "        # Add this subject's data to the test set\n",
    "        test_df = pd.concat([test_df, subject_data])\n",
    "\n",
    "# Reset the index of the resulting DataFrames\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "# I'm going to use those numbers as the split point in rapidminer filter operator\n",
    "display(\"The last row of the training set is -> \" + str(train_df.tail(1)[\"row_count\"].values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6eea57c-3f42-476c-ae67-10888d3ebcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate train_df and test_df for consistent encoding of categorical variables\n",
    "combined_df = pd.concat([train_df, test_df], axis=0)\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_cols = ['gender', 'language', 'marital_status', 'race']\n",
    "combined_df_encoded = pd.get_dummies(combined_df, columns=categorical_cols)\n",
    "\n",
    "# Convert 'age' column to numeric type\n",
    "combined_df_encoded['age'] = pd.to_numeric(combined_df_encoded['age'], errors='coerce')\n",
    "\n",
    "# Convert 'hospital_expire_flag' column to boolean type\n",
    "combined_df_encoded['hospital_expire_flag'] = combined_df_encoded['hospital_expire_flag'].astype(bool)\n",
    "\n",
    "\n",
    "# Split the dataframe at the original row index (before concatenation)\n",
    "combined_df_encoded_train = combined_df_encoded.iloc[:len(train_df)]\n",
    "combined_df_encoded_test = combined_df_encoded.iloc[len(train_df):]\n",
    "\n",
    "# Split data into features and target variable again\n",
    "X_train = combined_df_encoded_train.drop(['row_count', 'subject_id', 'hadm_id', 'Time_Zone', 'los'], axis=1)\n",
    "y_train = combined_df_encoded_train['los']\n",
    "X_test = combined_df_encoded_test.drop(['row_count', 'subject_id', 'hadm_id', 'Time_Zone', 'los'], axis=1)\n",
    "y_test = combined_df_encoded_test['los']\n",
    "\n",
    "# Train XGBoost model\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "#model = xgb.XGBRegressor(objective='reg:squarederror', learning_rate=0.069)\n",
    "#model = xgb.XGBRegressor(objective='reg:squarederror', learning_rate=0.069, max_depth=6)\n",
    "#model = xgb.XGBRegressor(objective='reg:squarederror', learning_rate=0.069, max_depth=6, reg_lambda=4.7)\n",
    "#model = xgb.XGBRegressor(objective='reg:squarederror', learning_rate=0.069, max_depth=6, reg_lambda=4.7, reg_alpha=0.0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75d1edc9-0621-4568-89e6-b0121161b1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error (MSE): 2.7111381547239803\n",
      "Mean Absolute Error (MAE): 1.177213571688383\n",
      "Root Mean Squared Error (RMSE): 1.6465534169057439\n",
      "R-squared (R2): 53.00 %\n",
      "Mean Squared Logarithmic Error cannot be calculated because targets contain negative values.\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "print(\"Mean Square Error (MSE):\", mean_squared_error(y_test, y_pred))\n",
    "print(\"Mean Absolute Error (MAE):\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error (RMSE):\", mean_squared_error(y_test, y_pred, squared=False))\n",
    "r2 = r2_score(y_test, y_pred) * 100\n",
    "print(f\"R-squared (R2): {r2:.2f} %\")\n",
    "\n",
    "# MSLE calculation must not have negative values in y_test and y_pred\n",
    "try:\n",
    "    msle = mean_squared_log_error(y_test, y_pred)\n",
    "    print(\"Mean Squared Logarithmic Error (MSLE):\", msle)\n",
    "except ValueError:\n",
    "    print(\"Mean Squared Logarithmic Error cannot be calculated because targets contain negative values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e5ee89-6e54-49fa-8e9b-40c5629f7ee6",
   "metadata": {},
   "source": [
    "# Most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74f15d96-8eab-4129-9b21-4932c1701469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 most important features:\n",
      "                                            Feature  Importance\n",
      "92                                    Spont Vt (mL)    0.116994\n",
      "45                                             pH.1    0.050216\n",
      "202      Arterial Blood Pressure Alarm - Low (mmHg)    0.045596\n",
      "153                   High risk (>51) interventions    0.034696\n",
      "121                                        Eye Care    0.033455\n",
      "138                              ICU Consent Signed    0.030525\n",
      "9                                         Albumin.1    0.025447\n",
      "98                  Tidal Volume (spontaneous) (mL)    0.024918\n",
      "72                                    PH (dipstick)    0.023688\n",
      "208                    Arterial Line Zero/Calibrate    0.020562\n",
      "5                                                pH    0.017388\n",
      "183                             Pain Level Response    0.017156\n",
      "198                    20 Gauge placed in the field    0.016680\n",
      "46                                 Specific Gravity    0.014439\n",
      "70                                              ALT    0.014414\n",
      "206                                    Free Calcium    0.013929\n",
      "94                                Daily Weight (kg)    0.013824\n",
      "258                                      race_WHITE    0.013270\n",
      "251  race_NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER    0.011804\n",
      "142                                   Height (Inch)    0.011737\n"
     ]
    }
   ],
   "source": [
    "# Get feature importances\n",
    "feature_importance = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store feature importances along with their corresponding names\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importance})\n",
    "\n",
    "# Sort the DataFrame by feature importance in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the top N most important features\n",
    "top_n = 20  # set features number\n",
    "print(f\"Top {top_n} most important features:\")\n",
    "print(feature_importance_df.head(top_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b86e0f0-487e-4549-a183-11113684f3fb",
   "metadata": {},
   "source": [
    "# Stand Alone Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92c6ff9f-1aa9-4b92-bbb1-8e45e7a92f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 99000 candidates, totalling 495000 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 35\u001b[0m\n\u001b[0;32m     27\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mxgb\u001b[38;5;241m.\u001b[39mXGBRegressor(objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg:squarederror\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     28\u001b[0m                             param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[0;32m     29\u001b[0m                             cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,  \u001b[38;5;66;03m# Number of folds in cross-validation\u001b[39;00m\n\u001b[0;32m     30\u001b[0m                             scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Scoring metric\u001b[39;00m\n\u001b[0;32m     31\u001b[0m                             verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,  \u001b[38;5;66;03m# Controls the verbosity\u001b[39;00m\n\u001b[0;32m     32\u001b[0m                             n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Number of jobs to run in parallel (-1: all processors)\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Search for best hyperparameters\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Best hyperparameters\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 327\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Testing field\n",
    "\"\"\"\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': np.arange(0.01, 1.00, 0.01),  # Learning rate from 0.01 to 0.51 with step 0.01\n",
    "    #'learning_rate': [], # Learning rate set value\n",
    "    #------------------------------------------------\n",
    "    'max_depth': np.arange(1, 11, 1),  # Max depth from 1 to 10 with step 1\n",
    "    #'max_depth': [], # Max depth set value\n",
    "    #------------------------------------------------\n",
    "    'lambda': np.arange(0.0, 10.0, 0.1),  # L2 from 0.0 to 10.0 with step 0.1\n",
    "    #'lambda': [], # L2 set value\n",
    "    #------------------------------------------------\n",
    "    #'alpha': np.arange(0.0, 10.0, 0.1),  # L1 regularization from 0.0 to 10.0 with step 0.1\n",
    "    #'alpha': [], # L1 set value\n",
    "    #------------------------------------------------\n",
    "    #'n_estimators': np.arange(1, 100, 1), # Number of trees from 1 to 100 with step 1\n",
    "    #'n_estimators': [],  # Number of trees\n",
    "    #-------------------------------------------------\n",
    "    #'gamma': np.arange(0.0, 1.0, 0.1), # Minimum loss reduction required to make a further partition on a leaf node\n",
    "    #'gamma': [0, 0.1, 0.2]  # Minimum loss reduction value\n",
    "}\n",
    "\n",
    "# Create a grid search object\n",
    "grid_search = GridSearchCV(estimator=xgb.XGBRegressor(objective='reg:squarederror'),\n",
    "                            param_grid=param_grid,\n",
    "                            cv=5,  # Number of folds in cross-validation\n",
    "                            scoring='neg_mean_squared_error',  # Scoring metric\n",
    "                            verbose=1,  # Controls the verbosity\n",
    "                            n_jobs=-1)  # Number of jobs to run in parallel (-1: all processors)\n",
    "\n",
    "# Search for best hyperparameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test set using the best model\n",
    "y_pred_best_stand_alone = best_model.predict(X_test)\n",
    "\n",
    "# Best model evaluation\n",
    "print(\"Mean Square Error (MSE):\", mean_squared_error(y_test, y_pred_best_stand_alone))\n",
    "print(\"Mean Absolute Error (MAE):\", mean_absolute_error(y_test, y_pred_best_stand_alone))\n",
    "print(\"Root Mean Squared Error (RMSE):\", mean_squared_error(y_test, y_pred_best_stand_alone, squared=False))\n",
    "print(\"R-squared (R2):\", r2_score(y_test, y_pred_best_stand_alone))\n",
    "\n",
    "# MSLE calculation must not have negative values in y_test and y_pred\n",
    "try:\n",
    "    msle = mean_squared_log_error(y_test, y_pred_best_stand_alone)\n",
    "    print(\"Mean Squared Logarithmic Error (MSLE):\", msle)\n",
    "except ValueError:\n",
    "    print(\"Mean Squared Logarithmic Error cannot be calculated because targets contain negative values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e309165c-5a06-40e8-a91d-a1c0da0f3cd5",
   "metadata": {},
   "source": [
    "# Set all HyperParameters & Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaf1181-5225-41a0-8660-c739b744059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val=10,  # Number of folds in cross-validation\n",
    "score_metric='neg_mean_squared_error',  # Scoring metric\n",
    "verbosity=1,  # Controls the verbosity\n",
    "processors_jobs=-1)  # Number of jobs to run in parallel (-1: all processors)\n",
    "\n",
    "# Learning Rate HyperParameter\n",
    "param_grid_learning_rate = {\n",
    "    'learning_rate': np.arange(0.01, 1.01, 0.01),  # Learning rate from 0.01 to 1.00 with step 0.01\n",
    "}\n",
    "\n",
    "# Create a grid search object for learning rate\n",
    "grid_search_learning_rate = GridSearchCV(estimator=xgb.XGBRegressor(objective='reg:squarederror'),\n",
    "                            param_grid=param_grid_learning_rate,\n",
    "                            cv=cross_val,  # Number of folds in cross-validation\n",
    "                            scoring=score_metric,  # Scoring metric\n",
    "                            verbose=verbosity,  # Controls the verbosity\n",
    "                            n_jobs=processors_jobs)  # Number of jobs to run in parallel (-1: all processors)\n",
    "\n",
    "# Search best learning rate\n",
    "grid_search_learning_rate.fit(X_train, y_train)\n",
    "\n",
    "# Best learning rate\n",
    "best_learning_rate = grid_search_learning_rate.best_params_['learning_rate']\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Max Depth HyperParameter\n",
    "param_grid_max_depth = {\n",
    "    'max_depth': np.arange(1, 11, 1),  # Max depth from 1 to 10 with step 1\n",
    "}\n",
    "\n",
    "# Create a grid search object for max depth\n",
    "grid_search_max_depth = GridSearchCV(estimator=xgb.XGBRegressor(objective='reg:squarederror', learning_rate=best_learning_rate),\n",
    "                            param_grid=param_grid_max_depth,\n",
    "                            cv=cross_val,  # Number of folds in cross-validation\n",
    "                            scoring=score_metric,  # Scoring metric\n",
    "                            verbose=verbosity,  # Controls the verbosity\n",
    "                            n_jobs=processors_jobs)  # Number of jobs to run in parallel (-1: all processors)\n",
    "\n",
    "# Search best max depth\n",
    "grid_search_max_depth.fit(X_train, y_train)\n",
    "\n",
    "# Best max depth\n",
    "best_max_depth = grid_search_max_depth.best_params_['max_depth']\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# L2 HyperParameter\n",
    "param_grid_lambda = {\n",
    "    'reg_lambda': np.arange(0.0, 10.1, 0.1),  # Lambda (L2 regularization) from 0.0 to 10.0 with step 0.1\n",
    "}\n",
    "\n",
    "# Create a grid search object for lambda\n",
    "grid_search_lambda = GridSearchCV(estimator=xgb.XGBRegressor(objective='reg:squarederror', learning_rate=best_learning_rate, max_depth=best_max_depth),\n",
    "                            param_grid=param_grid_lambda,\n",
    "                            cv=cross_val,  # Number of folds in cross-validation\n",
    "                            scoring=score_metric,  # Scoring metric\n",
    "                            verbose=verbosity,  # Controls the verbosity\n",
    "                            n_jobs=processors_jobs)  # Number of jobs to run in parallel (-1: all processors)\n",
    "\n",
    "# Search for best L2\n",
    "grid_search_lambda.fit(X_train, y_train)\n",
    "\n",
    "# Best L2\n",
    "best_lambda = grid_search_lambda.best_params_['reg_lambda']\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# L1 HyperParameter\n",
    "param_grid_alpha = {\n",
    "    'reg_alpha': np.arange(0.0, 10.1, 0.1),  # Alpha (L1 regularization) from 0.0 to 10.0 with step 0.1\n",
    "}\n",
    "\n",
    "# Create a grid search object for alpha\n",
    "grid_search_alpha = GridSearchCV(estimator=xgb.XGBRegressor(objective='reg:squarederror', learning_rate=best_learning_rate, max_depth=best_max_depth, reg_lambda=best_lambda),\n",
    "                            param_grid=param_grid_alpha,\n",
    "                            cv=cross_val,  # Number of folds in cross-validation\n",
    "                            scoring=score_metric,  # Scoring metric\n",
    "                            verbose=verbosity,  # Controls the verbosity\n",
    "                            n_jobs=processors_jobs)  # Number of jobs to run in parallel (-1: all processors)\n",
    "\n",
    "# Search for best L1\n",
    "grid_search_alpha.fit(X_train, y_train)\n",
    "\n",
    "# Best L1\n",
    "best_alpha = grid_search_alpha.best_params_['reg_alpha']\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Gamma HyperParameter\n",
    "param_grid_gamma = {\n",
    "    'gamma': np.arange(0.0, 1.1, 0.1),  # Gamma from 0.0 to 1.0 with step 0.1\n",
    "}\n",
    "\n",
    "# Create a grid search object for gamma\n",
    "grid_search_gamma = GridSearchCV(estimator=xgb.XGBRegressor(objective='reg:squarederror', learning_rate=best_learning_rate, max_depth=best_max_depth, reg_lambda=best_lambda, alpha=best_alpha),\n",
    "                            param_grid=param_grid_gamma,\n",
    "                            cv=cross_val,  # Number of folds in cross-validation\n",
    "                            scoring=score_metric,  # Scoring metric\n",
    "                            verbose=verbosity,  # Controls the verbosity\n",
    "                            n_jobs=processors_jobs)  # Number of jobs to run in parallel (-1: all processors)\n",
    "\n",
    "# Search for best gamma\n",
    "grid_search_gamma.fit(X_train, y_train)\n",
    "\n",
    "# Best gamma\n",
    "best_gamma = grid_search_gamma.best_params_['gamma']\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Train the model using the best hyperparameter values\n",
    "best_model = xgb.XGBRegressor(objective='reg:squarederror', learning_rate=best_learning_rate, max_depth=best_max_depth, reg_lambda=best_lambda, reg_alpha=best_alpha, gamma=best_gamma)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set using the best model\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Best model evaluation\n",
    "print(\"Mean Square Error (MSE):\", mean_squared_error(y_test, y_pred_best))\n",
    "print(\"Mean Absolute Error (MAE):\", mean_absolute_error(y_test, y_pred_best))\n",
    "print(\"Root Mean Squared Error (RMSE):\", mean_squared_error(y_test, y_pred_best, squared=False))\n",
    "r2 = r2_score(y_test, y_pred_best) * 100\n",
    "print(f\"R-squared (R2): {r2:.2f} %\")\n",
    "\n",
    "# MSLE calculation must not have negative values in y_test and y_pred\n",
    "try:\n",
    "    msle = mean_squared_log_error(y_test, y_pred_best)\n",
    "    print(\"Mean Squared Logarithmic Error (MSLE):\", msle)\n",
    "except ValueError:\n",
    "    print(\"Mean Squared Logarithmic Error cannot be calculated because targets contain negative values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4d59b2-6802-4712-9319-159868527681",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best LR\", best_learning_rate)\n",
    "print(\"Best Max Depth\", best_max_depth)\n",
    "print(\"Best L2\", best_lambda)\n",
    "print(\"Best L1\", best_alpha)\n",
    "print(\"Best Gamma\", best_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93384fc-81c0-466c-a2bb-bfefcd10a622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
