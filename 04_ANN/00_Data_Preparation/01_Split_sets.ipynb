{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6243b02-165d-496a-a198-f00704a71eb6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6671463d-f9c0-4542-b28c-eec0dfb36e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43925465-ed65-4369-80e9-24640b9d0dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"data_loading.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25beddeb-cbdd-4fc6-bcd2-dc740997c4da",
   "metadata": {},
   "source": [
    "# Reads | Filter Patients (Phase 01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a182eba9-001e-43e2-b928-7bdd96cf667c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 12:25:12,951 - INFO - Successfully read ../CSV/exports/whole_set/o1_hour_overlap_window_mimic.csv into variable o1_mimic\n",
      "2024-12-21 12:25:20,707 - INFO - Successfully read ../CSV/exports/whole_set/o1_hour_overlap_window_eicu.csv into variable o1_eicu\n",
      "2024-12-21 12:25:23,309 - INFO - Successfully read ../CSV/exports/whole_set/o2_hour_overlap_window_mimic.csv into variable o2_mimic\n",
      "2024-12-21 12:25:26,951 - INFO - Successfully read ../CSV/exports/whole_set/o2_hour_overlap_window_eicu.csv into variable o2_eicu\n",
      "2024-12-21 12:25:28,759 - INFO - Successfully read ../CSV/exports/whole_set/o3_hour_overlap_window_mimic.csv into variable o3_mimic\n",
      "2024-12-21 12:25:31,284 - INFO - Successfully read ../CSV/exports/whole_set/o3_hour_overlap_window_eicu.csv into variable o3_eicu\n",
      "2024-12-21 12:25:32,634 - INFO - Successfully read ../CSV/exports/whole_set/o4_hour_overlap_window_mimic.csv into variable o4_mimic\n",
      "2024-12-21 12:25:34,416 - INFO - Successfully read ../CSV/exports/whole_set/o4_hour_overlap_window_eicu.csv into variable o4_eicu\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    # File paths\n",
    "    eicu_file = f\"../CSV/exports/whole_set/o{i}_hour_overlap_window_eicu.csv\"\n",
    "    mimic_file = f\"../CSV/exports/whole_set/o{i}_hour_overlap_window_mimic.csv\"\n",
    "    \n",
    "    # Variable names\n",
    "    eicu_var_name = f\"o{i}_eicu\"\n",
    "    mimic_var_name = f\"o{i}_mimic\"\n",
    "    \n",
    "    try:\n",
    "        # Read MIMIC file and assign to a variable\n",
    "        globals()[mimic_var_name] = pd.read_csv(mimic_file)\n",
    "        logging.info(f\"Successfully read {mimic_file} into variable {mimic_var_name}\")\n",
    "    except FileNotFoundError:\n",
    "        logging.info(f\"{mimic_file} not found.\")\n",
    "    except Exception as e:\n",
    "        logging.info(f\"An error occurred while reading {mimic_file}: {e}\")\n",
    "    \n",
    "    try:\n",
    "        # Read eICU file and assign to a variable\n",
    "        globals()[eicu_var_name] = pd.read_csv(eicu_file)\n",
    "        logging.info(f\"Successfully read {eicu_file} into variable {eicu_var_name}\")\n",
    "    except FileNotFoundError:\n",
    "        logging.info(f\"{eicu_file} not found.\")\n",
    "    except Exception as e:\n",
    "        logging.info(f\"An error occurred while reading {eicu_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79f2f17d-c77d-4f99-bdfd-50e44a076ded",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 12:33:17,623 - INFO - Starting row multiplication for all mimic and eicu datasets.\n",
      "2024-12-21 12:33:17,624 - INFO - Processing mimic dataframe: o2_mimic, multiplying rows by 2.\n",
      "2024-12-21 12:33:17,919 - INFO - Completed multiplication for o2_mimic. New row count: 174432.\n",
      "2024-12-21 12:33:17,920 - INFO - Processing mimic dataframe: o3_mimic, multiplying rows by 3.\n",
      "2024-12-21 12:33:18,196 - INFO - Completed multiplication for o3_mimic. New row count: 174432.\n",
      "2024-12-21 12:33:18,197 - INFO - Processing mimic dataframe: o4_mimic, multiplying rows by 4.\n",
      "2024-12-21 12:33:18,474 - INFO - Completed multiplication for o4_mimic. New row count: 174432.\n",
      "2024-12-21 12:33:18,476 - INFO - Processing eicu dataframe: o2_eicu, multiplying rows by 2.\n",
      "2024-12-21 12:33:18,909 - INFO - Completed multiplication for o2_eicu. New row count: 260016.\n",
      "2024-12-21 12:33:18,910 - INFO - Processing eicu dataframe: o3_eicu, multiplying rows by 3.\n",
      "2024-12-21 12:33:19,332 - INFO - Completed multiplication for o3_eicu. New row count: 260016.\n",
      "2024-12-21 12:33:19,333 - INFO - Processing eicu dataframe: o4_eicu, multiplying rows by 4.\n",
      "2024-12-21 12:33:19,746 - INFO - Completed multiplication for o4_eicu. New row count: 260016.\n",
      "2024-12-21 12:33:19,797 - INFO - Row multiplication for all mimic and eicu datasets is complete.\n"
     ]
    }
   ],
   "source": [
    "# Making all the dataset to have the same rows by multiplication.\n",
    "logging.info(\"Starting row multiplication for all mimic and eicu datasets.\")\n",
    "\n",
    "# Store mimic and eicu dataframes in separate dictionaries\n",
    "mimic_dataframes = {\n",
    "    \"o2_mimic\": o2_mimic,\n",
    "    \"o3_mimic\": o3_mimic,\n",
    "    \"o4_mimic\": o4_mimic,\n",
    "}\n",
    "\n",
    "eicu_dataframes = {\n",
    "    \"o2_eicu\": o2_eicu,\n",
    "    \"o3_eicu\": o3_eicu,\n",
    "    \"o4_eicu\": o4_eicu,\n",
    "}\n",
    "\n",
    "# Multiply rows for mimic datasets\n",
    "for i in range(2, 5):\n",
    "    df_name = f\"o{i}_mimic\"\n",
    "    logging.info(f\"Processing mimic dataframe: {df_name}, multiplying rows by {i}.\")\n",
    "    mimic_dataframes[df_name] = mimic_dataframes[df_name].loc[mimic_dataframes[df_name].index.repeat(i)].reset_index(drop=True)\n",
    "    logging.info(f\"Completed multiplication for {df_name}. New row count: {len(mimic_dataframes[df_name])}.\")\n",
    "\n",
    "# Multiply rows for eicu datasets\n",
    "for i in range(2, 5):\n",
    "    df_name = f\"o{i}_eicu\"\n",
    "    logging.info(f\"Processing eicu dataframe: {df_name}, multiplying rows by {i}.\")\n",
    "    eicu_dataframes[df_name] = eicu_dataframes[df_name].loc[eicu_dataframes[df_name].index.repeat(i)].reset_index(drop=True)\n",
    "    logging.info(f\"Completed multiplication for {df_name}. New row count: {len(eicu_dataframes[df_name])}.\")\n",
    "\n",
    "# Access the modified mimic and eicu dataframes\n",
    "o2_mimic = mimic_dataframes[\"o2_mimic\"]\n",
    "o3_mimic = mimic_dataframes[\"o3_mimic\"]\n",
    "o4_mimic = mimic_dataframes[\"o4_mimic\"]\n",
    "\n",
    "o2_eicu = eicu_dataframes[\"o2_eicu\"]\n",
    "o3_eicu = eicu_dataframes[\"o3_eicu\"]\n",
    "o4_eicu = eicu_dataframes[\"o4_eicu\"]\n",
    "\n",
    "# Logging the end of the process\n",
    "logging.info(\"Row multiplication for all mimic and eicu datasets is complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bc6b27a-0833-4272-8260-1cb5e835b122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 12:35:10,263 - INFO - Processing datasets: o1_mimic and o1_eicu\n",
      "2024-12-21 12:35:10,264 - INFO - Row count of o1_mimic: 174432\n",
      "2024-12-21 12:35:10,653 - INFO - Combined dataset for o1_mimic and o1_eicu created.\n",
      "2024-12-21 12:35:12,363 - INFO - One-hot encoding applied to categorical columns for o1_mimic and o1_eicu.\n",
      "2024-12-21 12:35:12,364 - INFO - Splitting completed for o1_mimic and o1_eicu.\n",
      "2024-12-21 12:35:12,365 - INFO - Processing datasets: o2_mimic and o2_eicu\n",
      "2024-12-21 12:35:12,366 - INFO - Row count of o2_mimic: 174432\n",
      "2024-12-21 12:35:12,843 - INFO - Combined dataset for o2_mimic and o2_eicu created.\n",
      "2024-12-21 12:35:14,647 - INFO - One-hot encoding applied to categorical columns for o2_mimic and o2_eicu.\n",
      "2024-12-21 12:35:14,648 - INFO - Splitting completed for o2_mimic and o2_eicu.\n",
      "2024-12-21 12:35:14,649 - INFO - Processing datasets: o3_mimic and o3_eicu\n",
      "2024-12-21 12:35:14,649 - INFO - Row count of o3_mimic: 174432\n",
      "2024-12-21 12:35:15,122 - INFO - Combined dataset for o3_mimic and o3_eicu created.\n",
      "2024-12-21 12:35:16,753 - INFO - One-hot encoding applied to categorical columns for o3_mimic and o3_eicu.\n",
      "2024-12-21 12:35:16,754 - INFO - Splitting completed for o3_mimic and o3_eicu.\n",
      "2024-12-21 12:35:16,755 - INFO - Processing datasets: o4_mimic and o4_eicu\n",
      "2024-12-21 12:35:16,756 - INFO - Row count of o4_mimic: 174432\n",
      "2024-12-21 12:35:17,292 - INFO - Combined dataset for o4_mimic and o4_eicu created.\n",
      "2024-12-21 12:35:18,917 - INFO - One-hot encoding applied to categorical columns for o4_mimic and o4_eicu.\n",
      "2024-12-21 12:35:18,918 - INFO - Splitting completed for o4_mimic and o4_eicu.\n",
      "2024-12-21 12:35:18,920 - INFO - All datasets have been processed successfully.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "I'm gonna concat and split the mimic and icu\n",
    "at this point. I must create the same columns\n",
    "from the tranformation of categorical data.\n",
    "\"\"\"\n",
    "# Store mimic and eicu datasets in dictionaries\n",
    "mimic_dataframes = {\n",
    "    \"o1_mimic\": o1_mimic,\n",
    "    \"o2_mimic\": o2_mimic,\n",
    "    \"o3_mimic\": o3_mimic,\n",
    "    \"o4_mimic\": o4_mimic,\n",
    "}\n",
    "\n",
    "eicu_dataframes = {\n",
    "    \"o1_eicu\": o1_eicu,\n",
    "    \"o2_eicu\": o2_eicu,\n",
    "    \"o3_eicu\": o3_eicu,\n",
    "    \"o4_eicu\": o4_eicu,\n",
    "}\n",
    "\n",
    "# Loop through datasets to concatenate and split\n",
    "combined_results = {}\n",
    "for i in range(1, 5):\n",
    "    mimic_df_name = f\"o{i}_mimic\"\n",
    "    eicu_df_name = f\"o{i}_eicu\"\n",
    "    \n",
    "    logging.info(f\"Processing datasets: {mimic_df_name} and {eicu_df_name}\")\n",
    "    \n",
    "    # Get the mimic and eicu datasets\n",
    "    mimic_df = mimic_dataframes[mimic_df_name]\n",
    "    eicu_df = eicu_dataframes[eicu_df_name]\n",
    "    \n",
    "    # Get the row count of mimic dataset\n",
    "    row_count = mimic_df.shape[0]\n",
    "    logging.info(f\"Row count of {mimic_df_name}: {row_count}\")\n",
    "    \n",
    "    # Concatenate mimic and eicu datasets\n",
    "    df_combined = pd.concat([mimic_df, eicu_df], ignore_index=True)\n",
    "    logging.info(f\"Combined dataset for {mimic_df_name} and {eicu_df_name} created.\")\n",
    "    \n",
    "    # Find categorical columns and apply one-hot encoding\n",
    "    categorical_columns = df_combined.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    df_encoded = pd.get_dummies(df_combined, columns=categorical_columns)\n",
    "    logging.info(f\"One-hot encoding applied to categorical columns for {mimic_df_name} and {eicu_df_name}.\")\n",
    "    \n",
    "    # Split the encoded dataframe back into mimic and eicu datasets\n",
    "    mimic_encoded = df_encoded.iloc[:row_count, :]\n",
    "    eicu_encoded = df_encoded.iloc[row_count:, :]\n",
    "    \n",
    "    # Store the split results\n",
    "    combined_results[mimic_df_name] = mimic_encoded\n",
    "    combined_results[eicu_df_name] = eicu_encoded\n",
    "    \n",
    "    logging.info(f\"Splitting completed for {mimic_df_name} and {eicu_df_name}.\")\n",
    "\n",
    "# Access the modified mimic and eicu dataframes\n",
    "o1_mimic = combined_results[\"o1_mimic\"]\n",
    "o1_eicu = combined_results[\"o1_eicu\"]\n",
    "o2_mimic = combined_results[\"o2_mimic\"]\n",
    "o2_eicu = combined_results[\"o2_eicu\"]\n",
    "o3_mimic = combined_results[\"o3_mimic\"]\n",
    "o3_eicu = combined_results[\"o3_eicu\"]\n",
    "o4_mimic = combined_results[\"o4_mimic\"]\n",
    "o4_eicu = combined_results[\"o4_eicu\"]\n",
    "\n",
    "# Logging the end of the process\n",
    "logging.info(\"All datasets have been processed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "337b45be-6089-42d7-9d69-f8e946661def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_count</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>Time_Zone</th>\n",
       "      <th>age</th>\n",
       "      <th>Alanine_Aminotransferase_(ALT)_(Max)</th>\n",
       "      <th>Alanine_Aminotransferase_(ALT)_(Mean)</th>\n",
       "      <th>Alanine_Aminotransferase_(ALT)_(Median)</th>\n",
       "      <th>Alanine_Aminotransferase_(ALT)_(Min)</th>\n",
       "      <th>Albumin_(Max)</th>\n",
       "      <th>...</th>\n",
       "      <th>race_PATIENT DECLINED TO ANSWER</th>\n",
       "      <th>race_PORTUGUESE</th>\n",
       "      <th>race_SOUTH AMERICAN</th>\n",
       "      <th>race_UNABLE TO OBTAIN</th>\n",
       "      <th>race_UNKNOWN</th>\n",
       "      <th>race_WHITE</th>\n",
       "      <th>race_WHITE - BRAZILIAN</th>\n",
       "      <th>race_WHITE - EASTERN EUROPEAN</th>\n",
       "      <th>race_WHITE - OTHER EUROPEAN</th>\n",
       "      <th>race_WHITE - RUSSIAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174427</th>\n",
       "      <td>174428</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>44</td>\n",
       "      <td>57</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174428</th>\n",
       "      <td>174429</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>45</td>\n",
       "      <td>57</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174429</th>\n",
       "      <td>174430</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>46</td>\n",
       "      <td>57</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174430</th>\n",
       "      <td>174431</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174431</th>\n",
       "      <td>174432</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>48</td>\n",
       "      <td>57</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153120 rows × 351 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        row_count  subject_id   hadm_id  Time_Zone  age  \\\n",
       "0               1    10004733  27411876          1   51   \n",
       "1               2    10004733  27411876          2   51   \n",
       "2               3    10004733  27411876          3   51   \n",
       "3               4    10004733  27411876          4   51   \n",
       "4               5    10004733  27411876          5   51   \n",
       "...           ...         ...       ...        ...  ...   \n",
       "174427     174428    19999987  23865745         44   57   \n",
       "174428     174429    19999987  23865745         45   57   \n",
       "174429     174430    19999987  23865745         46   57   \n",
       "174430     174431    19999987  23865745         47   57   \n",
       "174431     174432    19999987  23865745         48   57   \n",
       "\n",
       "        Alanine_Aminotransferase_(ALT)_(Max)  \\\n",
       "0                                       46.0   \n",
       "1                                       46.0   \n",
       "2                                       46.0   \n",
       "3                                       46.0   \n",
       "4                                       46.0   \n",
       "...                                      ...   \n",
       "174427                                  63.0   \n",
       "174428                                  63.0   \n",
       "174429                                  63.0   \n",
       "174430                                  63.0   \n",
       "174431                                  63.0   \n",
       "\n",
       "        Alanine_Aminotransferase_(ALT)_(Mean)  \\\n",
       "0                                        46.0   \n",
       "1                                        46.0   \n",
       "2                                        46.0   \n",
       "3                                        46.0   \n",
       "4                                        46.0   \n",
       "...                                       ...   \n",
       "174427                                   63.0   \n",
       "174428                                   63.0   \n",
       "174429                                   63.0   \n",
       "174430                                   63.0   \n",
       "174431                                   63.0   \n",
       "\n",
       "        Alanine_Aminotransferase_(ALT)_(Median)  \\\n",
       "0                                          46.0   \n",
       "1                                          46.0   \n",
       "2                                          46.0   \n",
       "3                                          46.0   \n",
       "4                                          46.0   \n",
       "...                                         ...   \n",
       "174427                                     63.0   \n",
       "174428                                     63.0   \n",
       "174429                                     63.0   \n",
       "174430                                     63.0   \n",
       "174431                                     63.0   \n",
       "\n",
       "        Alanine_Aminotransferase_(ALT)_(Min)  Albumin_(Max)  ...  \\\n",
       "0                                       46.0            2.9  ...   \n",
       "1                                       46.0            2.9  ...   \n",
       "2                                       46.0            2.9  ...   \n",
       "3                                       46.0            2.9  ...   \n",
       "4                                       46.0            2.9  ...   \n",
       "...                                      ...            ...  ...   \n",
       "174427                                  63.0            NaN  ...   \n",
       "174428                                  63.0            NaN  ...   \n",
       "174429                                  63.0            NaN  ...   \n",
       "174430                                  63.0            NaN  ...   \n",
       "174431                                  63.0            NaN  ...   \n",
       "\n",
       "        race_PATIENT DECLINED TO ANSWER  race_PORTUGUESE  race_SOUTH AMERICAN  \\\n",
       "0                                 False            False                False   \n",
       "1                                 False            False                False   \n",
       "2                                 False            False                False   \n",
       "3                                 False            False                False   \n",
       "4                                 False            False                False   \n",
       "...                                 ...              ...                  ...   \n",
       "174427                            False            False                False   \n",
       "174428                            False            False                False   \n",
       "174429                            False            False                False   \n",
       "174430                            False            False                False   \n",
       "174431                            False            False                False   \n",
       "\n",
       "        race_UNABLE TO OBTAIN  race_UNKNOWN  race_WHITE  \\\n",
       "0                       False          True       False   \n",
       "1                       False          True       False   \n",
       "2                       False          True       False   \n",
       "3                       False          True       False   \n",
       "4                       False          True       False   \n",
       "...                       ...           ...         ...   \n",
       "174427                  False          True       False   \n",
       "174428                  False          True       False   \n",
       "174429                  False          True       False   \n",
       "174430                  False          True       False   \n",
       "174431                  False          True       False   \n",
       "\n",
       "        race_WHITE - BRAZILIAN  race_WHITE - EASTERN EUROPEAN  \\\n",
       "0                        False                          False   \n",
       "1                        False                          False   \n",
       "2                        False                          False   \n",
       "3                        False                          False   \n",
       "4                        False                          False   \n",
       "...                        ...                            ...   \n",
       "174427                   False                          False   \n",
       "174428                   False                          False   \n",
       "174429                   False                          False   \n",
       "174430                   False                          False   \n",
       "174431                   False                          False   \n",
       "\n",
       "        race_WHITE - OTHER EUROPEAN  race_WHITE - RUSSIAN  \n",
       "0                             False                 False  \n",
       "1                             False                 False  \n",
       "2                             False                 False  \n",
       "3                             False                 False  \n",
       "4                             False                 False  \n",
       "...                             ...                   ...  \n",
       "174427                        False                 False  \n",
       "174428                        False                 False  \n",
       "174429                        False                 False  \n",
       "174430                        False                 False  \n",
       "174431                        False                 False  \n",
       "\n",
       "[153120 rows x 351 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(o1_mimic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abae581b-694b-43c7-9805-90856381db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "day = 10\n",
    "\n",
    "# Filter icu stay less than 10 days\n",
    "o1_mimic = o1_mimic[o1_mimic['los'] < day]\n",
    "o2_mimic = o2_mimic[o2_mimic['los'] < day]\n",
    "o3_mimic = o3_mimic[o3_mimic['los'] < day]\n",
    "o4_mimic = o4_mimic[o4_mimic['los'] < day]\n",
    "\n",
    "# Filter icu stay less than 10 days\n",
    "o1_eicu = o1_eicu[o1_eicu['los'] < day]\n",
    "o2_eicu = o2_eicu[o2_eicu['los'] < day]\n",
    "o3_eicu = o3_eicu[o3_eicu['los'] < day]\n",
    "o4_eicu = o4_eicu[o4_eicu['los'] < day]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bc6cae-2821-43c1-a6b1-04c79b38273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Time Zone\n",
    "\n",
    "#time_zone = 16\n",
    "#mimic_df = mimic_df[mimic_df['Time_Zone'] == time_zone]\n",
    "#eicu_df = eicu_df[eicu_df['Time_Zone'] == time_zone]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1786ba0-60a9-4593-87be-689ee23fffe2",
   "metadata": {},
   "source": [
    "# Split Training - Validation - Test Set (Phase 02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4565d216-91bb-40f0-b998-c5d8b52d1a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 12:37:05,604 - INFO - o1_mimic:\n",
      "2024-12-21 12:37:05,605 - INFO -   Training set size: 122496\n",
      "2024-12-21 12:37:05,606 - INFO -   Validation set size: 15312\n",
      "2024-12-21 12:37:05,607 - INFO -   Test set size: 15312\n",
      "2024-12-21 12:37:05,983 - INFO - o2_mimic:\n",
      "2024-12-21 12:37:05,984 - INFO -   Training set size: 122496\n",
      "2024-12-21 12:37:05,985 - INFO -   Validation set size: 15312\n",
      "2024-12-21 12:37:05,986 - INFO -   Test set size: 15312\n",
      "2024-12-21 12:37:06,389 - INFO - o3_mimic:\n",
      "2024-12-21 12:37:06,390 - INFO -   Training set size: 122496\n",
      "2024-12-21 12:37:06,391 - INFO -   Validation set size: 15312\n",
      "2024-12-21 12:37:06,392 - INFO -   Test set size: 15312\n",
      "2024-12-21 12:37:06,751 - INFO - o4_mimic:\n",
      "2024-12-21 12:37:06,752 - INFO -   Training set size: 122496\n",
      "2024-12-21 12:37:06,752 - INFO -   Validation set size: 15312\n",
      "2024-12-21 12:37:06,753 - INFO -   Test set size: 15312\n"
     ]
    }
   ],
   "source": [
    "# Mimic datasets dictionary\n",
    "mimic_dataframes = {\n",
    "    \"o1_mimic\": o1_mimic,\n",
    "    \"o2_mimic\": o2_mimic,\n",
    "    \"o3_mimic\": o3_mimic,\n",
    "    \"o4_mimic\": o4_mimic,\n",
    "}\n",
    "\n",
    "# Parameters for splitting\n",
    "total_test_val_perc = 0.2  # Total percentage for validation and test sets\n",
    "split_between_test_val_perc = 0.5  # Percentage split between validation and test sets\n",
    "\n",
    "# Splitting function\n",
    "def split_mimic_data(mimic_df, total_test_val_perc, split_between_test_val_perc):\n",
    "    # Step 1: Group by subject_id and hadm_id\n",
    "    grouped_df = mimic_df.groupby(['subject_id', 'hadm_id'])\n",
    "    patient_df = grouped_df['hospital_expire_flag'].first().reset_index()\n",
    "\n",
    "    # Step 2: Perform stratified split\n",
    "    train, temp = train_test_split(\n",
    "        patient_df,\n",
    "        test_size=total_test_val_perc,\n",
    "        stratify=patient_df['hospital_expire_flag'],\n",
    "        random_state=42\n",
    "    )\n",
    "    val, test = train_test_split(\n",
    "        temp,\n",
    "        test_size=split_between_test_val_perc,\n",
    "        stratify=temp['hospital_expire_flag'],\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Step 3: Merge back to original mimic_df\n",
    "    train_df = mimic_df.merge(train[['subject_id', 'hadm_id']], on=['subject_id', 'hadm_id'], how='inner')\n",
    "    val_df = mimic_df.merge(val[['subject_id', 'hadm_id']], on=['subject_id', 'hadm_id'], how='inner')\n",
    "    test_df = mimic_df.merge(test[['subject_id', 'hadm_id']], on=['subject_id', 'hadm_id'], how='inner')\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "# Loop through mimic datasets and apply the split\n",
    "split_results = {}\n",
    "for name, df in mimic_dataframes.items():\n",
    "    train_df, val_df, test_df = split_mimic_data(df, total_test_val_perc, split_between_test_val_perc)\n",
    "    split_results[name] = {\n",
    "        \"train\": train_df,\n",
    "        \"val\": val_df,\n",
    "        \"test\": test_df\n",
    "    }\n",
    "    # Print the sizes of splits\n",
    "    logging.info(f\"{name}:\")\n",
    "    logging.info(f\"  Training set size: {train_df.shape[0]}\")\n",
    "    logging.info(f\"  Validation set size: {val_df.shape[0]}\")\n",
    "    logging.info(f\"  Test set size: {test_df.shape[0]}\")\n",
    "\n",
    "# Access the splits\n",
    "o1_train = split_results[\"o1_mimic\"][\"train\"]\n",
    "o1_val = split_results[\"o1_mimic\"][\"val\"]\n",
    "o1_test = split_results[\"o1_mimic\"][\"test\"]\n",
    "\n",
    "o2_train = split_results[\"o2_mimic\"][\"train\"]\n",
    "o2_val = split_results[\"o2_mimic\"][\"val\"]\n",
    "o2_test = split_results[\"o2_mimic\"][\"test\"]\n",
    "\n",
    "o3_train = split_results[\"o3_mimic\"][\"train\"]\n",
    "o3_val = split_results[\"o3_mimic\"][\"val\"]\n",
    "o3_test = split_results[\"o3_mimic\"][\"test\"]\n",
    "\n",
    "o4_train = split_results[\"o4_mimic\"][\"train\"]\n",
    "o4_val = split_results[\"o4_mimic\"][\"val\"]\n",
    "o4_test = split_results[\"o4_mimic\"][\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47462f19-6295-4cb1-a8f7-64b8bd104609",
   "metadata": {},
   "source": [
    "# Check ratio and unique patients between sets (Phase 03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "729ed3bc-b7ae-48fe-892f-66b6f814c5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set\n",
      "Survive: 2028.0\n",
      "Non-survive: 524.0\n",
      "Ratio Train Set: 3.87:1\n",
      "\n",
      "Validation Set\n",
      "Survive: 253.0\n",
      "Non-survive: 66.0\n",
      "Ratio Train Set: 3.83:1\n",
      "\n",
      "Test Set\n",
      "Survive: 254.0\n",
      "Non-survive: 65.0\n",
      "Ratio Train Set: 3.91:1\n"
     ]
    }
   ],
   "source": [
    "# Count on Training set survive and non-survive\n",
    "survival_counts = o2_train['hospital_expire_flag'].value_counts()\n",
    "temp_survive = survival_counts.get(0, 0)/48\n",
    "temp_non_survive = survival_counts.get(1, 0)/48\n",
    "\n",
    "# Display the results\n",
    "print(f'Train Set')\n",
    "print(f'Survive: {temp_survive}')\n",
    "print(f'Non-survive: {temp_non_survive}')\n",
    "\n",
    "# Check if temp_non_survive is not zero to avoid division by zero\n",
    "if temp_non_survive != 0:\n",
    "    ratio = temp_survive / temp_non_survive\n",
    "else:\n",
    "    ratio = float('inf')  # Set ratio to infinity if there are no non-survivors\n",
    "\n",
    "# Display the ratio\n",
    "print(f'Ratio Train Set: {ratio:.2f}:1')\n",
    "\n",
    "\"\"\"----------------------------\"\"\"\n",
    "\n",
    "# Count on validation set survive and non-survive\n",
    "survival_counts = o2_val['hospital_expire_flag'].value_counts()\n",
    "temp_survive = survival_counts.get(0, 0)/48\n",
    "temp_non_survive = survival_counts.get(1, 0)/48\n",
    "\n",
    "# Display the results\n",
    "print(f'\\nValidation Set')\n",
    "print(f'Survive: {temp_survive}')\n",
    "print(f'Non-survive: {temp_non_survive}')\n",
    "\n",
    "# Check if temp_non_survive is not zero to avoid division by zero\n",
    "if temp_non_survive != 0:\n",
    "    ratio = temp_survive / temp_non_survive\n",
    "else:\n",
    "    ratio = float('inf')  # Set ratio to infinity if there are no non-survivors\n",
    "\n",
    "# Display the ratio\n",
    "print(f'Ratio Train Set: {ratio:.2f}:1')\n",
    "\n",
    "\"\"\"----------------------------\"\"\"\n",
    "\n",
    "# Count on validation set survive and non-survive\n",
    "survival_counts = o2_test['hospital_expire_flag'].value_counts()\n",
    "temp_survive = survival_counts.get(0, 0)/48\n",
    "temp_non_survive = survival_counts.get(1, 0)/48\n",
    "\n",
    "# Display the results\n",
    "print(f'\\nTest Set')\n",
    "print(f'Survive: {temp_survive}')\n",
    "print(f'Non-survive: {temp_non_survive}')\n",
    "\n",
    "# Check if temp_non_survive is not zero to avoid division by zero\n",
    "if temp_non_survive != 0:\n",
    "    ratio = temp_survive / temp_non_survive\n",
    "else:\n",
    "    ratio = float('inf')  # Set ratio to infinity if there are no non-survivors\n",
    "\n",
    "# Display the ratio\n",
    "print(f'Ratio Train Set: {ratio:.2f}:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73205561-9bcc-42fe-acc4-8bcd1616d9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap between training and validation sets: 0\n",
      "Overlap between training and test sets: 0\n",
      "Overlap between validation and test sets: 0\n"
     ]
    }
   ],
   "source": [
    "# Mine unique subject_id from sets\n",
    "train_subjects = set(o2_train['subject_id'].unique())\n",
    "val_subjects = set(o2_val['subject_id'].unique())\n",
    "test_subjects = set(o2_test['subject_id'].unique())\n",
    "\n",
    "# Check if there are overlaping subject_id\n",
    "train_val_overlap = train_subjects.intersection(val_subjects)\n",
    "train_test_overlap = train_subjects.intersection(test_subjects)\n",
    "val_test_overlap = val_subjects.intersection(test_subjects)\n",
    "\n",
    "# Display the results\n",
    "print(f'Overlap between training and validation sets: {len(train_val_overlap)}')\n",
    "print(f'Overlap between training and test sets: {len(train_test_overlap)}')\n",
    "print(f'Overlap between validation and test sets: {len(val_test_overlap)}')\n",
    "\n",
    "# print overlaping\n",
    "if train_val_overlap:\n",
    "    print(f'Subjects in both training and validation: {train_val_overlap}')\n",
    "if train_test_overlap:\n",
    "    print(f'Subjects in both training and test: {train_test_overlap}')\n",
    "if val_test_overlap:\n",
    "    print(f'Subjects in both validation and test: {val_test_overlap}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d473a75a-86eb-4dac-be9a-b73cf80b111b",
   "metadata": {},
   "source": [
    "# Split label from Train - Validation - Test Sets (Phase 04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee62e244-e475-4222-802b-57d374b63c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# External validation from eICU\n",
    "o1_X_external = o1_eicu.drop(columns=['hospital_expire_flag', 'los', 'subject_id', 'hadm_id', 'row_count', 'Time_Zone'])\n",
    "o1_y_external_los = o1_eicu['los']\n",
    "o1_y_external_mortality = o1_eicu['hospital_expire_flag']\n",
    "\n",
    "o2_X_external = o2_eicu.drop(columns=['hospital_expire_flag', 'los', 'subject_id', 'hadm_id', 'row_count', 'Time_Zone'])\n",
    "o2_y_external_los = o2_eicu['los']\n",
    "o2_y_external_mortality = o2_eicu['hospital_expire_flag']\n",
    "\n",
    "o3_X_external = o3_eicu.drop(columns=['hospital_expire_flag', 'los', 'subject_id', 'hadm_id', 'row_count', 'Time_Zone'])\n",
    "o3_y_external_los = o3_eicu['los']\n",
    "o3_y_external_mortality = o3_eicu['hospital_expire_flag']\n",
    "\n",
    "o4_X_external = o4_eicu.drop(columns=['hospital_expire_flag', 'los', 'subject_id', 'hadm_id', 'row_count', 'Time_Zone'])\n",
    "o4_y_external_los = o4_eicu['los']\n",
    "o4_y_external_mortality = o4_eicu['hospital_expire_flag']\n",
    "\n",
    "\n",
    "# Separate features and target for the training, validation, and test sets\n",
    "# Train\n",
    "o1_X_train = o1_train.drop(columns=['hospital_expire_flag', 'los', 'subject_id', 'hadm_id', 'row_count', 'Time_Zone'])\n",
    "o1_y_train_los = o1_train['los']\n",
    "o1_y_train_mortality = o1_train['hospital_expire_flag']\n",
    "\n",
    "o2_X_train = o2_train.drop(columns=['hospital_expire_flag', 'los', 'subject_id', 'hadm_id', 'row_count', 'Time_Zone'])\n",
    "o2_y_train_los = o2_train['los']\n",
    "o2_y_train_mortality = o2_train['hospital_expire_flag']\n",
    "\n",
    "o3_X_train = o3_train.drop(columns=['hospital_expire_flag', 'los', 'subject_id', 'hadm_id', 'row_count', 'Time_Zone'])\n",
    "o3_y_train_los = o3_train['los']\n",
    "o3_y_train_mortality = o3_train['hospital_expire_flag']\n",
    "\n",
    "o4_X_train = o4_train.drop(columns=['hospital_expire_flag', 'los', 'subject_id', 'hadm_id', 'row_count', 'Time_Zone'])\n",
    "o4_y_train_los = o4_train['los']\n",
    "o4_y_train_mortality = o4_train['hospital_expire_flag']\n",
    "\n",
    "# Validation\n",
    "o1_X_validate = o1_val.drop(columns=['hospital_expire_flag', 'los', 'subject_id', 'hadm_id', 'row_count', 'Time_Zone'])\n",
    "o1_y_validate_los = o1_val['los']\n",
    "o1_y_validate_mortality = o1_val['hospital_expire_flag']\n",
    "\n",
    "o2_X_validate = o2_val.drop(columns=['hospital_expire_flag', 'los', 'subject_id', 'hadm_id', 'row_count', 'Time_Zone'])\n",
    "o2_y_validate_los = o2_val['los']\n",
    "o2_y_validate_mortality = o2_val['hospital_expire_flag']\n",
    "\n",
    "o3_X_validate = o3_val.drop(columns=['hospital_expire_flag', 'los', 'subject_id', 'hadm_id', 'row_count', 'Time_Zone'])\n",
    "o3_y_validate_los = o3_val['los']\n",
    "o3_y_validate_mortality = o3_val['hospital_expire_flag']\n",
    "\n",
    "o4_X_validate = o4_val.drop(columns=['hospital_expire_flag', 'los', 'subject_id', 'hadm_id', 'row_count', 'Time_Zone'])\n",
    "o4_y_validate_los = o4_val['los']\n",
    "o4_y_validate_mortality = o4_val['hospital_expire_flag']\n",
    "\n",
    "# Test\n",
    "o1_X_test = o1_test.drop(columns=['hospital_expire_flag', 'los', 'subject_id', 'hadm_id', 'row_count', 'Time_Zone'])\n",
    "o1_y_test_los = o1_test['los']\n",
    "o1_y_test_mortality = o1_test['hospital_expire_flag']\n",
    "\n",
    "o2_X_test = o2_test.drop(columns=['hospital_expire_flag', 'los', 'subject_id', 'hadm_id', 'row_count', 'Time_Zone'])\n",
    "o2_y_test_los = o2_test['los']\n",
    "o2_y_test_mortality = o2_test['hospital_expire_flag']\n",
    "\n",
    "o3_X_test = o3_test.drop(columns=['hospital_expire_flag', 'los', 'subject_id', 'hadm_id', 'row_count', 'Time_Zone'])\n",
    "o3_y_test_los = o3_test['los']\n",
    "o3_y_test_mortality = o3_test['hospital_expire_flag']\n",
    "\n",
    "o4_X_test = o4_test.drop(columns=['hospital_expire_flag', 'los', 'subject_id', 'hadm_id', 'row_count', 'Time_Zone'])\n",
    "o4_y_test_los = o4_test['los']\n",
    "o4_y_test_mortality = o4_test['hospital_expire_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca998b29-a24f-449a-b37f-4533a295b61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframes have the same order in the columns 'subject_id' and 'hadm_id'.\n"
     ]
    }
   ],
   "source": [
    "# Check if the specified columns have the same order across all dataframes\n",
    "columns_to_check = ['subject_id', 'hadm_id']\n",
    "\n",
    "# Extract the relevant columns from each dataframe\n",
    "o1_subset = o1_train[columns_to_check]\n",
    "o2_subset = o2_train[columns_to_check]\n",
    "o3_subset = o3_train[columns_to_check]\n",
    "o4_subset = o4_train[columns_to_check]\n",
    "\n",
    "# Compare the order and content\n",
    "same_order = (\n",
    "    o1_subset.equals(o2_subset) and\n",
    "    o1_subset.equals(o3_subset) and\n",
    "    o1_subset.equals(o4_subset)\n",
    ")\n",
    "\n",
    "# Print the result\n",
    "if same_order:\n",
    "    print(\"The dataframes have the same order in the columns 'subject_id' and 'hadm_id'.\")\n",
    "else:\n",
    "    print(\"The dataframes do NOT have the same order in the columns 'subject_id' and'hadm_id'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbc9eff3-d99d-4fed-b2f6-a0986eba0049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 12:38:12,610 - INFO - Output directory set to: ../CSV/exports/split_set\n",
      "2024-12-21 12:38:55,603 - INFO - Saved o1_X_external.csv to ../CSV/exports/split_set\\o1_X_external.csv\n",
      "2024-12-21 12:38:55,807 - INFO - Saved o1_y_external_los.csv to ../CSV/exports/split_set\\o1_y_external_los.csv\n",
      "2024-12-21 12:38:55,909 - INFO - Saved o1_y_external_mortality.csv to ../CSV/exports/split_set\\o1_y_external_mortality.csv\n",
      "2024-12-21 12:39:38,264 - INFO - Saved o2_X_external.csv to ../CSV/exports/split_set\\o2_X_external.csv\n",
      "2024-12-21 12:39:38,480 - INFO - Saved o2_y_external_los.csv to ../CSV/exports/split_set\\o2_y_external_los.csv\n",
      "2024-12-21 12:39:38,586 - INFO - Saved o2_y_external_mortality.csv to ../CSV/exports/split_set\\o2_y_external_mortality.csv\n",
      "2024-12-21 12:40:20,678 - INFO - Saved o3_X_external.csv to ../CSV/exports/split_set\\o3_X_external.csv\n",
      "2024-12-21 12:40:20,893 - INFO - Saved o3_y_external_los.csv to ../CSV/exports/split_set\\o3_y_external_los.csv\n",
      "2024-12-21 12:40:21,002 - INFO - Saved o3_y_external_mortality.csv to ../CSV/exports/split_set\\o3_y_external_mortality.csv\n",
      "2024-12-21 12:41:02,697 - INFO - Saved o4_X_external.csv to ../CSV/exports/split_set\\o4_X_external.csv\n",
      "2024-12-21 12:41:02,909 - INFO - Saved o4_y_external_los.csv to ../CSV/exports/split_set\\o4_y_external_los.csv\n",
      "2024-12-21 12:41:03,021 - INFO - Saved o4_y_external_mortality.csv to ../CSV/exports/split_set\\o4_y_external_mortality.csv\n",
      "2024-12-21 12:41:26,042 - INFO - Saved o1_X_train.csv to ../CSV/exports/split_set\\o1_X_train.csv\n",
      "2024-12-21 12:41:26,247 - INFO - Saved o1_y_train_los.csv to ../CSV/exports/split_set\\o1_y_train_los.csv\n",
      "2024-12-21 12:41:26,309 - INFO - Saved o1_y_train_mortality.csv to ../CSV/exports/split_set\\o1_y_train_mortality.csv\n",
      "2024-12-21 12:41:50,071 - INFO - Saved o2_X_train.csv to ../CSV/exports/split_set\\o2_X_train.csv\n",
      "2024-12-21 12:41:50,287 - INFO - Saved o2_y_train_los.csv to ../CSV/exports/split_set\\o2_y_train_los.csv\n",
      "2024-12-21 12:41:50,354 - INFO - Saved o2_y_train_mortality.csv to ../CSV/exports/split_set\\o2_y_train_mortality.csv\n",
      "2024-12-21 12:42:14,494 - INFO - Saved o3_X_train.csv to ../CSV/exports/split_set\\o3_X_train.csv\n",
      "2024-12-21 12:42:14,701 - INFO - Saved o3_y_train_los.csv to ../CSV/exports/split_set\\o3_y_train_los.csv\n",
      "2024-12-21 12:42:14,764 - INFO - Saved o3_y_train_mortality.csv to ../CSV/exports/split_set\\o3_y_train_mortality.csv\n",
      "2024-12-21 12:42:38,469 - INFO - Saved o4_X_train.csv to ../CSV/exports/split_set\\o4_X_train.csv\n",
      "2024-12-21 12:42:38,678 - INFO - Saved o4_y_train_los.csv to ../CSV/exports/split_set\\o4_y_train_los.csv\n",
      "2024-12-21 12:42:38,738 - INFO - Saved o4_y_train_mortality.csv to ../CSV/exports/split_set\\o4_y_train_mortality.csv\n",
      "2024-12-21 12:42:41,645 - INFO - Saved o1_X_validate.csv to ../CSV/exports/split_set\\o1_X_validate.csv\n",
      "2024-12-21 12:42:41,680 - INFO - Saved o1_y_validate_los.csv to ../CSV/exports/split_set\\o1_y_validate_los.csv\n",
      "2024-12-21 12:42:41,690 - INFO - Saved o1_y_validate_mortality.csv to ../CSV/exports/split_set\\o1_y_validate_mortality.csv\n",
      "2024-12-21 12:42:44,639 - INFO - Saved o2_X_validate.csv to ../CSV/exports/split_set\\o2_X_validate.csv\n",
      "2024-12-21 12:42:44,670 - INFO - Saved o2_y_validate_los.csv to ../CSV/exports/split_set\\o2_y_validate_los.csv\n",
      "2024-12-21 12:42:44,682 - INFO - Saved o2_y_validate_mortality.csv to ../CSV/exports/split_set\\o2_y_validate_mortality.csv\n",
      "2024-12-21 12:42:47,607 - INFO - Saved o3_X_validate.csv to ../CSV/exports/split_set\\o3_X_validate.csv\n",
      "2024-12-21 12:42:47,643 - INFO - Saved o3_y_validate_los.csv to ../CSV/exports/split_set\\o3_y_validate_los.csv\n",
      "2024-12-21 12:42:47,654 - INFO - Saved o3_y_validate_mortality.csv to ../CSV/exports/split_set\\o3_y_validate_mortality.csv\n",
      "2024-12-21 12:42:50,751 - INFO - Saved o4_X_validate.csv to ../CSV/exports/split_set\\o4_X_validate.csv\n",
      "2024-12-21 12:42:50,784 - INFO - Saved o4_y_validate_los.csv to ../CSV/exports/split_set\\o4_y_validate_los.csv\n",
      "2024-12-21 12:42:50,794 - INFO - Saved o4_y_validate_mortality.csv to ../CSV/exports/split_set\\o4_y_validate_mortality.csv\n",
      "2024-12-21 12:42:53,812 - INFO - Saved o1_X_test.csv to ../CSV/exports/split_set\\o1_X_test.csv\n",
      "2024-12-21 12:42:53,844 - INFO - Saved o1_y_test_los.csv to ../CSV/exports/split_set\\o1_y_test_los.csv\n",
      "2024-12-21 12:42:53,855 - INFO - Saved o1_y_test_mortality.csv to ../CSV/exports/split_set\\o1_y_test_mortality.csv\n",
      "2024-12-21 12:42:56,785 - INFO - Saved o2_X_test.csv to ../CSV/exports/split_set\\o2_X_test.csv\n",
      "2024-12-21 12:42:56,814 - INFO - Saved o2_y_test_los.csv to ../CSV/exports/split_set\\o2_y_test_los.csv\n",
      "2024-12-21 12:42:56,826 - INFO - Saved o2_y_test_mortality.csv to ../CSV/exports/split_set\\o2_y_test_mortality.csv\n",
      "2024-12-21 12:42:59,757 - INFO - Saved o3_X_test.csv to ../CSV/exports/split_set\\o3_X_test.csv\n",
      "2024-12-21 12:42:59,786 - INFO - Saved o3_y_test_los.csv to ../CSV/exports/split_set\\o3_y_test_los.csv\n",
      "2024-12-21 12:42:59,798 - INFO - Saved o3_y_test_mortality.csv to ../CSV/exports/split_set\\o3_y_test_mortality.csv\n",
      "2024-12-21 12:43:02,766 - INFO - Saved o4_X_test.csv to ../CSV/exports/split_set\\o4_X_test.csv\n",
      "2024-12-21 12:43:02,795 - INFO - Saved o4_y_test_los.csv to ../CSV/exports/split_set\\o4_y_test_los.csv\n",
      "2024-12-21 12:43:02,806 - INFO - Saved o4_y_test_mortality.csv to ../CSV/exports/split_set\\o4_y_test_mortality.csv\n",
      "2024-12-21 12:43:02,806 - INFO - All datasets have been processed successfully.\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"../CSV/exports/split_set\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "logging.info(f\"Output directory set to: {output_dir}\")\n",
    "\n",
    "# Variables to save\n",
    "variables_to_save = {\n",
    "    \"o1_X_external.csv\": o1_X_external,\n",
    "    \"o1_y_external_los.csv\": o1_y_external_los,\n",
    "    \"o1_y_external_mortality.csv\": o1_y_external_mortality,\n",
    "    \"o2_X_external.csv\": o2_X_external,\n",
    "    \"o2_y_external_los.csv\": o2_y_external_los,\n",
    "    \"o2_y_external_mortality.csv\": o2_y_external_mortality,\n",
    "    \"o3_X_external.csv\": o3_X_external,\n",
    "    \"o3_y_external_los.csv\": o3_y_external_los,\n",
    "    \"o3_y_external_mortality.csv\": o3_y_external_mortality,\n",
    "    \"o4_X_external.csv\": o4_X_external,\n",
    "    \"o4_y_external_los.csv\": o4_y_external_los,\n",
    "    \"o4_y_external_mortality.csv\": o4_y_external_mortality,\n",
    "    \"o1_X_train.csv\": o1_X_train,\n",
    "    \"o1_y_train_los.csv\": o1_y_train_los,\n",
    "    \"o1_y_train_mortality.csv\": o1_y_train_mortality,\n",
    "    \"o2_X_train.csv\": o2_X_train,\n",
    "    \"o2_y_train_los.csv\": o2_y_train_los,\n",
    "    \"o2_y_train_mortality.csv\": o2_y_train_mortality,\n",
    "    \"o3_X_train.csv\": o3_X_train,\n",
    "    \"o3_y_train_los.csv\": o3_y_train_los,\n",
    "    \"o3_y_train_mortality.csv\": o3_y_train_mortality,\n",
    "    \"o4_X_train.csv\": o4_X_train,\n",
    "    \"o4_y_train_los.csv\": o4_y_train_los,\n",
    "    \"o4_y_train_mortality.csv\": o4_y_train_mortality,\n",
    "    \"o1_X_validate.csv\": o1_X_validate,\n",
    "    \"o1_y_validate_los.csv\": o1_y_validate_los,\n",
    "    \"o1_y_validate_mortality.csv\": o1_y_validate_mortality,\n",
    "    \"o2_X_validate.csv\": o2_X_validate,\n",
    "    \"o2_y_validate_los.csv\": o2_y_validate_los,\n",
    "    \"o2_y_validate_mortality.csv\": o2_y_validate_mortality,\n",
    "    \"o3_X_validate.csv\": o3_X_validate,\n",
    "    \"o3_y_validate_los.csv\": o3_y_validate_los,\n",
    "    \"o3_y_validate_mortality.csv\": o3_y_validate_mortality,\n",
    "    \"o4_X_validate.csv\": o4_X_validate,\n",
    "    \"o4_y_validate_los.csv\": o4_y_validate_los,\n",
    "    \"o4_y_validate_mortality.csv\": o4_y_validate_mortality,\n",
    "    \"o1_X_test.csv\": o1_X_test,\n",
    "    \"o1_y_test_los.csv\": o1_y_test_los,\n",
    "    \"o1_y_test_mortality.csv\": o1_y_test_mortality,\n",
    "    \"o2_X_test.csv\": o2_X_test,\n",
    "    \"o2_y_test_los.csv\": o2_y_test_los,\n",
    "    \"o2_y_test_mortality.csv\": o2_y_test_mortality,\n",
    "    \"o3_X_test.csv\": o3_X_test,\n",
    "    \"o3_y_test_los.csv\": o3_y_test_los,\n",
    "    \"o3_y_test_mortality.csv\": o3_y_test_mortality,\n",
    "    \"o4_X_test.csv\": o4_X_test,\n",
    "    \"o4_y_test_los.csv\": o4_y_test_los,\n",
    "    \"o4_y_test_mortality.csv\": o4_y_test_mortality,\n",
    "}\n",
    "\n",
    "# Save each variable to its respective CSV file\n",
    "for file_name, variable in variables_to_save.items():\n",
    "    file_path = os.path.join(output_dir, file_name)\n",
    "    variable.to_csv(file_path, index=False)\n",
    "    logging.info(f\"Saved {file_name} to {file_path}\")\n",
    "\n",
    "# Logging the end of the process\n",
    "logging.info(\"All datasets have been processed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
