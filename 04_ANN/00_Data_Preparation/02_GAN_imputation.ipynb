{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27150fe1-2273-4084-bfdb-af667c2c54c2",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ba9ff51-183c-48dd-ab85-986b02ba8647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, ParameterGrid, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75af6198-0887-4e5d-bd6f-63071e1ceb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"data_loading.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688a0783-9c31-47d9-8cb4-b093c68c1302",
   "metadata": {},
   "source": [
    "# Load Train - Validation - Test & External Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a53833f-0875-467d-a556-4e3508c362fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 20:11:33,241 - INFO - Loading X_external from ../CSV/exports/split_set/o4_X_external.csv\n",
      "2024-12-15 20:11:34,887 - INFO - Loading y_external from ../CSV/exports/split_set/o4_y_external_los.csv\n",
      "2024-12-15 20:11:34,904 - INFO - Loading X_train from ../CSV/exports/split_set/o4_X_train.csv\n",
      "2024-12-15 20:11:35,867 - INFO - Loading y_train from ../CSV/exports/split_set/o4_y_train_los.csv\n",
      "2024-12-15 20:11:35,883 - INFO - Loading X_validate from ../CSV/exports/split_set/o4_X_validate.csv\n",
      "2024-12-15 20:11:36,028 - INFO - Loading y_validate from ../CSV/exports/split_set/o4_y_validate_los.csv\n",
      "2024-12-15 20:11:36,033 - INFO - Loading X_test from ../CSV/exports/split_set/o4_X_test.csv\n",
      "2024-12-15 20:11:36,182 - INFO - Loading y_test from ../CSV/exports/split_set/o4_y_test_los.csv\n"
     ]
    }
   ],
   "source": [
    "# Define subfolder\n",
    "subfolder = \"split_set\"\n",
    "name = \"o4\"\n",
    "\n",
    "# Load CSV files into corresponding variables\n",
    "logging.info(f\"Loading X_external from ../CSV/exports/{subfolder}/{name}_X_external.csv\")\n",
    "X_external = pd.read_csv(f\"../CSV/exports/{subfolder}/{name}_X_external.csv\")\n",
    "\n",
    "logging.info(f\"Loading y_external from ../CSV/exports/{subfolder}/{name}_y_external_los.csv\")\n",
    "y_external = pd.read_csv(f\"../CSV/exports/{subfolder}/{name}_y_external_los.csv\")\n",
    "\n",
    "logging.info(f\"Loading X_train from ../CSV/exports/{subfolder}/{name}_X_train.csv\")\n",
    "X_train = pd.read_csv(f\"../CSV/exports/{subfolder}/{name}_X_train.csv\")\n",
    "\n",
    "logging.info(f\"Loading y_train from ../CSV/exports/{subfolder}/{name}_y_train_los.csv\")\n",
    "y_train = pd.read_csv(f\"../CSV/exports/{subfolder}/{name}_y_train_los.csv\")\n",
    "\n",
    "logging.info(f\"Loading X_validate from ../CSV/exports/{subfolder}/{name}_X_validate.csv\")\n",
    "X_validate = pd.read_csv(f\"../CSV/exports/{subfolder}/{name}_X_validate.csv\")\n",
    "\n",
    "logging.info(f\"Loading y_validate from ../CSV/exports/{subfolder}/{name}_y_validate_los.csv\")\n",
    "y_validate = pd.read_csv(f\"../CSV/exports/{subfolder}/{name}_y_validate_los.csv\")\n",
    "\n",
    "logging.info(f\"Loading X_test from ../CSV/exports/{subfolder}/{name}_X_test.csv\")\n",
    "X_test = pd.read_csv(f\"../CSV/exports/{subfolder}/{name}_X_test.csv\")\n",
    "\n",
    "logging.info(f\"Loading y_test from ../CSV/exports/{subfolder}/{name}_y_test_los.csv\")\n",
    "y_test = pd.read_csv(f\"../CSV/exports/{subfolder}/{name}_y_test_los.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b1ea72-18c5-4f51-a463-15f83bb26771",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# o01 Simple GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49001668-dc2b-4c05-8e19-9e2bcbfbbf8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Custom Dataset class for PyTorch\n",
    "def prepare_dataset(X):\n",
    "    class CustomDataset(Dataset):\n",
    "        def __init__(self, data):\n",
    "            # Ensure data is converted to numeric type to avoid object type errors\n",
    "            self.data = torch.tensor(data.astype(np.float32), dtype=torch.float32)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self.data[idx]\n",
    "    \n",
    "    return CustomDataset(X)\n",
    "\n",
    "# Define Generator model\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "# Define Discriminator model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "# GAN Imputation Function with Early Stopping\n",
    "def impute_missing_values_with_gan(X, epochs=1000, batch_size=64, learning_rate=0.0002, patience=10):\n",
    "    # Prepare data and mask for missing values\n",
    "    X_missing = X.copy()\n",
    "    mask = X_missing.isna()\n",
    "    X_missing.fillna(0, inplace=True)\n",
    "    \n",
    "    # Prepare dataset and dataloader\n",
    "    dataset = prepare_dataset(X_missing.values)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    input_dim = X.shape[1]\n",
    "\n",
    "    # Initialize Generator and Discriminator\n",
    "    generator = Generator(input_dim)\n",
    "    discriminator = Discriminator(input_dim)\n",
    "\n",
    "    # Device placement\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    generator.to(device)\n",
    "    discriminator.to(device)\n",
    "\n",
    "    # Optimizers\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Loss function\n",
    "    adversarial_loss = nn.BCELoss().to(device)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i, real_data in enumerate(dataloader):\n",
    "            # Move data to the correct device\n",
    "            real_data = real_data.to(device)\n",
    "\n",
    "            # Adversarial ground truths\n",
    "            valid = torch.ones(real_data.size(0), 1).to(device)\n",
    "            fake = torch.zeros(real_data.size(0), 1).to(device)\n",
    "\n",
    "            # Train Generator\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "            # Generate data and replace missing values with generated data\n",
    "            gen_data = generator(real_data)\n",
    "            batch_mask = mask.iloc[i * batch_size:(i + 1) * batch_size].values\n",
    "            gen_data[batch_mask] = real_data[batch_mask]\n",
    "\n",
    "            # Generator loss\n",
    "            g_loss = adversarial_loss(discriminator(gen_data), valid)\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            # Train Discriminator\n",
    "            optimizer_D.zero_grad()\n",
    "\n",
    "            # Real and fake losses\n",
    "            real_loss = adversarial_loss(discriminator(real_data), valid)\n",
    "            fake_loss = adversarial_loss(discriminator(gen_data.detach()), fake)\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "        # Logging progress\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        logging.info(f\"Epoch {epoch + 1}/{epochs} - Generator Loss: {g_loss.item()}, Discriminator Loss: {d_loss.item()}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if g_loss.item() < best_loss:\n",
    "            best_loss = g_loss.item()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            logging.info(f\"Early stopping at epoch {epoch + 1} - Generator Loss: {g_loss.item()}\")\n",
    "            break\n",
    "\n",
    "    # Impute missing values using the trained generator\n",
    "    X_imputed = X_missing.copy()\n",
    "    X_imputed = torch.tensor(X_imputed.values.astype(np.float32), dtype=torch.float32).to(device)\n",
    "    X_imputed = generator(X_imputed).detach().cpu().numpy()  # Move back to CPU for numpy compatibility\n",
    "    X_imputed[mask.values] = X_missing.values[mask.values]\n",
    "\n",
    "    return pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "# Save models (optional)\n",
    "# torch.save(generator.state_dict(), \"generator.pth\")\n",
    "# torch.save(discriminator.state_dict(), \"discriminator.pth\")\n",
    "\n",
    "# Impute missing values for each dataset separately\n",
    "X_external_imputed = impute_missing_values_with_gan(X_external)\n",
    "X_train_imputed = impute_missing_values_with_gan(X_train)\n",
    "X_validate_imputed = impute_missing_values_with_gan(X_validate)\n",
    "X_test_imputed = impute_missing_values_with_gan(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db63bc38-3870-4a3e-bc8e-95c90d03569b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# o02 Run GAN multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9044bafa-3401-42fd-b9f7-5be534ee19a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Custom Dataset class for PyTorch\n",
    "def prepare_dataset(X):\n",
    "    class CustomDataset(Dataset):\n",
    "        def __init__(self, data):\n",
    "            # Ensure data is converted to numeric type to avoid object type errors\n",
    "            self.data = torch.tensor(data.astype(np.float32), dtype=torch.float32)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self.data[idx]\n",
    "    \n",
    "    return CustomDataset(X)\n",
    "\n",
    "# Define Generator model\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "# Define Discriminator model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "# GAN Imputation Function with Multiple Passes and Early Stopping\n",
    "def impute_missing_values_with_multiple_passes(X, num_passes=3, epochs=1000, batch_size=64, learning_rate=0.0002, patience=10):\n",
    "    # Prepare data and mask for missing values\n",
    "    X_imputed = X.copy()\n",
    "    mask = X_imputed.isna()\n",
    "    X_imputed.fillna(0, inplace=True)\n",
    "    \n",
    "    # Input dimension\n",
    "    input_dim = X.shape[1]\n",
    "\n",
    "    # Multiple passes\n",
    "    for pass_num in range(num_passes):\n",
    "        print(f\"\\n--- Imputation Pass {pass_num + 1}/{num_passes} ---\\n\")\n",
    "        \n",
    "        # Prepare dataset and dataloader\n",
    "        dataset = prepare_dataset(X_imputed.values)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        # Initialize Generator and Discriminator\n",
    "        generator = Generator(input_dim)\n",
    "        discriminator = Discriminator(input_dim)\n",
    "\n",
    "        # Optimizers\n",
    "        optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "        optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Loss function\n",
    "        adversarial_loss = nn.BCELoss()\n",
    "\n",
    "        best_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for i, real_data in enumerate(dataloader):\n",
    "                # Adversarial ground truths\n",
    "                valid = torch.ones(real_data.size(0), 1)\n",
    "                fake = torch.zeros(real_data.size(0), 1)\n",
    "\n",
    "                # Train Generator\n",
    "                optimizer_G.zero_grad()\n",
    "\n",
    "                # Generate data and replace missing values with generated data\n",
    "                gen_data = generator(real_data)\n",
    "                gen_data[mask.iloc[i * batch_size:(i + 1) * batch_size].values] = real_data[mask.iloc[i * batch_size:(i + 1) * batch_size].values]\n",
    "\n",
    "                # Generator loss\n",
    "                g_loss = adversarial_loss(discriminator(gen_data), valid)\n",
    "                g_loss.backward()\n",
    "                optimizer_G.step()\n",
    "\n",
    "                # Train Discriminator\n",
    "                optimizer_D.zero_grad()\n",
    "\n",
    "                # Real and fake losses\n",
    "                real_loss = adversarial_loss(discriminator(real_data), valid)\n",
    "                fake_loss = adversarial_loss(discriminator(gen_data.detach()), fake)\n",
    "                d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "                d_loss.backward()\n",
    "                optimizer_D.step()\n",
    "\n",
    "            # Display progress\n",
    "            #print(f\"Epoch {epoch + 1}/{epochs} - Generator Loss: {g_loss.item()}, Discriminator Loss: {d_loss.item()}\")\n",
    "\n",
    "            # Logging progress\n",
    "            logging.basicConfig(level=logging.INFO)\n",
    "            logging.info(f\"Epoch {epoch + 1}/{epochs} - Generator Loss: {g_loss.item()}, Discriminator Loss: {d_loss.item()}\")\n",
    "\n",
    "            # Early stopping\n",
    "            if g_loss.item() < best_loss:\n",
    "                best_loss = g_loss.item()\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} - Generator Loss: {g_loss.item()}\")\n",
    "                break\n",
    "\n",
    "        # Update X_imputed with refined values\n",
    "        X_imputed_tensor = torch.tensor(X_imputed.values.astype(np.float32), dtype=torch.float32)\n",
    "        refined_data = generator(X_imputed_tensor).detach().numpy()\n",
    "        X_imputed.values[mask.values] = refined_data[mask.values]  # Only update missing values\n",
    "\n",
    "    return pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "# Impute missing values for each dataset separately\n",
    "X_external_imputed = impute_missing_values_with_multiple_passes(X_external)\n",
    "X_train_imputed = impute_missing_values_with_multiple_passes(X_train)\n",
    "X_validate_imputed = impute_missing_values_with_multiple_passes(X_validate)\n",
    "X_test_imputed = impute_missing_values_with_multiple_passes(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818233d3-e09a-41e1-ae33-e0b1ba6d8be1",
   "metadata": {},
   "source": [
    "# o03 Run GAN multiple times with more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "533af569-8ca5-491a-a367-4aa460846525",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 20:11:44,463 - INFO - \n",
      "--- Imputation Pass 1/3 ---\n",
      "\n",
      "2024-12-15 20:12:04,419 - INFO - Epoch 1/1000 - Generator Loss: 1.0747894048690796, Discriminator Loss: 1.30485999584198\n",
      "2024-12-15 20:12:20,620 - INFO - Epoch 2/1000 - Generator Loss: 1.54397451877594, Discriminator Loss: 0.44356492161750793\n",
      "2024-12-15 20:12:37,300 - INFO - Epoch 3/1000 - Generator Loss: 0.8169678449630737, Discriminator Loss: 0.49852806329727173\n",
      "2024-12-15 20:12:54,606 - INFO - Epoch 4/1000 - Generator Loss: 0.8335322141647339, Discriminator Loss: 0.7359015941619873\n",
      "2024-12-15 20:13:11,794 - INFO - Epoch 5/1000 - Generator Loss: 1.3846280574798584, Discriminator Loss: 0.7499973177909851\n",
      "2024-12-15 20:13:28,861 - INFO - Epoch 6/1000 - Generator Loss: 0.6470097303390503, Discriminator Loss: 0.6486812829971313\n",
      "2024-12-15 20:13:46,190 - INFO - Epoch 7/1000 - Generator Loss: 1.4880684614181519, Discriminator Loss: 0.43448740243911743\n",
      "2024-12-15 20:14:03,668 - INFO - Epoch 8/1000 - Generator Loss: 1.0345088243484497, Discriminator Loss: 0.45120638608932495\n",
      "2024-12-15 20:14:21,296 - INFO - Epoch 9/1000 - Generator Loss: 0.9472721219062805, Discriminator Loss: 0.5394315719604492\n",
      "2024-12-15 20:14:39,612 - INFO - Epoch 10/1000 - Generator Loss: 0.7618295550346375, Discriminator Loss: 0.5369678735733032\n",
      "2024-12-15 20:14:57,641 - INFO - Epoch 11/1000 - Generator Loss: 0.9371111989021301, Discriminator Loss: 0.393410861492157\n",
      "2024-12-15 20:15:15,733 - INFO - Epoch 12/1000 - Generator Loss: 2.228940963745117, Discriminator Loss: 0.3036448359489441\n",
      "2024-12-15 20:15:33,696 - INFO - Epoch 13/1000 - Generator Loss: 1.2237298488616943, Discriminator Loss: 0.7929604649543762\n",
      "2024-12-15 20:15:52,009 - INFO - Epoch 14/1000 - Generator Loss: 0.7750483751296997, Discriminator Loss: 0.7390104532241821\n",
      "2024-12-15 20:16:10,287 - INFO - Epoch 15/1000 - Generator Loss: 1.1052345037460327, Discriminator Loss: 0.7361457347869873\n",
      "2024-12-15 20:16:28,766 - INFO - Epoch 16/1000 - Generator Loss: 1.1156466007232666, Discriminator Loss: 0.4607899785041809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16 - Generator Loss: 1.1156466007232666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 20:16:32,487 - INFO - \n",
      "--- Imputation Pass 2/3 ---\n",
      "\n",
      "2024-12-15 20:16:50,043 - INFO - Epoch 1/1000 - Generator Loss: 0.31663355231285095, Discriminator Loss: 1.1050056219100952\n",
      "2024-12-15 20:17:06,616 - INFO - Epoch 2/1000 - Generator Loss: 0.7460512518882751, Discriminator Loss: 0.48876112699508667\n",
      "2024-12-15 20:17:23,888 - INFO - Epoch 3/1000 - Generator Loss: 0.4728429317474365, Discriminator Loss: 1.0725009441375732\n",
      "2024-12-15 20:17:40,678 - INFO - Epoch 4/1000 - Generator Loss: 0.8350852131843567, Discriminator Loss: 0.7614063620567322\n",
      "2024-12-15 20:17:57,264 - INFO - Epoch 5/1000 - Generator Loss: 0.8276912569999695, Discriminator Loss: 0.5790270566940308\n",
      "2024-12-15 20:18:15,041 - INFO - Epoch 6/1000 - Generator Loss: 0.5297325849533081, Discriminator Loss: 0.7068414092063904\n",
      "2024-12-15 20:18:32,163 - INFO - Epoch 7/1000 - Generator Loss: 1.3719007968902588, Discriminator Loss: 0.48656290769577026\n",
      "2024-12-15 20:18:49,714 - INFO - Epoch 8/1000 - Generator Loss: 0.6725568771362305, Discriminator Loss: 0.7024559378623962\n",
      "2024-12-15 20:19:07,266 - INFO - Epoch 9/1000 - Generator Loss: 0.856133759021759, Discriminator Loss: 0.7389219999313354\n",
      "2024-12-15 20:19:25,158 - INFO - Epoch 10/1000 - Generator Loss: 1.309644341468811, Discriminator Loss: 0.5384073853492737\n",
      "2024-12-15 20:19:44,005 - INFO - Epoch 11/1000 - Generator Loss: 1.0925068855285645, Discriminator Loss: 0.7787339687347412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11 - Generator Loss: 1.0925068855285645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 20:19:47,583 - INFO - \n",
      "--- Imputation Pass 3/3 ---\n",
      "\n",
      "2024-12-15 20:20:05,172 - INFO - Epoch 1/1000 - Generator Loss: 1.2086658477783203, Discriminator Loss: 0.4787372350692749\n",
      "2024-12-15 20:20:21,568 - INFO - Epoch 2/1000 - Generator Loss: 0.7568482160568237, Discriminator Loss: 1.2621774673461914\n",
      "2024-12-15 20:20:38,895 - INFO - Epoch 3/1000 - Generator Loss: 0.9534355998039246, Discriminator Loss: 0.5031024217605591\n",
      "2024-12-15 20:20:55,816 - INFO - Epoch 4/1000 - Generator Loss: 0.979882538318634, Discriminator Loss: 0.7164821624755859\n",
      "2024-12-15 20:21:13,340 - INFO - Epoch 5/1000 - Generator Loss: 0.8582409620285034, Discriminator Loss: 0.44867050647735596\n",
      "2024-12-15 20:21:31,137 - INFO - Epoch 6/1000 - Generator Loss: 0.45888277888298035, Discriminator Loss: 0.9068809151649475\n",
      "2024-12-15 20:21:48,630 - INFO - Epoch 7/1000 - Generator Loss: 1.1851071119308472, Discriminator Loss: 0.6434530019760132\n",
      "2024-12-15 20:22:06,910 - INFO - Epoch 8/1000 - Generator Loss: 1.0098916292190552, Discriminator Loss: 0.6202443838119507\n",
      "2024-12-15 20:22:25,012 - INFO - Epoch 9/1000 - Generator Loss: 0.934209406375885, Discriminator Loss: 0.7267705202102661\n",
      "2024-12-15 20:22:43,204 - INFO - Epoch 10/1000 - Generator Loss: 1.0392061471939087, Discriminator Loss: 0.8964101672172546\n",
      "2024-12-15 20:23:01,330 - INFO - Epoch 11/1000 - Generator Loss: 0.8112226128578186, Discriminator Loss: 0.6987131834030151\n",
      "2024-12-15 20:23:19,734 - INFO - Epoch 12/1000 - Generator Loss: 0.8646638989448547, Discriminator Loss: 0.7943069338798523\n",
      "2024-12-15 20:23:37,964 - INFO - Epoch 13/1000 - Generator Loss: 0.6218283772468567, Discriminator Loss: 0.5572236776351929\n",
      "2024-12-15 20:23:56,825 - INFO - Epoch 14/1000 - Generator Loss: 0.8068955540657043, Discriminator Loss: 0.539455771446228\n",
      "2024-12-15 20:24:16,100 - INFO - Epoch 15/1000 - Generator Loss: 0.9108386635780334, Discriminator Loss: 0.7231310606002808\n",
      "2024-12-15 20:24:35,048 - INFO - Epoch 16/1000 - Generator Loss: 0.8439058661460876, Discriminator Loss: 0.5835109949111938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16 - Generator Loss: 0.8439058661460876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 20:24:38,909 - INFO - \n",
      "--- Imputation Pass 1/3 ---\n",
      "\n",
      "2024-12-15 20:24:48,354 - INFO - Epoch 1/1000 - Generator Loss: 1.3271923065185547, Discriminator Loss: 0.563438892364502\n",
      "2024-12-15 20:24:56,159 - INFO - Epoch 2/1000 - Generator Loss: 1.1219958066940308, Discriminator Loss: 0.35019057989120483\n",
      "2024-12-15 20:25:04,933 - INFO - Epoch 3/1000 - Generator Loss: 0.7714702486991882, Discriminator Loss: 0.7006574869155884\n",
      "2024-12-15 20:25:13,150 - INFO - Epoch 4/1000 - Generator Loss: 2.10231351852417, Discriminator Loss: 0.5426560640335083\n",
      "2024-12-15 20:25:22,515 - INFO - Epoch 5/1000 - Generator Loss: 0.843502402305603, Discriminator Loss: 0.6731006503105164\n",
      "2024-12-15 20:25:30,733 - INFO - Epoch 6/1000 - Generator Loss: 1.686538577079773, Discriminator Loss: 0.39538073539733887\n",
      "2024-12-15 20:25:39,799 - INFO - Epoch 7/1000 - Generator Loss: 1.7751681804656982, Discriminator Loss: 0.25392577052116394\n",
      "2024-12-15 20:25:48,196 - INFO - Epoch 8/1000 - Generator Loss: 1.4901353120803833, Discriminator Loss: 0.4192412793636322\n",
      "2024-12-15 20:25:57,466 - INFO - Epoch 9/1000 - Generator Loss: 1.5437018871307373, Discriminator Loss: 0.39361321926116943\n",
      "2024-12-15 20:26:06,533 - INFO - Epoch 10/1000 - Generator Loss: 1.060163140296936, Discriminator Loss: 0.5665026903152466\n",
      "2024-12-15 20:26:15,509 - INFO - Epoch 11/1000 - Generator Loss: 1.9483795166015625, Discriminator Loss: 0.4980114698410034\n",
      "2024-12-15 20:26:25,061 - INFO - Epoch 12/1000 - Generator Loss: 1.5579874515533447, Discriminator Loss: 0.5754402279853821\n",
      "2024-12-15 20:26:33,853 - INFO - Epoch 13/1000 - Generator Loss: 1.4669846296310425, Discriminator Loss: 0.7027128338813782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 13 - Generator Loss: 1.4669846296310425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 20:26:35,680 - INFO - \n",
      "--- Imputation Pass 2/3 ---\n",
      "\n",
      "2024-12-15 20:26:45,042 - INFO - Epoch 1/1000 - Generator Loss: 0.45326852798461914, Discriminator Loss: 0.7565370202064514\n",
      "2024-12-15 20:26:53,025 - INFO - Epoch 2/1000 - Generator Loss: 2.9247403144836426, Discriminator Loss: 0.5761120915412903\n",
      "2024-12-15 20:27:01,765 - INFO - Epoch 3/1000 - Generator Loss: 0.7050061225891113, Discriminator Loss: 0.6115669012069702\n",
      "2024-12-15 20:27:10,381 - INFO - Epoch 4/1000 - Generator Loss: 1.405816674232483, Discriminator Loss: 0.900619387626648\n",
      "2024-12-15 20:27:19,103 - INFO - Epoch 5/1000 - Generator Loss: 1.6139945983886719, Discriminator Loss: 0.45358848571777344\n",
      "2024-12-15 20:27:28,125 - INFO - Epoch 6/1000 - Generator Loss: 1.526914119720459, Discriminator Loss: 0.3692247271537781\n",
      "2024-12-15 20:27:36,922 - INFO - Epoch 7/1000 - Generator Loss: 1.0742970705032349, Discriminator Loss: 0.5782427787780762\n",
      "2024-12-15 20:27:46,349 - INFO - Epoch 8/1000 - Generator Loss: 1.525931715965271, Discriminator Loss: 0.6040858030319214\n",
      "2024-12-15 20:27:55,010 - INFO - Epoch 9/1000 - Generator Loss: 1.617024540901184, Discriminator Loss: 0.4215008616447449\n",
      "2024-12-15 20:28:04,255 - INFO - Epoch 10/1000 - Generator Loss: 1.7924946546554565, Discriminator Loss: 1.2026063203811646\n",
      "2024-12-15 20:28:12,918 - INFO - Epoch 11/1000 - Generator Loss: 1.5421669483184814, Discriminator Loss: 1.8833608627319336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 11 - Generator Loss: 1.5421669483184814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 20:28:14,762 - INFO - \n",
      "--- Imputation Pass 3/3 ---\n",
      "\n",
      "2024-12-15 20:28:23,673 - INFO - Epoch 1/1000 - Generator Loss: 3.3230063915252686, Discriminator Loss: 3.0241923332214355\n",
      "2024-12-15 20:28:32,347 - INFO - Epoch 2/1000 - Generator Loss: 1.6814552545547485, Discriminator Loss: 0.6391303539276123\n",
      "2024-12-15 20:28:40,409 - INFO - Epoch 3/1000 - Generator Loss: 1.0187832117080688, Discriminator Loss: 0.5255692601203918\n",
      "2024-12-15 20:28:49,508 - INFO - Epoch 4/1000 - Generator Loss: 0.9439082741737366, Discriminator Loss: 0.527639627456665\n",
      "2024-12-15 20:28:57,997 - INFO - Epoch 5/1000 - Generator Loss: 1.2998247146606445, Discriminator Loss: 0.6741635799407959\n",
      "2024-12-15 20:29:07,186 - INFO - Epoch 6/1000 - Generator Loss: 0.7202398777008057, Discriminator Loss: 0.5032034516334534\n",
      "2024-12-15 20:29:15,496 - INFO - Epoch 7/1000 - Generator Loss: 1.1760680675506592, Discriminator Loss: 0.34310466051101685\n",
      "2024-12-15 20:29:24,729 - INFO - Epoch 8/1000 - Generator Loss: 0.9272780418395996, Discriminator Loss: 0.6637818813323975\n",
      "2024-12-15 20:29:33,439 - INFO - Epoch 9/1000 - Generator Loss: 1.8542221784591675, Discriminator Loss: 0.5818492770195007\n",
      "2024-12-15 20:29:42,383 - INFO - Epoch 10/1000 - Generator Loss: 1.2498430013656616, Discriminator Loss: 0.5457944273948669\n",
      "2024-12-15 20:29:51,326 - INFO - Epoch 11/1000 - Generator Loss: 1.5474071502685547, Discriminator Loss: 0.3934781849384308\n",
      "2024-12-15 20:30:00,322 - INFO - Epoch 12/1000 - Generator Loss: 1.2610728740692139, Discriminator Loss: 0.5353789329528809\n",
      "2024-12-15 20:30:09,813 - INFO - Epoch 13/1000 - Generator Loss: 1.6805287599563599, Discriminator Loss: 0.38760387897491455\n",
      "2024-12-15 20:30:18,606 - INFO - Epoch 14/1000 - Generator Loss: 2.0161139965057373, Discriminator Loss: 0.2332596778869629\n",
      "2024-12-15 20:30:28,232 - INFO - Epoch 15/1000 - Generator Loss: 1.1698999404907227, Discriminator Loss: 0.36591440439224243\n",
      "2024-12-15 20:30:37,955 - INFO - Epoch 16/1000 - Generator Loss: 0.9700429439544678, Discriminator Loss: 0.4518364667892456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 16 - Generator Loss: 0.9700429439544678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 20:30:39,910 - INFO - \n",
      "--- Imputation Pass 1/3 ---\n",
      "\n",
      "2024-12-15 20:30:41,159 - INFO - Epoch 1/1000 - Generator Loss: 2.196349859237671, Discriminator Loss: 0.1490233689546585\n",
      "2024-12-15 20:30:42,190 - INFO - Epoch 2/1000 - Generator Loss: 2.130969762802124, Discriminator Loss: 0.23882807791233063\n",
      "2024-12-15 20:30:43,157 - INFO - Epoch 3/1000 - Generator Loss: 1.4125478267669678, Discriminator Loss: 0.3225172758102417\n",
      "2024-12-15 20:30:44,136 - INFO - Epoch 4/1000 - Generator Loss: 6.5022711753845215, Discriminator Loss: 3.0890088081359863\n",
      "2024-12-15 20:30:45,101 - INFO - Epoch 5/1000 - Generator Loss: 0.9934859871864319, Discriminator Loss: 0.8561071157455444\n",
      "2024-12-15 20:30:46,071 - INFO - Epoch 6/1000 - Generator Loss: 2.848104238510132, Discriminator Loss: 0.6010442972183228\n",
      "2024-12-15 20:30:47,041 - INFO - Epoch 7/1000 - Generator Loss: 4.104102611541748, Discriminator Loss: 1.798781156539917\n",
      "2024-12-15 20:30:47,996 - INFO - Epoch 8/1000 - Generator Loss: 1.3882927894592285, Discriminator Loss: 0.576575756072998\n",
      "2024-12-15 20:30:48,962 - INFO - Epoch 9/1000 - Generator Loss: 0.4608694612979889, Discriminator Loss: 2.007636070251465\n",
      "2024-12-15 20:30:49,916 - INFO - Epoch 10/1000 - Generator Loss: 2.309044361114502, Discriminator Loss: 0.3679569959640503\n",
      "2024-12-15 20:30:50,881 - INFO - Epoch 11/1000 - Generator Loss: 5.970874309539795, Discriminator Loss: 0.6095890998840332\n",
      "2024-12-15 20:30:51,848 - INFO - Epoch 12/1000 - Generator Loss: 2.8560142517089844, Discriminator Loss: 1.4017252922058105\n",
      "2024-12-15 20:30:53,020 - INFO - Epoch 13/1000 - Generator Loss: 0.7679506540298462, Discriminator Loss: 0.9926981925964355\n",
      "2024-12-15 20:30:54,219 - INFO - Epoch 14/1000 - Generator Loss: 0.5324810147285461, Discriminator Loss: 1.0979738235473633\n",
      "2024-12-15 20:30:55,422 - INFO - Epoch 15/1000 - Generator Loss: 3.8109676837921143, Discriminator Loss: 1.6304552555084229\n",
      "2024-12-15 20:30:56,620 - INFO - Epoch 16/1000 - Generator Loss: 0.7612450122833252, Discriminator Loss: 0.5811722278594971\n",
      "2024-12-15 20:30:57,613 - INFO - Epoch 17/1000 - Generator Loss: 1.3470728397369385, Discriminator Loss: 0.5471487045288086\n",
      "2024-12-15 20:30:58,618 - INFO - Epoch 18/1000 - Generator Loss: 2.9207186698913574, Discriminator Loss: 1.6250834465026855\n",
      "2024-12-15 20:30:59,619 - INFO - Epoch 19/1000 - Generator Loss: 2.6762821674346924, Discriminator Loss: 1.741390585899353\n",
      "2024-12-15 20:30:59,840 - INFO - \n",
      "--- Imputation Pass 2/3 ---\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19 - Generator Loss: 2.6762821674346924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 20:31:00,947 - INFO - Epoch 1/1000 - Generator Loss: 6.511636734008789, Discriminator Loss: 3.1273419857025146\n",
      "2024-12-15 20:31:01,926 - INFO - Epoch 2/1000 - Generator Loss: 1.7458586692810059, Discriminator Loss: 0.2569155991077423\n",
      "2024-12-15 20:31:02,937 - INFO - Epoch 3/1000 - Generator Loss: 2.7525248527526855, Discriminator Loss: 0.4538579285144806\n",
      "2024-12-15 20:31:03,901 - INFO - Epoch 4/1000 - Generator Loss: 2.6167635917663574, Discriminator Loss: 1.566697597503662\n",
      "2024-12-15 20:31:04,871 - INFO - Epoch 5/1000 - Generator Loss: 2.7925329208374023, Discriminator Loss: 1.7390623092651367\n",
      "2024-12-15 20:31:05,828 - INFO - Epoch 6/1000 - Generator Loss: 1.523999571800232, Discriminator Loss: 1.9946774244308472\n",
      "2024-12-15 20:31:06,798 - INFO - Epoch 7/1000 - Generator Loss: 2.475281000137329, Discriminator Loss: 0.6025263667106628\n",
      "2024-12-15 20:31:07,770 - INFO - Epoch 8/1000 - Generator Loss: 0.7063435912132263, Discriminator Loss: 0.9137990474700928\n",
      "2024-12-15 20:31:08,879 - INFO - Epoch 9/1000 - Generator Loss: 1.2144043445587158, Discriminator Loss: 0.8232359886169434\n",
      "2024-12-15 20:31:10,047 - INFO - Epoch 10/1000 - Generator Loss: 1.5144708156585693, Discriminator Loss: 0.8142440319061279\n",
      "2024-12-15 20:31:11,217 - INFO - Epoch 11/1000 - Generator Loss: 1.1786859035491943, Discriminator Loss: 0.4495733082294464\n",
      "2024-12-15 20:31:12,397 - INFO - Epoch 12/1000 - Generator Loss: 2.029851198196411, Discriminator Loss: 1.7533776760101318\n",
      "2024-12-15 20:31:13,430 - INFO - Epoch 13/1000 - Generator Loss: 1.0593039989471436, Discriminator Loss: 0.4267275929450989\n",
      "2024-12-15 20:31:14,434 - INFO - Epoch 14/1000 - Generator Loss: 2.8042149543762207, Discriminator Loss: 1.8557566404342651\n",
      "2024-12-15 20:31:15,453 - INFO - Epoch 15/1000 - Generator Loss: 1.2072898149490356, Discriminator Loss: 0.6757181882858276\n",
      "2024-12-15 20:31:16,473 - INFO - Epoch 16/1000 - Generator Loss: 1.3690844774246216, Discriminator Loss: 0.43148934841156006\n",
      "2024-12-15 20:31:17,513 - INFO - Epoch 17/1000 - Generator Loss: 2.8162291049957275, Discriminator Loss: 1.6467726230621338\n",
      "2024-12-15 20:31:18,535 - INFO - Epoch 18/1000 - Generator Loss: 1.2624757289886475, Discriminator Loss: 0.8207322955131531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18 - Generator Loss: 1.2624757289886475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 20:31:18,757 - INFO - \n",
      "--- Imputation Pass 3/3 ---\n",
      "\n",
      "2024-12-15 20:31:19,862 - INFO - Epoch 1/1000 - Generator Loss: 2.3089189529418945, Discriminator Loss: 0.1619698703289032\n",
      "2024-12-15 20:31:20,839 - INFO - Epoch 2/1000 - Generator Loss: 1.7068437337875366, Discriminator Loss: 0.22026391327381134\n",
      "2024-12-15 20:31:21,831 - INFO - Epoch 3/1000 - Generator Loss: 5.350123405456543, Discriminator Loss: 2.3201537132263184\n",
      "2024-12-15 20:31:22,827 - INFO - Epoch 4/1000 - Generator Loss: 3.1551671028137207, Discriminator Loss: 1.4398109912872314\n",
      "2024-12-15 20:31:23,794 - INFO - Epoch 5/1000 - Generator Loss: 2.2355706691741943, Discriminator Loss: 0.8548267483711243\n",
      "2024-12-15 20:31:24,910 - INFO - Epoch 6/1000 - Generator Loss: 1.7704933881759644, Discriminator Loss: 0.8258506059646606\n",
      "2024-12-15 20:31:26,095 - INFO - Epoch 7/1000 - Generator Loss: 1.0017517805099487, Discriminator Loss: 1.0646023750305176\n",
      "2024-12-15 20:31:27,261 - INFO - Epoch 8/1000 - Generator Loss: 0.7478488087654114, Discriminator Loss: 0.6261159181594849\n",
      "2024-12-15 20:31:28,428 - INFO - Epoch 9/1000 - Generator Loss: 1.266525387763977, Discriminator Loss: 0.5214946269989014\n",
      "2024-12-15 20:31:29,392 - INFO - Epoch 10/1000 - Generator Loss: 1.4181129932403564, Discriminator Loss: 0.4389122724533081\n",
      "2024-12-15 20:31:30,363 - INFO - Epoch 11/1000 - Generator Loss: 2.924696207046509, Discriminator Loss: 0.3673476576805115\n",
      "2024-12-15 20:31:31,331 - INFO - Epoch 12/1000 - Generator Loss: 1.297505259513855, Discriminator Loss: 0.5224268436431885\n",
      "2024-12-15 20:31:32,322 - INFO - Epoch 13/1000 - Generator Loss: 1.2031300067901611, Discriminator Loss: 0.7264420986175537\n",
      "2024-12-15 20:31:33,343 - INFO - Epoch 14/1000 - Generator Loss: 0.9331191778182983, Discriminator Loss: 1.2747983932495117\n",
      "2024-12-15 20:31:34,342 - INFO - Epoch 15/1000 - Generator Loss: 1.102726936340332, Discriminator Loss: 0.7699148654937744\n",
      "2024-12-15 20:31:35,331 - INFO - Epoch 16/1000 - Generator Loss: 2.871541738510132, Discriminator Loss: 1.5317597389221191\n",
      "2024-12-15 20:31:36,363 - INFO - Epoch 17/1000 - Generator Loss: 0.8525388240814209, Discriminator Loss: 0.7836399674415588\n",
      "2024-12-15 20:31:37,374 - INFO - Epoch 18/1000 - Generator Loss: 2.772284984588623, Discriminator Loss: 1.5661404132843018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18 - Generator Loss: 2.772284984588623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 20:31:37,617 - INFO - \n",
      "--- Imputation Pass 1/3 ---\n",
      "\n",
      "2024-12-15 20:31:38,727 - INFO - Epoch 1/1000 - Generator Loss: 2.1367287635803223, Discriminator Loss: 0.14177684485912323\n",
      "2024-12-15 20:31:39,702 - INFO - Epoch 2/1000 - Generator Loss: 1.9269686937332153, Discriminator Loss: 0.14973507821559906\n",
      "2024-12-15 20:31:40,830 - INFO - Epoch 3/1000 - Generator Loss: 3.029080629348755, Discriminator Loss: 0.12929172813892365\n",
      "2024-12-15 20:31:42,018 - INFO - Epoch 4/1000 - Generator Loss: 6.7752580642700195, Discriminator Loss: 2.547776937484741\n",
      "2024-12-15 20:31:43,227 - INFO - Epoch 5/1000 - Generator Loss: 2.8426356315612793, Discriminator Loss: 1.428961992263794\n",
      "2024-12-15 20:31:44,401 - INFO - Epoch 6/1000 - Generator Loss: 3.743220329284668, Discriminator Loss: 0.549566924571991\n",
      "2024-12-15 20:31:45,372 - INFO - Epoch 7/1000 - Generator Loss: 1.5729196071624756, Discriminator Loss: 0.31706130504608154\n",
      "2024-12-15 20:31:46,354 - INFO - Epoch 8/1000 - Generator Loss: 2.1396634578704834, Discriminator Loss: 0.5007075667381287\n",
      "2024-12-15 20:31:47,310 - INFO - Epoch 9/1000 - Generator Loss: 1.0269593000411987, Discriminator Loss: 1.2127692699432373\n",
      "2024-12-15 20:31:48,277 - INFO - Epoch 10/1000 - Generator Loss: 1.4518262147903442, Discriminator Loss: 0.8076209425926208\n",
      "2024-12-15 20:31:49,236 - INFO - Epoch 11/1000 - Generator Loss: 0.9240328669548035, Discriminator Loss: 0.8659354448318481\n",
      "2024-12-15 20:31:50,214 - INFO - Epoch 12/1000 - Generator Loss: 1.8909223079681396, Discriminator Loss: 0.6147177815437317\n",
      "2024-12-15 20:31:51,194 - INFO - Epoch 13/1000 - Generator Loss: 1.5431859493255615, Discriminator Loss: 0.5310690999031067\n",
      "2024-12-15 20:31:52,200 - INFO - Epoch 14/1000 - Generator Loss: 0.4584595561027527, Discriminator Loss: 0.9546041488647461\n",
      "2024-12-15 20:31:53,245 - INFO - Epoch 15/1000 - Generator Loss: 0.779712438583374, Discriminator Loss: 0.7241203784942627\n",
      "2024-12-15 20:31:54,258 - INFO - Epoch 16/1000 - Generator Loss: 0.8168584108352661, Discriminator Loss: 0.6614311337471008\n",
      "2024-12-15 20:31:55,297 - INFO - Epoch 17/1000 - Generator Loss: 1.2373193502426147, Discriminator Loss: 0.52457594871521\n",
      "2024-12-15 20:31:56,433 - INFO - Epoch 18/1000 - Generator Loss: 2.599384069442749, Discriminator Loss: 1.5588654279708862\n",
      "2024-12-15 20:31:57,701 - INFO - Epoch 19/1000 - Generator Loss: 0.6988884210586548, Discriminator Loss: 0.6308990716934204\n",
      "2024-12-15 20:31:58,998 - INFO - Epoch 20/1000 - Generator Loss: 1.3439137935638428, Discriminator Loss: 0.6217074394226074\n",
      "2024-12-15 20:32:00,303 - INFO - Epoch 21/1000 - Generator Loss: 0.8793175220489502, Discriminator Loss: 0.6735306978225708\n",
      "2024-12-15 20:32:01,432 - INFO - Epoch 22/1000 - Generator Loss: 0.6845864057540894, Discriminator Loss: 0.6169106960296631\n",
      "2024-12-15 20:32:02,535 - INFO - Epoch 23/1000 - Generator Loss: 2.072948932647705, Discriminator Loss: 0.562394380569458\n",
      "2024-12-15 20:32:03,662 - INFO - Epoch 24/1000 - Generator Loss: 1.3399971723556519, Discriminator Loss: 0.8459522724151611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 24 - Generator Loss: 1.3399971723556519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 20:32:03,881 - INFO - \n",
      "--- Imputation Pass 2/3 ---\n",
      "\n",
      "2024-12-15 20:32:04,986 - INFO - Epoch 1/1000 - Generator Loss: 2.486748218536377, Discriminator Loss: 0.1497921347618103\n",
      "2024-12-15 20:32:05,959 - INFO - Epoch 2/1000 - Generator Loss: 1.8400861024856567, Discriminator Loss: 0.2548302710056305\n",
      "2024-12-15 20:32:06,952 - INFO - Epoch 3/1000 - Generator Loss: 1.2466868162155151, Discriminator Loss: 0.4656599164009094\n",
      "2024-12-15 20:32:07,921 - INFO - Epoch 4/1000 - Generator Loss: 3.7990012168884277, Discriminator Loss: 1.189254641532898\n",
      "2024-12-15 20:32:08,900 - INFO - Epoch 5/1000 - Generator Loss: 3.1964035034179688, Discriminator Loss: 0.8369903564453125\n",
      "2024-12-15 20:32:09,858 - INFO - Epoch 6/1000 - Generator Loss: 1.4493598937988281, Discriminator Loss: 0.43827635049819946\n",
      "2024-12-15 20:32:10,822 - INFO - Epoch 7/1000 - Generator Loss: 1.3341928720474243, Discriminator Loss: 1.3142163753509521\n",
      "2024-12-15 20:32:11,776 - INFO - Epoch 8/1000 - Generator Loss: 1.126966953277588, Discriminator Loss: 1.9760438203811646\n",
      "2024-12-15 20:32:12,896 - INFO - Epoch 9/1000 - Generator Loss: 2.0847651958465576, Discriminator Loss: 0.33476486802101135\n",
      "2024-12-15 20:32:14,077 - INFO - Epoch 10/1000 - Generator Loss: 1.7182343006134033, Discriminator Loss: 2.0656092166900635\n",
      "2024-12-15 20:32:15,245 - INFO - Epoch 11/1000 - Generator Loss: 0.5002090334892273, Discriminator Loss: 1.5487914085388184\n",
      "2024-12-15 20:32:16,448 - INFO - Epoch 12/1000 - Generator Loss: 1.6551893949508667, Discriminator Loss: 0.5277847051620483\n",
      "2024-12-15 20:32:17,466 - INFO - Epoch 13/1000 - Generator Loss: 1.1930654048919678, Discriminator Loss: 2.3757433891296387\n",
      "2024-12-15 20:32:18,463 - INFO - Epoch 14/1000 - Generator Loss: 0.6233274936676025, Discriminator Loss: 1.055088758468628\n",
      "2024-12-15 20:32:19,473 - INFO - Epoch 15/1000 - Generator Loss: 1.5847432613372803, Discriminator Loss: 0.6724399328231812\n",
      "2024-12-15 20:32:20,485 - INFO - Epoch 16/1000 - Generator Loss: 0.8801246285438538, Discriminator Loss: 0.5492309331893921\n",
      "2024-12-15 20:32:21,522 - INFO - Epoch 17/1000 - Generator Loss: 0.7822819352149963, Discriminator Loss: 0.7115249037742615\n",
      "2024-12-15 20:32:22,564 - INFO - Epoch 18/1000 - Generator Loss: 0.7612653374671936, Discriminator Loss: 0.5698195695877075\n",
      "2024-12-15 20:32:23,657 - INFO - Epoch 19/1000 - Generator Loss: 0.5026599168777466, Discriminator Loss: 1.7783362865447998\n",
      "2024-12-15 20:32:24,708 - INFO - Epoch 20/1000 - Generator Loss: 1.2035969495773315, Discriminator Loss: 1.5757575035095215\n",
      "2024-12-15 20:32:25,778 - INFO - Epoch 21/1000 - Generator Loss: 0.8624267578125, Discriminator Loss: 0.5475198030471802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 21 - Generator Loss: 0.8624267578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 20:32:25,999 - INFO - \n",
      "--- Imputation Pass 3/3 ---\n",
      "\n",
      "2024-12-15 20:32:27,116 - INFO - Epoch 1/1000 - Generator Loss: 4.024667739868164, Discriminator Loss: 1.3190240859985352\n",
      "2024-12-15 20:32:28,116 - INFO - Epoch 2/1000 - Generator Loss: 4.638310432434082, Discriminator Loss: 1.074483871459961\n",
      "2024-12-15 20:32:29,292 - INFO - Epoch 3/1000 - Generator Loss: 2.920468807220459, Discriminator Loss: 0.11640326678752899\n",
      "2024-12-15 20:32:30,480 - INFO - Epoch 4/1000 - Generator Loss: 2.711681842803955, Discriminator Loss: 0.192236989736557\n",
      "2024-12-15 20:32:31,650 - INFO - Epoch 5/1000 - Generator Loss: 2.3497092723846436, Discriminator Loss: 0.28061193227767944\n",
      "2024-12-15 20:32:32,761 - INFO - Epoch 6/1000 - Generator Loss: 2.023092269897461, Discriminator Loss: 2.508610725402832\n",
      "2024-12-15 20:32:33,769 - INFO - Epoch 7/1000 - Generator Loss: 1.4030590057373047, Discriminator Loss: 0.516247034072876\n",
      "2024-12-15 20:32:34,730 - INFO - Epoch 8/1000 - Generator Loss: 2.757786989212036, Discriminator Loss: 0.8671324849128723\n",
      "2024-12-15 20:32:35,699 - INFO - Epoch 9/1000 - Generator Loss: 0.6989564895629883, Discriminator Loss: 1.96499764919281\n",
      "2024-12-15 20:32:36,672 - INFO - Epoch 10/1000 - Generator Loss: 1.8769359588623047, Discriminator Loss: 0.6755357980728149\n",
      "2024-12-15 20:32:37,647 - INFO - Epoch 11/1000 - Generator Loss: 0.984504759311676, Discriminator Loss: 0.7526389360427856\n",
      "2024-12-15 20:32:38,629 - INFO - Epoch 12/1000 - Generator Loss: 0.9730243682861328, Discriminator Loss: 3.4975860118865967\n",
      "2024-12-15 20:32:39,630 - INFO - Epoch 13/1000 - Generator Loss: 1.7002151012420654, Discriminator Loss: 0.47221434116363525\n",
      "2024-12-15 20:32:40,647 - INFO - Epoch 14/1000 - Generator Loss: 1.3966307640075684, Discriminator Loss: 0.8585711717605591\n",
      "2024-12-15 20:32:41,670 - INFO - Epoch 15/1000 - Generator Loss: 1.086555004119873, Discriminator Loss: 0.7320555448532104\n",
      "2024-12-15 20:32:42,700 - INFO - Epoch 16/1000 - Generator Loss: 1.9701697826385498, Discriminator Loss: 0.2876513600349426\n",
      "2024-12-15 20:32:43,751 - INFO - Epoch 17/1000 - Generator Loss: 1.143664002418518, Discriminator Loss: 0.6200908422470093\n",
      "2024-12-15 20:32:44,986 - INFO - Epoch 18/1000 - Generator Loss: 1.0030068159103394, Discriminator Loss: 2.3440051078796387\n",
      "2024-12-15 20:32:46,251 - INFO - Epoch 19/1000 - Generator Loss: 1.1578110456466675, Discriminator Loss: 0.78706955909729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19 - Generator Loss: 1.1578110456466675\n"
     ]
    }
   ],
   "source": [
    "# Custom Dataset class for PyTorch\n",
    "def prepare_dataset(X):\n",
    "    class CustomDataset(Dataset):\n",
    "        def __init__(self, data):\n",
    "            # Ensure data is converted to numeric type to avoid object type errors\n",
    "            self.data = torch.tensor(data.astype(np.float32), dtype=torch.float32)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self.data[idx]\n",
    "    \n",
    "    return CustomDataset(X)\n",
    "\n",
    "# Define Generator model\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "# Define Discriminator model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "# GAN Imputation Function with Multiple Passes and Early Stopping\n",
    "def impute_missing_values_with_multiple_passes(X, num_passes=3, epochs=1000, batch_size=64, learning_rate=0.0002, patience=10):\n",
    "    # Prepare data and mask for missing values\n",
    "    X_imputed = X.copy()\n",
    "    mask = X_imputed.isna()\n",
    "    X_imputed.fillna(0, inplace=True)\n",
    "    \n",
    "    # Input dimension\n",
    "    input_dim = X.shape[1]\n",
    "\n",
    "    # Multiple passes\n",
    "    for pass_num in range(num_passes):\n",
    "        logging.info(f\"\\n--- Imputation Pass {pass_num + 1}/{num_passes} ---\\n\")\n",
    "        \n",
    "        # Prepare dataset and dataloader\n",
    "        dataset = prepare_dataset(X_imputed.values)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        # Initialize Generator and Discriminator\n",
    "        generator = Generator(input_dim)\n",
    "        discriminator = Discriminator(input_dim)\n",
    "\n",
    "        # Optimizers\n",
    "        optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "        optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Loss function\n",
    "        adversarial_loss = nn.BCELoss()\n",
    "\n",
    "        best_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for i, real_data in enumerate(dataloader):\n",
    "                # Adversarial ground truths\n",
    "                valid = torch.ones(real_data.size(0), 1)\n",
    "                fake = torch.zeros(real_data.size(0), 1)\n",
    "\n",
    "                # Train Generator\n",
    "                optimizer_G.zero_grad()\n",
    "\n",
    "                # Generate data and replace missing values with generated data\n",
    "                gen_data = generator(real_data)\n",
    "                gen_data[mask.iloc[i * batch_size:(i + 1) * batch_size].values] = real_data[mask.iloc[i * batch_size:(i + 1) * batch_size].values]\n",
    "\n",
    "                # Generator loss\n",
    "                g_loss = adversarial_loss(discriminator(gen_data), valid)\n",
    "                g_loss.backward()\n",
    "                optimizer_G.step()\n",
    "\n",
    "                # Train Discriminator\n",
    "                optimizer_D.zero_grad()\n",
    "\n",
    "                # Real and fake losses\n",
    "                real_loss = adversarial_loss(discriminator(real_data), valid)\n",
    "                fake_loss = adversarial_loss(discriminator(gen_data.detach()), fake)\n",
    "                d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "                d_loss.backward()\n",
    "                optimizer_D.step()\n",
    "\n",
    "            # Display progress\n",
    "            logging.info(f\"Epoch {epoch + 1}/{epochs} - Generator Loss: {g_loss.item()}, Discriminator Loss: {d_loss.item()}\")\n",
    "\n",
    "            # Early stopping\n",
    "            if g_loss.item() < best_loss:\n",
    "                best_loss = g_loss.item()\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} - Generator Loss: {g_loss.item()}\")\n",
    "                break\n",
    "\n",
    "        # Update X_imputed with refined values\n",
    "        X_imputed_tensor = torch.tensor(X_imputed.values.astype(np.float32), dtype=torch.float32)\n",
    "        refined_data = generator(X_imputed_tensor).detach().numpy()\n",
    "        X_imputed.values[mask.values] = refined_data[mask.values]  # Only update missing values\n",
    "\n",
    "    return pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "# Impute missing values for each dataset separately\n",
    "X_external_imputed = impute_missing_values_with_multiple_passes(X_external)\n",
    "X_train_imputed = impute_missing_values_with_multiple_passes(X_train)\n",
    "X_validate_imputed = impute_missing_values_with_multiple_passes(X_validate)\n",
    "X_test_imputed = impute_missing_values_with_multiple_passes(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbac505-28a6-42b0-ba5e-b62c057d8cf3",
   "metadata": {},
   "source": [
    "# Save dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "974417b2-ddb0-4b83-a135-7e5717e726e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 missing values in external dataset\n",
      "\n",
      "0 missing values in train dataset\n",
      "\n",
      "0 missing values in validation dataset\n",
      "\n",
      "0 missing values in test dataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "external_total_missing_values = X_external_imputed.isna().sum().sum()\n",
    "train_total_missing_values = X_train_imputed.isna().sum().sum()\n",
    "validation_total_missing_values = X_validate_imputed.isna().sum().sum()\n",
    "test_total_missing_values = X_test_imputed.isna().sum().sum()\n",
    "print(external_total_missing_values, 'missing values in external dataset\\n')\n",
    "print(train_total_missing_values, 'missing values in train dataset\\n')\n",
    "print(validation_total_missing_values, 'missing values in validation dataset\\n')\n",
    "print(test_total_missing_values, 'missing values in test dataset\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afd7711a-d7a0-427c-8f04-4fc318d32961",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 20:46:06,897 - INFO - Resetting index for X_external\n",
      "2024-12-15 20:46:06,959 - INFO - Resetting index for X_external_imputed\n",
      "2024-12-15 20:46:07,014 - INFO - Resetting index for X_train\n",
      "2024-12-15 20:46:07,047 - INFO - Resetting index for X_train_imputed\n",
      "2024-12-15 20:46:07,079 - INFO - Resetting index for X_validate\n",
      "2024-12-15 20:46:07,089 - INFO - Resetting index for X_validate_imputed\n",
      "2024-12-15 20:46:07,094 - INFO - Resetting index for X_test\n",
      "2024-12-15 20:46:07,099 - INFO - Resetting index for X_test_imputed\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataframe in order to replace ages and race with the original ones.\n",
    "# Reset indices and log information\n",
    "logging.info(\"Resetting index for X_external\")\n",
    "X_external = X_external.reset_index(drop=True)\n",
    "\n",
    "logging.info(\"Resetting index for X_external_imputed\")\n",
    "X_external_imputed = X_external_imputed.reset_index(drop=True)\n",
    "\n",
    "logging.info(\"Resetting index for X_train\")\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "\n",
    "logging.info(\"Resetting index for X_train_imputed\")\n",
    "X_train_imputed = X_train_imputed.reset_index(drop=True)\n",
    "\n",
    "logging.info(\"Resetting index for X_validate\")\n",
    "X_validate = X_validate.reset_index(drop=True)\n",
    "\n",
    "logging.info(\"Resetting index for X_validate_imputed\")\n",
    "X_validate_imputed = X_validate_imputed.reset_index(drop=True)\n",
    "\n",
    "logging.info(\"Resetting index for X_test\")\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "\n",
    "logging.info(\"Resetting index for X_test_imputed\")\n",
    "X_test_imputed = X_test_imputed.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6cdd8a1-e7a7-4604-8ded-f9e741eebcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 20:46:09,179 - INFO - External replacement completed.\n"
     ]
    }
   ],
   "source": [
    "# List of columns to replace: 'age' and columns starting with 'race_'\n",
    "columns_to_replace = ['age'] + [col for col in X_external.columns if col.startswith('race_')]\n",
    "\n",
    "# Function to replace specified columns in the imputed dataframe with original data\n",
    "def replace_columns(imputed_df, original_df, columns):\n",
    "    imputed_df[columns] = original_df[columns]\n",
    "    return imputed_df\n",
    "\n",
    "X_external_imputed = replace_columns(X_external_imputed, X_external, columns_to_replace)\n",
    "logging.info(\"External replacement completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7a70d77-2d6c-402a-af08-bcad0f6ad027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 20:46:10,462 - INFO - Train replacement completed.\n"
     ]
    }
   ],
   "source": [
    "# List of columns to replace: 'age' and columns starting with 'race_'\n",
    "columns_to_replace = ['age'] + [col for col in X_train.columns if col.startswith('race_')]\n",
    "\n",
    "# Function to replace specified columns in the imputed dataframe with original data\n",
    "def replace_columns(imputed_df, original_df, columns):\n",
    "    imputed_df[columns] = original_df[columns]\n",
    "    return imputed_df\n",
    "\n",
    "\n",
    "X_train_imputed = replace_columns(X_train_imputed, X_train, columns_to_replace)\n",
    "logging.info(\"Train replacement completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48721be6-08c3-4561-bdd1-084b02265bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 20:46:11,067 - INFO - Validate replacement completed.\n"
     ]
    }
   ],
   "source": [
    "# List of columns to replace: 'age' and columns starting with 'race_'\n",
    "columns_to_replace = ['age'] + [col for col in X_validate.columns if col.startswith('race_')]\n",
    "\n",
    "# Function to replace specified columns in the imputed dataframe with original data\n",
    "def replace_columns(imputed_df, original_df, columns):\n",
    "    imputed_df[columns] = original_df[columns]\n",
    "    return imputed_df\n",
    "\n",
    "\n",
    "X_validate_imputed = replace_columns(X_validate_imputed, X_validate, columns_to_replace)\n",
    "logging.info(\"Validate replacement completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e4cf2c6-5da7-4006-aadf-bd7330a563aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 20:46:11,335 - INFO - Test replacement completed.\n"
     ]
    }
   ],
   "source": [
    "# List of columns to replace: 'age' and columns starting with 'race_'\n",
    "columns_to_replace = ['age'] + [col for col in X_test.columns if col.startswith('race_')]\n",
    "\n",
    "# Function to replace specified columns in the imputed dataframe with original data\n",
    "def replace_columns(imputed_df, original_df, columns):\n",
    "    imputed_df[columns] = original_df[columns]\n",
    "    return imputed_df\n",
    "\n",
    "\n",
    "X_test_imputed = replace_columns(X_test_imputed, X_test, columns_to_replace)\n",
    "logging.info(\"Test replacement completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae9e1e27-02f1-46a0-a457-3384d3876b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 20:46:14,234 - INFO - Save path set to: ../CSV/exports/impute/o1_GAN/o01/\n",
      "2024-12-15 20:46:14,236 - INFO - Directory already exists: ../CSV/exports/impute/o1_GAN/o01/\n",
      "2024-12-15 20:46:14,237 - INFO - Saving X_external_imputed to ../CSV/exports/impute/o1_GAN/o01/o4_X_external.csv\n",
      "2024-12-15 20:46:26,622 - INFO - Saving y_external to ../CSV/exports/impute/o1_GAN/o01/o4_y_external.csv\n",
      "2024-12-15 20:46:26,684 - INFO - Saving X_train_imputed to ../CSV/exports/impute/o1_GAN/o01/o4_X_train.csv\n",
      "2024-12-15 20:46:33,107 - INFO - Saving y_train to ../CSV/exports/impute/o1_GAN/o01/o4_y_train.csv\n",
      "2024-12-15 20:46:33,164 - INFO - Saving X_validate_imputed to ../CSV/exports/impute/o1_GAN/o01/o4_X_validate.csv\n",
      "2024-12-15 20:46:33,982 - INFO - Saving y_validate to ../CSV/exports/impute/o1_GAN/o01/o4_y_validate.csv\n",
      "2024-12-15 20:46:33,992 - INFO - Saving X_test_imputed to ../CSV/exports/impute/o1_GAN/o01/o4_X_test.csv\n",
      "2024-12-15 20:46:34,809 - INFO - Saving y_test to ../CSV/exports/impute/o1_GAN/o01/o4_y_test.csv\n"
     ]
    }
   ],
   "source": [
    "save_path = '../CSV/exports/impute/o1_GAN/o01/'\n",
    "logging.info(f\"Save path set to: {save_path}\")\n",
    "\n",
    "# Check if the directory exists, and if not, create it\n",
    "if not os.path.exists(save_path):\n",
    "    logging.info(f\"Directory does not exist. Creating directory: {save_path}\")\n",
    "    os.makedirs(save_path)\n",
    "else:\n",
    "    logging.info(f\"Directory already exists: {save_path}\")\n",
    "\n",
    "# Save external validation set from eICU\n",
    "logging.info(f\"Saving X_external_imputed to {save_path + name + '_X_external.csv'}\")\n",
    "X_external_imputed.to_csv(save_path + name + '_X_external.csv', index=False)\n",
    "\n",
    "logging.info(f\"Saving y_external to {save_path + name + '_y_external.csv'}\")\n",
    "y_external.to_csv(save_path + name + '_y_external.csv', index=False)\n",
    "\n",
    "# Save training set\n",
    "logging.info(f\"Saving X_train_imputed to {save_path + name + '_X_train.csv'}\")\n",
    "X_train_imputed.to_csv(save_path + name + '_X_train.csv', index=False)\n",
    "\n",
    "logging.info(f\"Saving y_train to {save_path + name + '_y_train.csv'}\")\n",
    "y_train.to_csv(save_path + name + '_y_train.csv', index=False)\n",
    "\n",
    "# Save validation set\n",
    "logging.info(f\"Saving X_validate_imputed to {save_path + name + '_X_validate.csv'}\")\n",
    "X_validate_imputed.to_csv(save_path + name + '_X_validate.csv', index=False)\n",
    "\n",
    "logging.info(f\"Saving y_validate to {save_path + name + '_y_validate.csv'}\")\n",
    "y_validate.to_csv(save_path + name + '_y_validate.csv', index=False)\n",
    "\n",
    "# Save test set\n",
    "logging.info(f\"Saving X_test_imputed to {save_path + name + '_X_test.csv'}\")\n",
    "X_test_imputed.to_csv(save_path + name + '_X_test.csv', index=False)\n",
    "\n",
    "logging.info(f\"Saving y_test to {save_path + name + '_y_test.csv'}\")\n",
    "y_test.to_csv(save_path + name + '_y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b09cdb3-12a4-4e78-8012-b009603b28e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
