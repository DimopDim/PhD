{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e450989-ef24-43cc-8be2-71a2bd108411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde0d097-fd42-4f2a-b32a-5680ca650fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"data_loading.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292b23b9-c73a-489c-a696-1222dafb401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the start of the process\n",
    "logging.info(\"Starting the data loading process...\")\n",
    "\n",
    "# Read MIMICs CSV files\n",
    "subfolder = 'o4_hour_overlap_window'\n",
    "\n",
    "logging.info(f\"Loading MIMIC-IV datasets\")\n",
    "try:\n",
    "    mimic_mean_df = pd.read_csv(f\"../../01_MimicIV/CSV/Exports/datasets/whole_set/{subfolder}/o01_final_mean_with_los.csv\", low_memory=False)\n",
    "    logging.info(\"Loaded mimic_mean_df successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading mimic_mean_df: {e}\")\n",
    "\n",
    "try:\n",
    "    mimic_median_df = pd.read_csv(f\"../../01_MimicIV/CSV/Exports/datasets/whole_set/{subfolder}/o02_final_median_with_los.csv\", low_memory=False)\n",
    "    logging.info(\"Loaded mimic_median_df successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading mimic_median_df: {e}\")\n",
    "\n",
    "try:\n",
    "    mimic_min_df = pd.read_csv(f\"../../01_MimicIV/CSV/Exports/datasets/whole_set/{subfolder}/o03_final_min_with_los.csv\", low_memory=False)\n",
    "    logging.info(\"Loaded mimic_min_df successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading mimic_min_df: {e}\")\n",
    "\n",
    "try:\n",
    "    mimic_max_df = pd.read_csv(f\"../../01_MimicIV/CSV/Exports/datasets/whole_set/{subfolder}/o04_final_max_with_los.csv\", low_memory=False)\n",
    "    logging.info(\"Loaded mimic_max_df successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading mimic_max_df: {e}\")\n",
    "\n",
    "# Read eICUs CSV files\n",
    "logging.info(\"Loading eICU datasets\")\n",
    "try:\n",
    "    eicu_mean_df = pd.read_csv(f\"../../02_eICU/CSV/Exports/datasets/whole_set/{subfolder}/o01_final_mean_table.csv\", low_memory=False)\n",
    "    logging.info(\"Loaded eicu_mean_df successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading eicu_mean_df: {e}\")\n",
    "\n",
    "try:\n",
    "    eicu_median_df = pd.read_csv(f\"../../02_eICU/CSV/Exports/datasets/whole_set/{subfolder}/o02_final_median_table.csv\", low_memory=False)\n",
    "    logging.info(\"Loaded eicu_median_df successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading eicu_median_df: {e}\")\n",
    "\n",
    "try:\n",
    "    eicu_min_df = pd.read_csv(f\"../../02_eICU/CSV/Exports/datasets/whole_set/{subfolder}/o03_final_min_table.csv\", low_memory=False)\n",
    "    logging.info(\"Loaded eicu_min_df successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading eicu_min_df: {e}\")\n",
    "\n",
    "try:\n",
    "    eicu_max_df = pd.read_csv(f\"../../02_eICU/CSV/Exports/datasets/whole_set/{subfolder}/o04_final_max_table.csv\", low_memory=False)\n",
    "    logging.info(\"Loaded eicu_max_df successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading eicu_max_df: {e}\")\n",
    "\n",
    "logging.info(\"Data loading process completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c91cf4c-e5f4-402c-8eea-0f11f90d99da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to keep\n",
    "mimic_columns_to_keep = pd.read_csv('../CSV/imports/mimic_features.csv')\n",
    "eicu_columns_to_keep = pd.read_csv('../CSV/imports/eicu_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bb54d7-8c78-4bad-b607-d37839e6d877",
   "metadata": {},
   "source": [
    "# MIMIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c645a68-5a3f-4a24-a713-e0af73caf54c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logging.info(\"Starting the chunk-based merging process for MIMIC-IV dataframes.\")\n",
    "\n",
    "try:\n",
    "    chunk_size = 2000\n",
    "    merged_chunks = []  # List to store merged chunks\n",
    "\n",
    "    # Iteratively process chunks from mimic_mean_df\n",
    "    for i in range(0, len(mimic_mean_df), chunk_size):\n",
    "        logging.info(f\"Processing chunk {i // chunk_size + 1}...\")\n",
    "\n",
    "        # Slice the chunk from mimic_mean_df\n",
    "        chunk = mimic_mean_df.iloc[i:i + chunk_size]\n",
    "\n",
    "        # Merge with mimic_median_df\n",
    "        logging.info(\"Merging with mimic_median_df...\")\n",
    "        chunk = chunk.merge(\n",
    "            mimic_median_df,\n",
    "            on=['row_count', 'subject_id', 'hadm_id', 'Time_Zone', 'gender', 'age', 'language', 'marital_status', 'race', 'hospital_expire_flag', 'los'],\n",
    "            suffixes=('_mean', '_median')\n",
    "        )\n",
    "        logging.info(\"Merged chunk with mimic_median_df successfully.\")\n",
    "\n",
    "        # Merge with mimic_min_df\n",
    "        logging.info(\"Merging with mimic_min_df...\")\n",
    "        chunk = chunk.merge(\n",
    "            mimic_min_df,\n",
    "            on=['row_count', 'subject_id', 'hadm_id', 'Time_Zone', 'gender', 'age', 'language', 'marital_status', 'race', 'hospital_expire_flag', 'los'],\n",
    "            suffixes=('', '_min')\n",
    "        )\n",
    "        logging.info(\"Merged chunk with mimic_min_df successfully.\")\n",
    "\n",
    "        # Merge with mimic_max_df\n",
    "        logging.info(\"Merging with mimic_max_df...\")\n",
    "        chunk = chunk.merge(\n",
    "            mimic_max_df,\n",
    "            on=['row_count', 'subject_id', 'hadm_id', 'Time_Zone', 'gender', 'age', 'language', 'marital_status', 'race', 'hospital_expire_flag', 'los'],\n",
    "            suffixes=('', '_max')\n",
    "        )\n",
    "        logging.info(\"Merged chunk with mimic_max_df successfully.\")\n",
    "\n",
    "        # Append merged chunk to the list\n",
    "        merged_chunks.append(chunk)\n",
    "\n",
    "    # Concatenate all chunks into a single dataframe\n",
    "    logging.info(\"Concatenating all merged chunks...\")\n",
    "    merged_mimic_df = pd.concat(merged_chunks, ignore_index=True)\n",
    "    logging.info(\"Concatenated all chunks successfully.\")\n",
    "\n",
    "    # Replace suffixes\n",
    "    logging.info(\"Replacing suffixes in column names...\")\n",
    "    merged_mimic_df.columns = merged_mimic_df.columns.str.replace(r'\\s*-\\s*Mean', ' (Mean)', regex=True)\n",
    "    merged_mimic_df.columns = merged_mimic_df.columns.str.replace(r'\\s*-\\s*Median', ' (Median)', regex=True)\n",
    "    merged_mimic_df.columns = merged_mimic_df.columns.str.replace(r'\\s*-\\s*Min', ' (Min)', regex=True)\n",
    "    merged_mimic_df.columns = merged_mimic_df.columns.str.replace(r'\\s*-\\s*Max', ' (Max)', regex=True)\n",
    "    logging.info(\"Replaced suffixes successfully.\")\n",
    "\n",
    "    # Move the 'hospital_expire_flag' and 'LOS' columns to the end of the dataframe\n",
    "    logging.info(\"Reordering columns: moving 'hospital_expire_flag' and 'los' to the end...\")\n",
    "    hospital_expire_flag_column = merged_mimic_df.pop('hospital_expire_flag')\n",
    "    los_column = merged_mimic_df.pop('los')\n",
    "    merged_mimic_df = pd.concat([merged_mimic_df, hospital_expire_flag_column, los_column], axis=1)\n",
    "    logging.info(\"Reordered columns successfully.\")\n",
    "\n",
    "    # Rename the last two columns to preserve their original names\n",
    "    logging.info(\"Renaming the last two columns to preserve original names...\")\n",
    "    merged_mimic_df.columns = list(merged_mimic_df.columns[:-2]) + ['hospital_expire_flag', 'los']\n",
    "    logging.info(\"Renamed the last two columns successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred during the merging process: {e}\")\n",
    "\n",
    "logging.info(\"Chunk-based merging process for MIMIC-IV dataframes completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75174a78-89da-4c51-83cb-f9c371c3bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Starting chunk-wise processing of merged_mimic_df.\")\n",
    "\n",
    "# Split dataframe into chunks\n",
    "num_chunks = 10  \n",
    "chunk_list = np.array_split(merged_mimic_df, num_chunks)\n",
    "\n",
    "# Placeholder\n",
    "processed_chunks = []\n",
    "\n",
    "for i, chunk in enumerate(chunk_list):\n",
    "    logging.info(f\"Processing chunk {i + 1}/{num_chunks}...\")\n",
    "    \n",
    "    for col in [\n",
    "        'GCS - Eye Opening (Mean)', 'GCS - Verbal Response (Mean)', 'GCS - Motor Response (Mean)',\n",
    "        'GCS - Eye Opening (Median)', 'GCS - Verbal Response (Median)', 'GCS - Motor Response (Median)',\n",
    "        'GCS - Eye Opening (Min)', 'GCS - Verbal Response (Min)', 'GCS - Motor Response (Min)',\n",
    "        'GCS - Eye Opening (Max)', 'GCS - Verbal Response (Max)', 'GCS - Motor Response (Max)'\n",
    "    ]:\n",
    "        chunk[col] = pd.to_numeric(chunk[col], errors='coerce')\n",
    "    \n",
    "    # Handling NaNs\n",
    "    chunk['GCS (Mean)'] = chunk[['GCS - Eye Opening (Mean)', 'GCS - Verbal Response (Mean)', 'GCS - Motor Response (Mean)']].fillna(0).to_numpy().sum(axis=1)\n",
    "    chunk['GCS (Median)'] = chunk[['GCS - Eye Opening (Median)', 'GCS - Verbal Response (Median)', 'GCS - Motor Response (Median)']].fillna(0).to_numpy().sum(axis=1)\n",
    "    chunk['GCS (Min)'] = chunk[['GCS - Eye Opening (Min)', 'GCS - Verbal Response (Min)', 'GCS - Motor Response (Min)']].fillna(0).to_numpy().sum(axis=1)\n",
    "    chunk['GCS (Max)'] = chunk[['GCS - Eye Opening (Max)', 'GCS - Verbal Response (Max)', 'GCS - Motor Response (Max)']].fillna(0).to_numpy().sum(axis=1)\n",
    "\n",
    "    # Replace rows where all original GCS columns were NaN with NaN in the new GCS columns\n",
    "    mask_mean = chunk[['GCS - Eye Opening (Mean)', 'GCS - Verbal Response (Mean)', 'GCS - Motor Response (Mean)']].isna().all(axis=1)\n",
    "    mask_median = chunk[['GCS - Eye Opening (Median)', 'GCS - Verbal Response (Median)', 'GCS - Motor Response (Median)']].isna().all(axis=1)\n",
    "    mask_min = chunk[['GCS - Eye Opening (Min)', 'GCS - Verbal Response (Min)', 'GCS - Motor Response (Min)']].isna().all(axis=1)\n",
    "    mask_max = chunk[['GCS - Eye Opening (Max)', 'GCS - Verbal Response (Max)', 'GCS - Motor Response (Max)']].isna().all(axis=1)\n",
    "\n",
    "    chunk.loc[mask_mean, 'GCS (Mean)'] = np.nan\n",
    "    chunk.loc[mask_median, 'GCS (Median)'] = np.nan\n",
    "    chunk.loc[mask_min, 'GCS (Min)'] = np.nan\n",
    "    chunk.loc[mask_max, 'GCS (Max)'] = np.nan\n",
    "\n",
    "    # Drop the original GCS component columns\n",
    "    chunk.drop(columns=[\n",
    "        'GCS - Eye Opening (Mean)', 'GCS - Verbal Response (Mean)', 'GCS - Motor Response (Mean)',\n",
    "        'GCS - Eye Opening (Median)', 'GCS - Verbal Response (Median)', 'GCS - Motor Response (Median)',\n",
    "        'GCS - Eye Opening (Min)', 'GCS - Verbal Response (Min)', 'GCS - Motor Response (Min)',\n",
    "        'GCS - Eye Opening (Max)', 'GCS - Verbal Response (Max)', 'GCS - Motor Response (Max)'\n",
    "    ], inplace=True)\n",
    "    \n",
    "    # Append processed chunk to the list\n",
    "    processed_chunks.append(chunk)\n",
    "    logging.info(f\"Chunk {i + 1}/{num_chunks} processed successfully.\")\n",
    "\n",
    "# Concatenate all processed chunks into a single DataFrame\n",
    "merged_mimic_df = pd.concat(processed_chunks, ignore_index=True)\n",
    "\n",
    "logging.info(\"All chunks processed and concatenated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9f0b0f-b335-4d14-8119-c5b1c32d76a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Starting chunk-wise processing of Braden components.\")\n",
    "\n",
    "# Split dataframe into chunks\n",
    "num_chunks = 10 \n",
    "chunk_list = np.array_split(merged_mimic_df, num_chunks)\n",
    "\n",
    "# Placeholder\n",
    "processed_chunks = []\n",
    "\n",
    "for i, chunk in enumerate(chunk_list):\n",
    "    logging.info(f\"Processing chunk {i + 1}/{num_chunks}...\")\n",
    "    \n",
    "    for col in [\n",
    "        'Braden Sensory Perception (Mean)', 'Braden Moisture (Mean)', 'Braden Activity (Mean)', \n",
    "        'Braden Mobility (Mean)', 'Braden Nutrition (Mean)', 'Braden Friction/Shear (Mean)',\n",
    "        'Braden Sensory Perception (Median)', 'Braden Moisture (Median)', 'Braden Activity (Median)', \n",
    "        'Braden Mobility (Median)', 'Braden Nutrition (Median)', 'Braden Friction/Shear (Median)',\n",
    "        'Braden Sensory Perception (Min)', 'Braden Moisture (Min)', 'Braden Activity (Min)', \n",
    "        'Braden Mobility (Min)', 'Braden Nutrition (Min)', 'Braden Friction/Shear (Min)',\n",
    "        'Braden Sensory Perception (Max)', 'Braden Moisture (Max)', 'Braden Activity (Max)', \n",
    "        'Braden Mobility (Max)', 'Braden Nutrition (Max)', 'Braden Friction/Shear (Max)'\n",
    "    ]:\n",
    "        chunk[col] = pd.to_numeric(chunk[col], errors='coerce')\n",
    "    \n",
    "    # Handling NaNs\n",
    "    chunk['Braden (Mean)'] = chunk[\n",
    "        ['Braden Sensory Perception (Mean)', 'Braden Moisture (Mean)', 'Braden Activity (Mean)', \n",
    "         'Braden Mobility (Mean)', 'Braden Nutrition (Mean)', 'Braden Friction/Shear (Mean)']\n",
    "    ].fillna(0).to_numpy().sum(axis=1)\n",
    "    \n",
    "    chunk['Braden (Median)'] = chunk[\n",
    "        ['Braden Sensory Perception (Median)', 'Braden Moisture (Median)', 'Braden Activity (Median)', \n",
    "         'Braden Mobility (Median)', 'Braden Nutrition (Median)', 'Braden Friction/Shear (Median)']\n",
    "    ].fillna(0).to_numpy().sum(axis=1)\n",
    "    \n",
    "    chunk['Braden (Min)'] = chunk[\n",
    "        ['Braden Sensory Perception (Min)', 'Braden Moisture (Min)', 'Braden Activity (Min)', \n",
    "         'Braden Mobility (Min)', 'Braden Nutrition (Min)', 'Braden Friction/Shear (Min)']\n",
    "    ].fillna(0).to_numpy().sum(axis=1)\n",
    "    \n",
    "    chunk['Braden (Max)'] = chunk[\n",
    "        ['Braden Sensory Perception (Max)', 'Braden Moisture (Max)', 'Braden Activity (Max)', \n",
    "         'Braden Mobility (Max)', 'Braden Nutrition (Max)', 'Braden Friction/Shear (Max)']\n",
    "    ].fillna(0).to_numpy().sum(axis=1)\n",
    "\n",
    "    # Replace rows where all original Braden columns were NaN with NaN in the new Braden columns\n",
    "    mask_mean = chunk[\n",
    "        ['Braden Sensory Perception (Mean)', 'Braden Moisture (Mean)', 'Braden Activity (Mean)', \n",
    "         'Braden Mobility (Mean)', 'Braden Nutrition (Mean)', 'Braden Friction/Shear (Mean)']\n",
    "    ].isna().all(axis=1)\n",
    "    \n",
    "    mask_median = chunk[\n",
    "        ['Braden Sensory Perception (Median)', 'Braden Moisture (Median)', 'Braden Activity (Median)', \n",
    "         'Braden Mobility (Median)', 'Braden Nutrition (Median)', 'Braden Friction/Shear (Median)']\n",
    "    ].isna().all(axis=1)\n",
    "    \n",
    "    mask_min = chunk[\n",
    "        ['Braden Sensory Perception (Min)', 'Braden Moisture (Min)', 'Braden Activity (Min)', \n",
    "         'Braden Mobility (Min)', 'Braden Nutrition (Min)', 'Braden Friction/Shear (Min)']\n",
    "    ].isna().all(axis=1)\n",
    "    \n",
    "    mask_max = chunk[\n",
    "        ['Braden Sensory Perception (Max)', 'Braden Moisture (Max)', 'Braden Activity (Max)', \n",
    "         'Braden Mobility (Max)', 'Braden Nutrition (Max)', 'Braden Friction/Shear (Max)']\n",
    "    ].isna().all(axis=1)\n",
    "\n",
    "    chunk.loc[mask_mean, 'Braden (Mean)'] = np.nan\n",
    "    chunk.loc[mask_median, 'Braden (Median)'] = np.nan\n",
    "    chunk.loc[mask_min, 'Braden (Min)'] = np.nan\n",
    "    chunk.loc[mask_max, 'Braden (Max)'] = np.nan\n",
    "\n",
    "    # Drop the original Braden component columns\n",
    "    chunk.drop(columns=[\n",
    "        'Braden Sensory Perception (Mean)', 'Braden Moisture (Mean)', 'Braden Activity (Mean)', \n",
    "        'Braden Mobility (Mean)', 'Braden Nutrition (Mean)', 'Braden Friction/Shear (Mean)',\n",
    "        'Braden Sensory Perception (Median)', 'Braden Moisture (Median)', 'Braden Activity (Median)', \n",
    "        'Braden Mobility (Median)', 'Braden Nutrition (Median)', 'Braden Friction/Shear (Median)',\n",
    "        'Braden Sensory Perception (Min)', 'Braden Moisture (Min)', 'Braden Activity (Min)', \n",
    "        'Braden Mobility (Min)', 'Braden Nutrition (Min)', 'Braden Friction/Shear (Min)',\n",
    "        'Braden Sensory Perception (Max)', 'Braden Moisture (Max)', 'Braden Activity (Max)', \n",
    "        'Braden Mobility (Max)', 'Braden Nutrition (Max)', 'Braden Friction/Shear (Max)'\n",
    "    ], inplace=True)\n",
    "    \n",
    "    # Append processed chunk to the list\n",
    "    processed_chunks.append(chunk)\n",
    "    logging.info(f\"Chunk {i + 1}/{num_chunks} processed successfully.\")\n",
    "\n",
    "# Concatenate all processed chunks into a single DataFrame\n",
    "merged_mimic_df = pd.concat(processed_chunks, ignore_index=True)\n",
    "\n",
    "logging.info(\"All chunks processed and concatenated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baff4a04-b710-49ea-bb59-e33f71e14fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove spaces and commas\n",
    "merged_mimic_df.columns = merged_mimic_df.columns.str.replace(r'[ ,]+', '_', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbd9287-8565-4962-8ebf-f6a18f011ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop second column from the column_names_df\n",
    "mimic_columns_to_keep.drop(columns=['Unnamed: 1'], inplace=True)\n",
    "\n",
    "# Extract column names from columns_to_keep DataFrame\n",
    "columns_to_keep_names = mimic_columns_to_keep['column'].tolist()\n",
    "\n",
    "# Select only the desired columns\n",
    "mimic_temp = merged_mimic_df[columns_to_keep_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aace7894-9469-4cbb-88fc-f53fe5e8df70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Duplicate Columns\n",
    "df_mimic_unique = mimic_temp.loc[:, ~mimic_temp.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02d562d-f42c-420d-91f4-d39ce3c9aa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply values by 4 in 'Ionized Calcium' column, leaving NaN values unchanged for normalization with eicu\n",
    "df_mimic_unique.loc[:, 'Ionized_Calcium_(Max)'] = mimic_temp['Ionized_Calcium_(Max)'].apply(lambda x: x * 4 if pd.notna(x) else x)\n",
    "df_mimic_unique.loc[:, 'Ionized_Calcium_(Mean)'] = mimic_temp['Ionized_Calcium_(Mean)'].apply(lambda x: x * 4 if pd.notna(x) else x)\n",
    "df_mimic_unique.loc[:, 'Ionized_Calcium_(Median)'] = mimic_temp['Ionized_Calcium_(Median)'].apply(lambda x: x * 4 if pd.notna(x) else x)\n",
    "df_mimic_unique.loc[:, 'Ionized_Calcium_(Min)'] = mimic_temp['Ionized_Calcium_(Min)'].apply(lambda x: x * 4 if pd.notna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab4b571-cee1-4183-996f-4251c49784e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy df_mimic_unique in order to avoid SettingWithCopyWarning\n",
    "df_mimic_unique = df_mimic_unique.copy()\n",
    "\n",
    "# Glucose merge - calculate the mean for each aggregation type and handle NaN values\n",
    "df_mimic_unique['Glucose (Max)'] = df_mimic_unique[['Glucose_(Max)', 'Glucose_(Max).1', 'Glucose_(Max).2']].mean(axis=1)\n",
    "df_mimic_unique['Glucose (Mean)'] = df_mimic_unique[['Glucose_(Mean)', 'Glucose_(Mean).1', 'Glucose_(Mean).2']].mean(axis=1)\n",
    "df_mimic_unique['Glucose (Median)'] = df_mimic_unique[['Glucose_(Median)', 'Glucose_(Median).1', 'Glucose_(Median).2']].mean(axis=1)\n",
    "df_mimic_unique['Glucose (Min)'] = df_mimic_unique[['Glucose_(Min)', 'Glucose_(Min).1', 'Glucose_(Min).2']].mean(axis=1)\n",
    "\n",
    "# Drop original Glucose columns to keep only the summarized columns\n",
    "df_mimic_unique.drop(columns=[\n",
    "    'Glucose_(Max)', 'Glucose_(Max).1', 'Glucose_(Max).2',\n",
    "    'Glucose_(Mean)', 'Glucose_(Mean).1', 'Glucose_(Mean).2',\n",
    "    'Glucose_(Median)', 'Glucose_(Median).1', 'Glucose_(Median).2',\n",
    "    'Glucose_(Min)', 'Glucose_(Min).1', 'Glucose_(Min).2'\n",
    "], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a1c826-fd28-4504-9e94-e96bb66a4d2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logging.info(\"Starting the pH column processing.\")\n",
    "\n",
    "# Make a copy of df_mimic_unique to avoid SettingWithCopyWarning\n",
    "df_mimic_unique = df_mimic_unique.copy()\n",
    "\n",
    "# pH merge\n",
    "logging.info(\"Calculating 'pH (Max)' column.\")\n",
    "df_mimic_unique.loc[:, 'pH (Max)'] = df_mimic_unique.apply(\n",
    "    lambda row: row[['pH_(Max)', 'pH_(Max).1', 'pH_(Max).3']].mean()\n",
    "    if not all(row[['pH_(Max)', 'pH_(Max).1', 'pH_(Max).3']].isna())\n",
    "    else np.nan, axis=1\n",
    ")\n",
    "\n",
    "logging.info(\"Calculating 'pH (Mean)' column.\")\n",
    "df_mimic_unique.loc[:, 'pH (Mean)'] = df_mimic_unique.apply(\n",
    "    lambda row: row[['pH_(Mean)', 'pH_(Mean).1', 'pH_(Mean).2', 'pH_(Mean).3']].mean()\n",
    "    if not all(row[['pH_(Mean)', 'pH_(Mean).1', 'pH_(Mean).2', 'pH_(Mean).3']].isna())\n",
    "    else np.nan, axis=1\n",
    ")\n",
    "\n",
    "logging.info(\"Calculating 'pH (Median)' column.\")\n",
    "df_mimic_unique.loc[:, 'pH (Median)'] = df_mimic_unique.apply(\n",
    "    lambda row: row[['pH_(Median)', 'pH_(Median).1', 'pH_(Median).3']].mean()\n",
    "    if not all(row[['pH_(Median)', 'pH_(Median).1', 'pH_(Median).3']].isna())\n",
    "    else np.nan, axis=1\n",
    ")\n",
    "\n",
    "logging.info(\"Calculating 'pH (Min)' column.\")\n",
    "df_mimic_unique.loc[:, 'pH (Min)'] = df_mimic_unique.apply(\n",
    "    lambda row: row[['pH_(Min)', 'pH_(Min).1', 'pH_(Min).3']].mean()\n",
    "    if not all(row[['pH_(Min)', 'pH_(Min).1', 'pH_(Min).3']].isna())\n",
    "    else np.nan, axis=1\n",
    ")\n",
    "\n",
    "# Drop original pH columns to keep only the summarized columns\n",
    "logging.info(\"Dropping original pH columns.\")\n",
    "df_mimic_unique.drop(columns=[\n",
    "    'pH_(Max)', 'pH_(Max).1', 'pH_(Max).3',\n",
    "    'pH_(Mean)', 'pH_(Mean).1', 'pH_(Mean).2', 'pH_(Mean).3',\n",
    "    'pH_(Median)', 'pH_(Median).1', 'pH_(Median).3',\n",
    "    'pH_(Min)', 'pH_(Min).1', 'pH_(Min).3'\n",
    "], inplace=True)\n",
    "\n",
    "logging.info(\"pH column processing completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f4c528-593c-4a86-b3f0-d7fce5631a83",
   "metadata": {},
   "source": [
    "# eICU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638bd02c-ab55-435d-8497-96cba4d5ede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Starting the merging process for eICU dataframes.\")\n",
    "\n",
    "try:\n",
    "    # Merge eICU dataframes\n",
    "    logging.info(\"Merging eicu_meam_df and eicu_median_df...\")\n",
    "    merged_eicu_df = eicu_mean_df.merge(\n",
    "        eicu_median_df, \n",
    "        on=['row_count', 'uniquepid', 'patientunitstayid', 'Time_Zone', 'gender', 'age', 'ethnicity', 'unitdischargestatus', 'LOS'], \n",
    "        suffixes=('_mean', '_median')\n",
    "    )\n",
    "    logging.info(\"Merged eicu_meam_df and eicu_median_df successfully.\")\n",
    "\n",
    "    logging.info(\"Merging with eicu_min_df...\")\n",
    "    merged_eicu_df = merged_eicu_df.merge(\n",
    "        eicu_min_df, \n",
    "        on=['row_count', 'uniquepid', 'patientunitstayid', 'Time_Zone', 'gender', 'age', 'ethnicity', 'unitdischargestatus', 'LOS'], \n",
    "        suffixes=('', '_min')\n",
    "    )\n",
    "    logging.info(\"Merged with eicu_min_df successfully.\")\n",
    "\n",
    "    logging.info(\"Merging with eicu_max_df...\")\n",
    "    merged_eicu_df = merged_eicu_df.merge(\n",
    "        eicu_max_df, \n",
    "        on=['row_count', 'uniquepid', 'patientunitstayid', 'Time_Zone', 'gender', 'age', 'ethnicity', 'unitdischargestatus', 'LOS'], \n",
    "        suffixes=('', '_max')\n",
    "    )\n",
    "    logging.info(\"Merged with eicu_max_df successfully.\")\n",
    "\n",
    "    # Move the 'unitdischargestatus' and 'LOS' columns to the end of the dataframe\n",
    "    logging.info(\"Reordering columns: moving 'unitdischargestatus' and 'LOS' to the end...\")\n",
    "    unitdischargestatus_column = merged_eicu_df.pop('unitdischargestatus')\n",
    "    los_column = merged_eicu_df.pop('LOS')\n",
    "    merged_eicu_df = pd.concat([merged_eicu_df, unitdischargestatus_column, los_column], axis=1)\n",
    "    logging.info(\"Reordered columns successfully.\")\n",
    "\n",
    "    # Rename the last two columns to preserve their original names\n",
    "    logging.info(\"Renaming the last two columns to preserve original names...\")\n",
    "    merged_eicu_df.columns = list(merged_eicu_df.columns[:-2]) + ['unitdischargestatus', 'LOS']\n",
    "    logging.info(\"Renamed the last two columns successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred during the merging process: {e}\")\n",
    "\n",
    "logging.info(\"Merging process for eICU dataframes completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6d9f87-4ba1-478a-8382-134c371ea70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop second column from the column_names_df\n",
    "eicu_columns_to_keep.drop(columns=['Unnamed: 1'], inplace=True)\n",
    "\n",
    "# Extract column names from columns_to_keep DataFrame\n",
    "columns_to_keep_names = eicu_columns_to_keep['column'].tolist()\n",
    "\n",
    "# Select only the desired columns\n",
    "eicu_temp = merged_eicu_df[columns_to_keep_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4c69a3-07f1-4b19-bc57-77d227f982eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"--------Replace Block----------\"\"\"\n",
    "# Make a copy df_mimic_unique in order to avoid SettingWithCopyWarning\n",
    "eicu_temp = eicu_temp.copy()\n",
    "\n",
    "# Replace 'Alive' with 0 and 'Expired' with 1 in the 'unitdischargestatus' column\n",
    "eicu_temp.loc[:, 'unitdischargestatus'] = eicu_temp['unitdischargestatus'].replace({'Alive': 0, 'Expired': 1})\n",
    "\n",
    "# Replace 'Female' with 'F' and 'Male' with 'M' in the 'gender' column\n",
    "eicu_temp.loc[:, 'gender'] = eicu_temp['gender'].replace({'Female': 'F', 'Male': 'M'})\n",
    "\n",
    "\n",
    "# Replace values in the 'ethnicity' column for standardization\n",
    "eicu_temp.loc[:, 'ethnicity'] = eicu_temp['ethnicity'].replace({\n",
    "    'African American': 'BLACK/AFRICAN AMERICAN',\n",
    "    'Caucasian': 'WHITE',\n",
    "    'Hispanic': 'HISPANIC OR LATINO',\n",
    "    'Asian': 'ASIAN',\n",
    "    'Native American': 'AMERICAN INDIAN/ALASKA NATIVE',\n",
    "    'Other/Unknown': 'UNKNOWN'\n",
    "})\n",
    "\n",
    "# Replace age values higher than 89 with 90, and convert age to integer\n",
    "eicu_temp.loc[:, 'age'] = eicu_temp['age'].replace('> 89', 90)\n",
    "eicu_temp.loc[:, 'age'] = eicu_temp['age'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed90bd15-ad41-4f26-b573-51fd5631e512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove spaces and commas\n",
    "df_mimic_unique.columns = df_mimic_unique.columns.str.replace(r'[ ,]+', '_', regex=True)\n",
    "\n",
    "eicu_temp.columns = eicu_temp.columns.str.replace(r'[ ,]+', '_', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf296c0-b15d-4008-86bc-5c3c9413370c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logging.info(\"Starting the processing of bedside glucose columns in eicu_temp.\")\n",
    "\n",
    "try:\n",
    "    # Make a copy of eicu_temp to avoid SettingWithCopyWarning\n",
    "    eicu_temp = eicu_temp.copy()\n",
    "\n",
    "    # Calculate 'bedside_glucose (Max)'\n",
    "    logging.info(\"Calculating 'bedside_glucose (Max)' column.\")\n",
    "    eicu_temp.loc[:, 'bedside_glucose (Max)'] = eicu_temp.apply(\n",
    "        lambda row: row[['bedside_glucose_(Max)', 'Bedside_Glucose_(Max)']].mean()\n",
    "        if not all(row[['bedside_glucose_(Max)', 'Bedside_Glucose_(Max)']].isna())\n",
    "        else np.nan, axis=1\n",
    "    )\n",
    "\n",
    "    # Calculate 'bedside_glucose (Mean)'\n",
    "    logging.info(\"Calculating 'bedside_glucose (Mean)' column.\")\n",
    "    eicu_temp.loc[:, 'bedside_glucose (Mean)'] = eicu_temp.apply(\n",
    "        lambda row: row[['bedside_glucose_(Mean)', 'Bedside_Glucose_(Mean)']].mean()\n",
    "        if not all(row[['bedside_glucose_(Mean)', 'Bedside_Glucose_(Mean)']].isna())\n",
    "        else np.nan, axis=1\n",
    "    )\n",
    "\n",
    "    # Calculate 'bedside_glucose (Median)'\n",
    "    logging.info(\"Calculating 'bedside_glucose (Median)' column.\")\n",
    "    eicu_temp.loc[:, 'bedside_glucose (Median)'] = eicu_temp.apply(\n",
    "        lambda row: row[['bedside_glucose_(Median)', 'Bedside_Glucose_(Median)']].mean()\n",
    "        if not all(row[['bedside_glucose_(Median)', 'Bedside_Glucose_(Median)']].isna())\n",
    "        else np.nan, axis=1\n",
    "    )\n",
    "\n",
    "    # Calculate 'bedside_glucose (Min)'\n",
    "    logging.info(\"Calculating 'bedside_glucose (Min)' column.\")\n",
    "    eicu_temp.loc[:, 'bedside_glucose (Min)'] = eicu_temp.apply(\n",
    "        lambda row: row[['bedside_glucose_(Min)', 'Bedside_Glucose_(Min)']].mean()\n",
    "        if not all(row[['bedside_glucose_(Min)', 'Bedside_Glucose_(Min)']].isna())\n",
    "        else np.nan, axis=1\n",
    "    )\n",
    "\n",
    "    # Drop original bedside glucose columns\n",
    "    logging.info(\"Dropping original bedside glucose columns.\")\n",
    "    eicu_temp.drop(columns=[\n",
    "        'bedside_glucose_(Max)', 'Bedside_Glucose_(Max)',\n",
    "        'bedside_glucose_(Mean)', 'Bedside_Glucose_(Mean)',\n",
    "        'bedside_glucose_(Median)', 'Bedside_Glucose_(Median)',\n",
    "        'bedside_glucose_(Min)', 'Bedside_Glucose_(Min)'\n",
    "    ], inplace=True)\n",
    "\n",
    "    # Replace spaces or commas in column names with underscores\n",
    "    logging.info(\"Replacing spaces and commas in column names with underscores.\")\n",
    "    eicu_temp.columns = eicu_temp.columns.str.replace(r'[ ,]+', '_', regex=True)\n",
    "\n",
    "    logging.info(\"Processing of bedside glucose columns completed successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred during the processing of bedside glucose columns: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a725b058-fc38-4cfc-8803-3c9c8cec8b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename eICU header to align with mimics\n",
    "column_eicu_mapping = {\n",
    "    'column': 'column',\n",
    "    'row_count': 'row_count',\n",
    "    'uniquepid': 'subject_id',\n",
    "    'patientunitstayid': 'hadm_id',\n",
    "    'Time_Zone': 'Time_Zone',\n",
    "    'gender': 'gender',\n",
    "    'age': 'age',\n",
    "    'ethnicity': 'race',\n",
    "    'Base_Excess_(Max)': 'Base_Excess_(Max)',\n",
    "    'Base_Excess_(Mean)': 'Base_Excess_(Mean)',\n",
    "    'Base_Excess_(Median)': 'Base_Excess_(Median)',\n",
    "    'Base_Excess_(Min)': 'Base_Excess_(Min)',\n",
    "    'lactate_(Max)': 'Lactate_(Max)',\n",
    "    'lactate_(Mean)': 'Lactate_(Mean)',\n",
    "    'lactate_(Median)': 'Lactate_(Median)',\n",
    "    'lactate_(Min)': 'Lactate_(Min)',\n",
    "    'paCO2_(Max)': 'pCO2_(Max)',\n",
    "    'paCO2_(Mean)': 'pCO2_(Mean)',\n",
    "    'paCO2_(Median)': 'pCO2_(Median)',\n",
    "    'paCO2_(Min)': 'pCO2_(Min)',\n",
    "    'Total_CO2_(Max)': 'Calculated_Total_CO2_(Max)',\n",
    "    'Total_CO2_(Mean)': 'Calculated_Total_CO2_(Mean)',\n",
    "    'Total_CO2_(Median)': 'Calculated_Total_CO2_(Median)',\n",
    "    'Total_CO2_(Min)': 'Calculated_Total_CO2_(Min)',\n",
    "    'BUN_(Max)': 'BUN_(Max)',\n",
    "    'BUN_(Mean)': 'BUN_(Mean)',\n",
    "    'BUN_(Median)': 'BUN_(Median)',\n",
    "    'BUN_(Min)': 'BUN_(Min)',\n",
    "    'pH_(Max)': 'pH_(Max)',\n",
    "    'pH_(Mean)': 'pH_(Mean)',\n",
    "    'pH_(Median)': 'pH_(Median)',\n",
    "    'pH_(Min)': 'pH_(Min)',\n",
    "    'paO2_(Max)': 'pO2_(Max)',\n",
    "    'paO2_(Mean)': 'pO2_(Mean)',\n",
    "    'paO2_(Median)': 'pO2_(Median)',\n",
    "    'paO2_(Min)': 'pO2_(Min)',\n",
    "    'ALT_(SGPT)_(Max)': 'Alanine_Aminotransferase_(ALT)_(Max)',\n",
    "    'ALT_(SGPT)_(Mean)': 'Alanine_Aminotransferase_(ALT)_(Mean)',\n",
    "    'ALT_(SGPT)_(Median)': 'Alanine_Aminotransferase_(ALT)_(Median)',\n",
    "    'ALT_(SGPT)_(Min)': 'Alanine_Aminotransferase_(ALT)_(Min)',\n",
    "    'alkaline_phos._(Max)': 'Alkaline_Phosphatase_(Max)',\n",
    "    'alkaline_phos._(Mean)': 'Alkaline_Phosphatase_(Mean)',\n",
    "    'alkaline_phos._(Median)': 'Alkaline_Phosphatase_(Median)',\n",
    "    'alkaline_phos._(Min)': 'Alkaline_Phosphatase_(Min)',\n",
    "    'anion_gap_(Max)': 'Anion_Gap_(Max)',\n",
    "    'anion_gap_(Mean)': 'Anion_Gap_(Mean)',\n",
    "    'anion_gap_(Median)': 'Anion_Gap_(Median)',\n",
    "    'anion_gap_(Min)': 'Anion_Gap_(Min)',\n",
    "    'AST_(SGOT)_(Max)': 'Asparate_Aminotransferase_(AST)_(Max)',\n",
    "    'AST_(SGOT)_(Mean)': 'Asparate_Aminotransferase_(AST)_(Mean)',\n",
    "    'AST_(SGOT)_(Median)': 'Asparate_Aminotransferase_(AST)_(Median)',\n",
    "    'AST_(SGOT)_(Min)': 'Asparate_Aminotransferase_(AST)_(Min)',\n",
    "    'bicarbonate_(Max)': 'Bicarbonate_(Max)',\n",
    "    'bicarbonate_(Mean)': 'Bicarbonate_(Mean)',\n",
    "    'bicarbonate_(Median)': 'Bicarbonate_(Median)',\n",
    "    'bicarbonate_(Min)': 'Bicarbonate_(Min)',\n",
    "    'chloride_(Max)': 'Chloride_(Max)',\n",
    "    'chloride_(Mean)': 'Chloride_(Mean)',\n",
    "    'chloride_(Median)': 'Chloride_(Median)',\n",
    "    'chloride_(Min)': 'Chloride_(Min)',\n",
    "    'creatinine_(Max)': 'Creatinine_(Max)',\n",
    "    'creatinine_(Mean)': 'Creatinine_(Mean)',\n",
    "    'creatinine_(Median)': 'Creatinine_(Median)',\n",
    "    'creatinine_(Min)': 'Creatinine_(Min)',\n",
    "    'glucose_(Max)': 'Glucose_(Max)',\n",
    "    'glucose_(Mean)': 'Glucose_(Mean)',\n",
    "    'glucose_(Median)': 'Glucose_(Median)',\n",
    "    'glucose_(Min)': 'Glucose_(Min)',\n",
    "    'magnesium_(Max)': 'Magnesium_(Max)',\n",
    "    'magnesium_(Mean)': 'Magnesium_(Mean)',\n",
    "    'magnesium_(Median)': 'Magnesium_(Median)',\n",
    "    'magnesium_(Min)': 'Magnesium_(Min)',\n",
    "    'phosphate_(Max)': 'Phosphate_(Max)',\n",
    "    'phosphate_(Mean)': 'Phosphate_(Mean)',\n",
    "    'phosphate_(Median)': 'Phosphate_(Median)',\n",
    "    'phosphate_(Min)': 'Phosphate_(Min)',\n",
    "    'potassium_(Max)': 'Potassium_(Max)',\n",
    "    'potassium_(Mean)': 'Potassium_(Mean)',\n",
    "    'potassium_(Median)': 'Potassium_(Median)',\n",
    "    'potassium_(Min)': 'Potassium_(Min)',\n",
    "    'sodium_(Max)': 'Sodium_(Max)',\n",
    "    'sodium_(Mean)': 'Sodium_(Mean)',\n",
    "    'sodium_(Median)': 'Sodium_(Median)',\n",
    "    'sodium_(Min)': 'Sodium_(Min)',\n",
    "    'Hct_(Max)': 'Hematocrit_(Max)',\n",
    "    'Hct_(Mean)': 'Hematocrit_(Mean)',\n",
    "    'Hct_(Median)': 'Hematocrit_(Median)',\n",
    "    'Hct_(Min)': 'Hematocrit_(Min)',\n",
    "    'Hgb_(Max)': 'Hemoglobin_(Max)',\n",
    "    'Hgb_(Mean)': 'Hemoglobin_(Mean)',\n",
    "    'Hgb_(Median)': 'Hemoglobin_(Median)',\n",
    "    'Hgb_(Min)': 'Hemoglobin_(Min)',\n",
    "    'PT_-_INR_(Max)': 'INR(PT)_(Max)',\n",
    "    'PT_-_INR_(Mean)': 'INR(PT)_(Mean)',\n",
    "    'PT_-_INR_(Median)': 'INR(PT)_(Median)',\n",
    "    'PT_-_INR_(Min)': 'INR(PT)_(Min)',\n",
    "    'MCH_(Max)': 'MCH_(Max)',\n",
    "    'MCH_(Mean)': 'MCH_(Mean)',\n",
    "    'MCH_(Median)': 'MCH_(Median)',\n",
    "    'MCH_(Min)': 'MCH_(Min)',\n",
    "    'MCHC_(Max)': 'MCHC_(Max)',\n",
    "    'MCHC_(Mean)': 'MCHC_(Mean)',\n",
    "    'MCHC_(Median)': 'MCHC_(Median)',\n",
    "    'MCHC_(Min)': 'MCHC_(Min)',\n",
    "    'MCV_(Max)': 'MCV_(Max)',\n",
    "    'MCV_(Mean)': 'MCV_(Mean)',\n",
    "    'MCV_(Median)': 'MCV_(Median)',\n",
    "    'MCV_(Min)': 'MCV_(Min)',\n",
    "    'platelets_x_1000_(Max)': 'Platelet_Count_(Max)',\n",
    "    'platelets_x_1000_(Mean)': 'Platelet_Count_(Mean)',\n",
    "    'platelets_x_1000_(Median)': 'Platelet_Count_(Median)',\n",
    "    'platelets_x_1000_(Min)': 'Platelet_Count_(Min)',\n",
    "    'PT_(Max)': 'PT_(Max)',\n",
    "    'PT_(Mean)': 'PT_(Mean)',\n",
    "    'PT_(Median)': 'PT_(Median)',\n",
    "    'PT_(Min)': 'PT_(Min)',\n",
    "    'PTT_(Max)': 'PTT_(Max)',\n",
    "    'PTT_(Mean)': 'PTT_(Mean)',\n",
    "    'PTT_(Median)': 'PTT_(Median)',\n",
    "    'PTT_(Min)': 'PTT_(Min)',\n",
    "    'RDW_(Max)': 'RDW_(Max)',\n",
    "    'RDW_(Mean)': 'RDW_(Mean)',\n",
    "    'RDW_(Median)': 'RDW_(Median)',\n",
    "    'RDW_(Min)': 'RDW_(Min)',\n",
    "    'RBC_(Max)': 'Red_Blood_Cells_(Max)',\n",
    "    'RBC_(Mean)': 'Red_Blood_Cells_(Mean)',\n",
    "    'RBC_(Median)': 'Red_Blood_Cells_(Median)',\n",
    "    'RBC_(Min)': 'Red_Blood_Cells_(Min)',\n",
    "    'WBC_x_1000_(Max)': 'White_Blood_Cells_(Max)',\n",
    "    'WBC_x_1000_(Mean)': 'White_Blood_Cells_(Mean)',\n",
    "    'WBC_x_1000_(Median)': 'White_Blood_Cells_(Median)',\n",
    "    'WBC_x_1000_(Min)': 'White_Blood_Cells_(Min)',\n",
    "    'Heart_Rate_(Max)': 'Heart_Rate_(bpm)_(Max)',\n",
    "    'Heart_Rate_(Mean)': 'Heart_Rate_(bpm)_(Mean)',\n",
    "    'Heart_Rate_(Median)': 'Heart_Rate_(bpm)_(Median)',\n",
    "    'Heart_Rate_(Min)': 'Heart_Rate_(bpm)_(Min)',\n",
    "    'Non-Invasive_BP_Diastolic_(Max)': 'Non_Invasive_Blood_Pressure_systolic_(mmHg)_(Max)',\n",
    "    'Non-Invasive_BP_Diastolic_(Mean)': 'Non_Invasive_Blood_Pressure_systolic_(mmHg)_(Mean)',\n",
    "    'Non-Invasive_BP_Diastolic_(Median)': 'Non_Invasive_Blood_Pressure_systolic_(mmHg)_(Median)',\n",
    "    'Non-Invasive_BP_Diastolic_(Min)': 'Non_Invasive_Blood_Pressure_systolic_(mmHg)_(Min)',\n",
    "    'Non-Invasive_BP_Systolic_(Max)': 'Non_Invasive_Blood_Pressure_diastolic_(mmHg)_(Max)',\n",
    "    'Non-Invasive_BP_Systolic_(Mean)': 'Non_Invasive_Blood_Pressure_diastolic_(mmHg)_(Mean)',\n",
    "    'Non-Invasive_BP_Systolic_(Median)': 'Non_Invasive_Blood_Pressure_diastolic_(mmHg)_(Median)',\n",
    "    'Non-Invasive_BP_Systolic_(Min)': 'Non_Invasive_Blood_Pressure_diastolic_(mmHg)_(Min)',\n",
    "    'Non-Invasive_BP_Mean_(Max)': 'Non_Invasive_Blood_Pressure_mean_(mmHg)_(Max)',\n",
    "    'Non-Invasive_BP_Mean_(Mean)': 'Non_Invasive_Blood_Pressure_mean_(mmHg)_(Mean)',\n",
    "    'Non-Invasive_BP_Mean_(Median)': 'Non_Invasive_Blood_Pressure_mean_(mmHg)_(Median)',\n",
    "    'Non-Invasive_BP_Mean_(Min)': 'Non_Invasive_Blood_Pressure_mean_(mmHg)_(Min)',\n",
    "    'Respiratory_Rate_(Max)': 'Respiratory_Rate_(insp/min)_(Max)',\n",
    "    'Respiratory_Rate_(Mean)': 'Respiratory_Rate_(insp/min)_(Mean)',\n",
    "    'Respiratory_Rate_(Median)': 'Respiratory_Rate_(insp/min)_(Median)',\n",
    "    'Respiratory_Rate_(Min)': 'Respiratory_Rate_(insp/min)_(Min)',\n",
    "    'O2_Saturation_(Max)': 'O2_saturation_pulseoxymetry_(%)_(Max)',\n",
    "    'O2_Saturation_(Mean)': 'O2_saturation_pulseoxymetry_(%)_(Mean)',\n",
    "    'O2_Saturation_(Median)': 'O2_saturation_pulseoxymetry_(%)_(Median)',\n",
    "    'O2_Saturation_(Min)': 'O2_saturation_pulseoxymetry_(%)_(Min)',\n",
    "    'CI_(Max)': 'Chloride_(serum)_(Max)',\n",
    "    'CI_(Mean)': 'Chloride_(serum)_(Mean)',\n",
    "    'CI_(Median)': 'Chloride_(serum)_(Median)',\n",
    "    'CI_(Min)': 'Chloride_(serum)_(Min)',\n",
    "    'calcium_(Max)': 'Calcium_non-ionized_(Max)',\n",
    "    'calcium_(Mean)': 'Calcium_non-ionized_(Mean)',\n",
    "    'calcium_(Median)': 'Calcium_non-ionized_(Median)',\n",
    "    'calcium_(Min)': 'Calcium_non-ionized_(Min)',\n",
    "    'CPK_(Max)': 'CK_(CPK)_(Max)',\n",
    "    'CPK_(Mean)': 'CK_(CPK)_(Mean)',\n",
    "    'CPK_(Median)': 'CK_(CPK)_(Median)',\n",
    "    'CPK_(Min)': 'CK_(CPK)_(Min)',\n",
    "    'Temperature_(F)_(Max)': 'Temperature_Fahrenheit_(F)_(Max)',\n",
    "    'Temperature_(F)_(Mean)': 'Temperature_Fahrenheit_(F)_(Mean)',\n",
    "    'Temperature_(F)_(Median)': 'Temperature_Fahrenheit_(F)_(Median)',\n",
    "    'Temperature_(F)_(Min)': 'Temperature_Fahrenheit_(F)_(Min)',\n",
    "    'Pain_Score_(Max)': 'Pain_Level_(Max)',\n",
    "    'Pain_Score_(Mean)': 'Pain_Level_(Mean)',\n",
    "    'Pain_Score_(Median)': 'Pain_Level_(Median)',\n",
    "    'Pain_Score_(Min)': 'Pain_Level_(Min)',\n",
    "    'LPM_O2_(Max)': 'O2_Flow_(L/min)_(Max)',\n",
    "    'LPM_O2_(Mean)': 'O2_Flow_(L/min)_(Mean)',\n",
    "    'LPM_O2_(Median)': 'O2_Flow_(L/min)_(Median)',\n",
    "    'LPM_O2_(Min)': 'O2_Flow_(L/min)_(Min)',\n",
    "    'O2_L/%_(Max)': 'Inspired_O2_Fraction_(Max)',\n",
    "    'O2_L/%_(Mean)': 'Inspired_O2_Fraction_(Mean)',\n",
    "    'O2_L/%_(Median)': 'Inspired_O2_Fraction_(Median)',\n",
    "    'O2_L/%_(Min)': 'Inspired_O2_Fraction_(Min)',\n",
    "    'ionized_calcium_(Max)': 'Ionized_Calcium_(Max)',\n",
    "    'ionized_calcium_(Mean)': 'Ionized_Calcium_(Mean)',\n",
    "    'ionized_calcium_(Median)': 'Ionized_Calcium_(Median)',\n",
    "    'ionized_calcium_(Min)': 'Ionized_Calcium_(Min)',\n",
    "    'albumin_(Max)': 'Albumin_(Max)',\n",
    "    'albumin_(Mean)': 'Albumin_(Mean)',\n",
    "    'albumin_(Median)': 'Albumin_(Median)',\n",
    "    'albumin_(Min)': 'Albumin_(Min)',\n",
    "    'GCS_Total_(Max)': 'GCS_(Max)',\n",
    "    'GCS_Total_(Mean)': 'GCS_(Mean)',\n",
    "    'GCS_Total_(Median)': 'GCS_(Median)',\n",
    "    'GCS_Total_(Min)': 'GCS_(Min)',\n",
    "    'LDH_(Max)': 'LDH_(Max)',\n",
    "    'LDH_(Mean)': 'LDH_(Mean)',\n",
    "    'LDH_(Median)': 'LDH_(Median)',\n",
    "    'LDH_(Min)': 'LDH_(Min)',\n",
    "    'ethanol_(Max)': 'ETOH_(Max)',\n",
    "    'ethanol_(Mean)': 'ETOH_(Mean)',\n",
    "    'ethanol_(Median)': 'ETOH_(Median)',\n",
    "    'ethanol_(Min)': 'ETOH_(Min)',\n",
    "    'Invasive_BP_Systolic_(Max)': 'Arterial_Blood_Pressure_systolic_(mmHg)_(Max)',\n",
    "    'Invasive_BP_Systolic_(Mean)': 'Arterial_Blood_Pressure_systolic_(mmHg)_(Mean)',\n",
    "    'Invasive_BP_Systolic_(Median)': 'Arterial_Blood_Pressure_systolic_(mmHg)_(Median)',\n",
    "    'Invasive_BP_Systolic_(Min)': 'Arterial_Blood_Pressure_systolic_(mmHg)_(Min)',\n",
    "    'Invasive_BP_Mean_(Max)': 'Arterial_Blood_Pressure_mean_(mmHg)_(Max)',\n",
    "    'Invasive_BP_Mean_(Mean)': 'Arterial_Blood_Pressure_mean_(mmHg)_(Mean)',\n",
    "    'Invasive_BP_Mean_(Median)': 'Arterial_Blood_Pressure_mean_(mmHg)_(Median)',\n",
    "    'Invasive_BP_Mean_(Min)': 'Arterial_Blood_Pressure_mean_(mmHg)_(Min)',\n",
    "    'serum_osmolality_(Max)': 'Serum_Osmolality_(Max)',\n",
    "    'serum_osmolality_(Mean)': 'Serum_Osmolality_(Mean)',\n",
    "    'serum_osmolality_(Median)': 'Serum_Osmolality_(Median)',\n",
    "    'serum_osmolality_(Min)': 'Serum_Osmolality_(Min)',\n",
    "    'troponin_-_I_(Max)': 'Troponin-T_(Max)',\n",
    "    'troponin_-_I_(Mean)': 'Troponin-T_(Mean)',\n",
    "    'troponin_-_I_(Median)': 'Troponin-T_(Median)',\n",
    "    'troponin_-_I_(Min)': 'Troponin-T_(Min)',\n",
    "    'uric_acid_(Max)': 'Uric_Acid_(Max)',\n",
    "    'uric_acid_(Mean)': 'Uric_Acid_(Mean)',\n",
    "    'uric_acid_(Median)': 'Uric_Acid_(Median)',\n",
    "    'uric_acid_(Min)': 'Uric_Acid_(Min)',\n",
    "    'ammonia_(Max)': 'Ammonia_(Max)',\n",
    "    'ammonia_(Mean)': 'Ammonia_(Mean)',\n",
    "    'ammonia_(Median)': 'Ammonia_(Median)',\n",
    "    'ammonia_(Min)': 'Ammonia_(Min)',\n",
    "    'CRP_(Max)': 'C_Reactive_Protein_(CRP)_(Max)',\n",
    "    'CRP_(Mean)': 'C_Reactive_Protein_(CRP)_(Mean)',\n",
    "    'CRP_(Median)': 'C_Reactive_Protein_(CRP)_(Min)',\n",
    "    'CRP_(Min)': 'C_Reactive_Protein_(CRP)_(Median)',\n",
    "    'fibrinogen_(Max)': 'Fibrinogen_(Max)',\n",
    "    'fibrinogen_(Mean)': 'Fibrinogen_(Mean)',\n",
    "    'fibrinogen_(Median)': 'Fibrinogen_(Median)',\n",
    "    'fibrinogen_(Min)': 'Fibrinogen_(Min)',\n",
    "    'PA_Systolic_(Max)': 'Pulmonary_Artery_Pressure_systolic_(mmHg)_(Max)',\n",
    "    'PA_Systolic_(Mean)': 'Pulmonary_Artery_Pressure_systolic_(mmHg)_(Mean)',\n",
    "    'PA_Systolic_(Median)': 'Pulmonary_Artery_Pressure_systolic_(mmHg)_(Median)',\n",
    "    'PA_Systolic_(Min)': 'Pulmonary_Artery_Pressure_systolic_(mmHg)_(Min)',\t\n",
    "    'PA_Diastolic_(Max)': 'Pulmonary_Artery_Pressure_diastolic_(mmHg)_(Max)',\n",
    "    'PA_Diastolic_(Mean)': 'Pulmonary_Artery_Pressure_diastolic_(mmHg)_(Mean)',\n",
    "    'PA_Diastolic_(Median)': 'Pulmonary_Artery_Pressure_diastolic_(mmHg)_(Median)',\n",
    "    'PA_Diastolic_(Min)': 'Pulmonary_Artery_Pressure_diastolic_(mmHg)_(Min)',\n",
    "    'PA_Mean_(Max)': 'Pulmonary_Artery_Pressure_mean_(mmHg)_(Max)',\n",
    "    'PA_Mean_(Mean)': 'Pulmonary_Artery_Pressure_mean_(mmHg)_(Mean)',\n",
    "    'PA_Mean_(Median)': 'Pulmonary_Artery_Pressure_mean_(mmHg)_(Median)',\n",
    "    'PA_Mean_(Min)': 'Pulmonary_Artery_Pressure_mean_(mmHg)_(Min)',\n",
    "    'bedside_glucose_(Max)': 'Glucose_finger_stick_(range_70-100)_(Max)',\n",
    "    'bedside_glucose_(Mean)': 'Glucose_finger_stick_(range_70-100)_(Mean)',\n",
    "    'bedside_glucose_(Median)': 'Glucose_finger_stick_(range_70-100)_(Median)',\n",
    "    'bedside_glucose_(Min)': 'Glucose_finger_stick_(range_70-100)_(Min)',\n",
    "    'reticulocyte_count_(Max)': 'Reticulocyte_Count_Automated_(Mean)',\n",
    "    'reticulocyte_count_(Mean)': 'Reticulocyte_Count_Automated_(Median)',\n",
    "    'reticulocyte_count_(Median)': 'Reticulocyte_Count_Automated_(Min)',\n",
    "    'reticulocyte_count_(Min)': 'Reticulocyte_Count_Automated_(Max)',\n",
    "    '-basos_(Max)': 'Differential-Basos_(Max)',\n",
    "    '-basos_(Mean)': 'Differential-Basos_(Mean)',\n",
    "    '-basos_(Median)': 'Differential-Basos_(Median)',\n",
    "    '-basos_(Min)': 'Differential-Basos_(Min)',\n",
    "    '-eos_(Max)': 'Differential-Eos_(Max)',\n",
    "    '-eos_(Mean)': 'Differential-Eos_(Mean)',\n",
    "    '-eos_(Median)': 'Differential-Eos_(Median)',\n",
    "    '-eos_(Min)': 'Differential-Eos_(Min)',\n",
    "    '-lymphs_(Max)': 'Differential-Lymphs_(Max)',\n",
    "    '-lymphs_(Mean)': 'Differential-Lymphs_(Mean)',\n",
    "    '-lymphs_(Median)': 'Differential-Lymphs_(Median)',\n",
    "    '-lymphs_(Min)': 'Differential-Lymphs_(Min)',\n",
    "    '-monos_(Max)': 'Differential-Monos_(Max)',\n",
    "    '-monos_(Mean)': 'Differential-Monos_(Mean)',\n",
    "    '-monos_(Median)': 'Differential-Monos_(Median)',\n",
    "    '-monos_(Min)': 'Differential-Monos_(Min)',\n",
    "    '-polys_(Max)': 'Differential-Neuts_(Max)',\n",
    "    '-polys_(Mean)': 'Differential-Neuts_(Mean)',\n",
    "    '-polys_(Median)': 'Differential-Neuts_(Median)',\n",
    "    '-polys_(Min)': 'Differential-Neuts_(Min)',\n",
    "    'haptoglobin_(Max)': 'Haptoglobin_(Max)',\n",
    "    'haptoglobin_(Mean)': 'Haptoglobin_(Mean)',\n",
    "    'haptoglobin_(Median)': 'Haptoglobin_(Median)',\n",
    "    'haptoglobin_(Min)': 'Haptoglobin_(Min)',\n",
    "    'direct_bilirubin_(Max)': 'Bilirubin_Direct_(Max)',\n",
    "    'direct_bilirubin_(Mean)': 'Bilirubin_Direct_(Mean)',\n",
    "    'direct_bilirubin_(Median)': 'Bilirubin_Direct_(Median)',\n",
    "    'direct_bilirubin_(Min)': 'Bilirubin_Direct_(Min)',\n",
    "    'free_T4_(Max)': 'Thyroxine_(T4)_Free_(Max)',\n",
    "    'free_T4_(Mean)': 'Thyroxine_(T4)_Free_(Mean)',\n",
    "    'free_T4_(Median)': 'Thyroxine_(T4)_Free_(Median)',\n",
    "    'free_T4_(Min)': 'Thyroxine_(T4)_Free_(Min)',\n",
    "    'ESR_(Max)': 'Sedimentation_Rate_(Max)',\n",
    "    'ESR_(Mean)': 'Sedimentation_Rate_(Mean)',\n",
    "    'ESR_(Median)': 'Sedimentation_Rate_(Median)',\n",
    "    'ESR_(Min)': 'Sedimentation_Rate_(Min)',\n",
    "    'CPK-MB_INDEX_(Max)': 'CK-MB_(Max)',\n",
    "    'CPK-MB_INDEX_(Mean)': 'CK-MB_(Mean)',\n",
    "    'CPK-MB_INDEX_(Median)': 'CK-MB_(Median)',\n",
    "    'CPK-MB_INDEX_(Min)': 'CK-MB_(Min)',\n",
    "    'amylase_(Max)': 'Amylase_(Max)',\n",
    "    'amylase_(Mean)': 'Amylase_(Mean)',\n",
    "    'amylase_(Median)': 'Amylase_(Median)',\n",
    "    'amylase_(Min)': 'Amylase_(Min)',\n",
    "    'PEEP_(Max)': 'PEEP_set_(cmH2O)_(Max)',\n",
    "    'PEEP_(Mean)': 'PEEP_set_(cmH2O)_(Mean)',\n",
    "    'PEEP_(Median)': 'PEEP_set_(cmH2O)_(Median)',\n",
    "    'PEEP_(Min)': 'PEEP_set_(cmH2O)_(Min)',\n",
    "    'CVP_(Max)': 'Central_Venous_Pressure_(mmHg)_(Max)',\n",
    "    'CVP_(Mean)': 'Central_Venous_Pressure_(mmHg)_(Mean)',\n",
    "    'CVP_(Median)': 'Central_Venous_Pressure_(mmHg)_(Median)',\n",
    "    'CVP_(Min)': 'Central_Venous_Pressure_(mmHg)_(Min)',\n",
    "    'total_bilirubin_(Max)': 'Total_Bilirubin_(Max)',\n",
    "    'total_bilirubin_(Mean)': 'Total_Bilirubin_(Mean)',\n",
    "    'total_bilirubin_(Median)': 'Total_Bilirubin_(Median)',\n",
    "    'total_bilirubin_(Min)': 'Total_Bilirubin_(Min)',\n",
    "    'Invasive_BP_Diastolic_(Max)': 'Arterial_Blood_Pressure_diastolic_(mmHg)_(Max)',\n",
    "    'Invasive_BP_Diastolic_(Mean)': 'Arterial_Blood_Pressure_diastolic_(mmHg)_(Mean)',\n",
    "    'Invasive_BP_Diastolic_(Median)': 'Arterial_Blood_Pressure_diastolic_(mmHg)_(Median)',\n",
    "    'Invasive_BP_Diastolic_(Min)': 'Arterial_Blood_Pressure_diastolic_(mmHg)_(Min)',\n",
    "    'unitdischargestatus': 'hospital_expire_flag',\n",
    "    'LOS': 'los'\n",
    "}\n",
    "\n",
    "# Replace the DataFrame and column names mapping\n",
    "eicu_temp.rename(columns=column_eicu_mapping, inplace=True)\n",
    "\n",
    "temperature_rename_mapping = {\n",
    "    'Temperature_Fahrenheit_(°F)_(Max)': 'Temperature_Fahrenheit_(F)_(Max)',\n",
    "    'Temperature_Fahrenheit_(°F)_(Mean)': 'Temperature_Fahrenheit_(F)_(Mean)',\n",
    "    'Temperature_Fahrenheit_(°F)_(Median)': 'Temperature_Fahrenheit_(F)_(Median)',\n",
    "    'Temperature_Fahrenheit_(°F)_(Min)': 'Temperature_Fahrenheit_(F)_(Min)'\n",
    "}\n",
    "\n",
    "# Rename the columns using the dictionary and reassign the DataFrame\n",
    "df_mimic_unique = df_mimic_unique.rename(columns=temperature_rename_mapping)\n",
    "\n",
    "# Remove \"-\" from the 'subject_id' column in eicu\n",
    "eicu_temp['subject_id'] = eicu_temp['subject_id'].str.replace('-', '')\n",
    "\n",
    "# Convert 'subject_id' in eicu to int64\n",
    "eicu_temp['subject_id'] = eicu_temp['subject_id'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c9b177-5a2e-47de-b486-a08a2eef7a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'Survive' with 0 and 'Death' with 1 in the 'hospital_expire_flag' column\n",
    "df_mimic_unique['hospital_expire_flag'] = df_mimic_unique['hospital_expire_flag'].replace({'Survive': 0, 'Death': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6654980-c42c-4750-9ddb-fcc30bb0f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if mimic and eicu datasets have the same dtype and header names\n",
    "# Get the column names from each DataFrame\n",
    "mimic_columns = set(df_mimic_unique.columns)\n",
    "eicu_columns = set(eicu_temp.columns)\n",
    "\n",
    "# Get the column names and dtypes of mimic_df\n",
    "mimic_info = df_mimic_unique.dtypes\n",
    "\n",
    "# Get the column names and dtypes of eicu_df\n",
    "eicu_info = eicu_temp.dtypes\n",
    "\n",
    "# Find the columns that are in mimic_df but not in eicu_df\n",
    "mimic_not_in_eicu = mimic_columns - eicu_columns\n",
    "\n",
    "# Find the columns that are in eicu_df but not in mimic_df\n",
    "eicu_not_in_mimic = eicu_columns - mimic_columns\n",
    "\n",
    "# Display columns that are different\n",
    "if mimic_not_in_eicu:\n",
    "    print(\"Columns in mimic_df but not in eicu_df:\")\n",
    "    print(mimic_not_in_eicu)\n",
    "\n",
    "if eicu_not_in_mimic:\n",
    "    print(\"\\nColumns in eicu_df but not in mimic_df:\")\n",
    "    print(eicu_not_in_mimic)\n",
    "\n",
    "if not mimic_not_in_eicu and not eicu_not_in_mimic:\n",
    "    print(\"The column names are identical between mimic_df and eicu_df.\")\n",
    "\n",
    "# Check if the number of columns is the same\n",
    "if len(mimic_info) != len(eicu_info):\n",
    "    print(\"Number of columns is different between mimic_df and eicu_df.\")\n",
    "else:\n",
    "    # Iterate over the columns and compare the data type.\n",
    "    for column_name in mimic_info.index:\n",
    "        mimic_dtype = mimic_info[column_name]\n",
    "        eicu_dtype = eicu_info[column_name]\n",
    "        if mimic_dtype != eicu_dtype:\n",
    "            print(f\"Column '{column_name}' has different data types: mimic_df has '{mimic_dtype}' and eicu_df has '{eicu_dtype}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62957075-f7d9-43bd-8857-7a1049d16dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'age' in eicu_temp to numeric, handling any non-numeric values by coercing to NaN, then convert to Int64 (nullable integer type)\n",
    "eicu_temp['age'] = pd.to_numeric(eicu_temp['age'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Convert 'hospital_expire_flag' in eicu_temp to numeric, handling non-numeric values, and convert to Int64\n",
    "eicu_temp['hospital_expire_flag'] = pd.to_numeric(eicu_temp['hospital_expire_flag'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Ensure 'age' and 'hospital_expire_flag' in df_mimic_unique are also Int64 to handle any potential missing values consistently\n",
    "df_mimic_unique['age'] = df_mimic_unique['age'].astype('Int64')\n",
    "df_mimic_unique['hospital_expire_flag'] = df_mimic_unique['hospital_expire_flag'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16af2a05-68cd-4606-85b8-9f5f31e00409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put 'hospital_expire_flag' and 'los' to the end of df_mimic_unique\n",
    "hospital_expire_flag_mimic = df_mimic_unique.pop('hospital_expire_flag')\n",
    "los_mimic = df_mimic_unique.pop('los')\n",
    "df_mimic_unique = pd.concat([df_mimic_unique, hospital_expire_flag_mimic, los_mimic], axis=1)\n",
    "\n",
    "# Move 'hospital_expire_flag' and 'los' to the end of eicu_temp\n",
    "hospital_expire_flag_eicu = eicu_temp.pop('hospital_expire_flag')\n",
    "los_eicu = eicu_temp.pop('los')\n",
    "eicu_temp = pd.concat([eicu_temp, hospital_expire_flag_eicu, los_eicu], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f832d9-7945-45cc-a629-2949d58ab207",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    logging.info(\"Starting the export of Mimic DataFrame to a CSV file.\")\n",
    "    \n",
    "    # Define the output path\n",
    "    output_path = (f\"../CSV/exports/final/{subfolder}_mimic.csv\")\n",
    "    output_dir = os.path.dirname(output_path)\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        logging.info(f\"Directory {output_dir} does not exist. Creating it.\")\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Export the merged DataFrame to a CSV file\n",
    "    df_mimic_unique.to_csv(output_path, index=False)\n",
    "    logging.info(f\"DataFrame successfully exported to {output_path}.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred during the export of the DataFrame: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa6918-6452-46ba-ae14-4ccfbc73c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    logging.info(\"Starting the export of eICU DataFrame to a CSV file.\")\n",
    "    \n",
    "    # Define the output path\n",
    "    output_path = (f\"../CSV/exports/final/{subfolder}_eicu.csv\")\n",
    "    output_dir = os.path.dirname(output_path)\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        logging.info(f\"Directory {output_dir} does not exist. Creating it.\")\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Export the merged DataFrame to a CSV file\n",
    "    eicu_temp.to_csv(output_path, index=False)\n",
    "    logging.info(f\"DataFrame successfully exported to {output_path}.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred during the export of the DataFrame: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77862bd6-9b5d-4780-8a82-113fa3a30960",
   "metadata": {},
   "outputs": [],
   "source": [
    "eicu_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3eb8f5-4495-44ea-b59f-a77b8833e008",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mimic_unique.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
