{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "032a1ce8-5983-4e55-9e97-d95caa3b4aad",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77b1d3ab-adbb-4e80-8118-96e78a4df776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "# display Matplotlib plots directly within the notebook interface\n",
    "%matplotlib inline \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn  # neural network\n",
    "import torch.nn.functional as F  # help us move our data forward in function\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_squared_log_error\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f325999-bfaa-40bc-9983-f75093b263ed",
   "metadata": {},
   "source": [
    "# Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f815e91a-e99b-45d8-861c-9eee517658b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We convert the data into float32 because PyTorch expects float 32 values\n",
    "- Compatibility with DL\n",
    "- Memory Efficiency\n",
    "- Prevent errors in training (backpropagation etc)\n",
    "\"\"\"\n",
    "# Define subfolder\n",
    "subfolder = \"o6_GAN/o02\"\n",
    "\n",
    "# Load CSV files into corresponding variables\n",
    "X_external = pd.read_csv(f\"../03_External_Validation/CSV/exports/impute/{subfolder}/X_external.csv\").astype('float32')\n",
    "y_external = pd.read_csv(f\"../03_External_Validation/CSV/exports/impute/{subfolder}/y_external.csv\").values.ravel().astype('float32')\n",
    "X_train = pd.read_csv(f\"../03_External_Validation/CSV/exports/impute/{subfolder}/X_train.csv\").astype('float32')\n",
    "y_train = pd.read_csv(f\"../03_External_Validation/CSV/exports/impute/{subfolder}/y_train.csv\").values.ravel().astype('float32')\n",
    "X_validate = pd.read_csv(f\"../03_External_Validation/CSV/exports/impute/{subfolder}/X_validate.csv\").astype('float32')\n",
    "y_validate = pd.read_csv(f\"../03_External_Validation/CSV/exports/impute/{subfolder}/y_validate.csv\").values.ravel().astype('float32')\n",
    "X_test = pd.read_csv(f\"../03_External_Validation/CSV/exports/impute/{subfolder}/X_test.csv\").astype('float32')\n",
    "y_test = pd.read_csv(f\"../03_External_Validation/CSV/exports/impute/{subfolder}/y_test.csv\").values.ravel().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81b9c234-969a-4262-9baa-dcc44e77d6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "All computations in PyTorch are performed by the use of tensors\n",
    "and not with pandas dataframes or NymPy arrays.\n",
    "\n",
    "X_train.values extract NumPy arrays from pandas dataframe\n",
    "and torch.tensor converts it to PyTorch tensor.\n",
    "\"\"\"\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train.values)\n",
    "y_train = torch.tensor(y_train) # this is already an NymPy array\n",
    "X_validate = torch.tensor(X_validate.values)\n",
    "y_validate = torch.tensor(y_validate) # this is already an NymPy array\n",
    "X_test = torch.tensor(X_test.values)\n",
    "y_test = torch.tensor(y_test) # this is already an NymPy array\n",
    "X_external = torch.tensor(X_external.values)\n",
    "y_external = torch.tensor(y_external) # this is already an NymPy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ded2b6-44ca-4ebd-9c63-938bb258a525",
   "metadata": {},
   "source": [
    "# Simple Feed Forward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13a885af-5426-4b0a-b8ba-c2b3190d75a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Model Class that inherits nn.Module\n",
    "\n",
    "class Model(nn.Module):\n",
    "    # Input layer (344 ICU features) -->\n",
    "    # Hidden Layer 1 (number of neurons) -->\n",
    "    # Hidden Layer 2 (number of neurons) -->\n",
    "    # Output (1 LOS)\n",
    "    def __init__(self, in_features=344, h1=512, h2=256, h3=64, h4=32, out_features=1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.fc3 = nn.Linear(h2, h3)\n",
    "        self.fc4 = nn.Linear(h3, h4)\n",
    "        self.output = nn.Linear(h4, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c940d87b-d98a-4cb3-9fb3-84b7f228a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of a model\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41f1eeaa-2bd8-41d7-ae4b-14071584dbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the criterion of model to measure the error\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Choose Optimizer, set learning rate and epochs (model.parameters are the NN layers)\n",
    "optimizer =torch.optim.Adam(model.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c13403-d6db-4828-b21c-ef8abac953a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.parameters are the NN layers\n",
    "display(model.parameters)\n",
    "print(\"\\n-------------------\\n\")\n",
    "display(list(model.parameters()))\n",
    "print(\"\\n-------------------\\n\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]}\")  # Display first 2 values for brevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60b563e7-4c31-4036-845c-d39880009540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 16.401647567749023\n",
      "Epoch: 10, Loss: 10.0493803024292\n",
      "Epoch: 20, Loss: 9.037598609924316\n",
      "Epoch: 30, Loss: 8.91746711730957\n",
      "Epoch: 40, Loss: 8.744110107421875\n",
      "Epoch: 50, Loss: 8.409981727600098\n",
      "Epoch: 60, Loss: 8.813785552978516\n",
      "Epoch: 70, Loss: 6.989594459533691\n",
      "Epoch: 80, Loss: 5.880810260772705\n",
      "Epoch: 90, Loss: 8.402518272399902\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "epochs = 100\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    # Forward pass\n",
    "    y_pred = model(X_train)\n",
    "    \n",
    "    # Ensure shapes match\n",
    "    y_pred = y_pred.squeeze()  # Make y_pred a 1D tensor\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    \n",
    "    # Track losses\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # Print every 10 epochs\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Epoch: {i}, Loss: {loss.item()}\")\n",
    "    \n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f64353a2-bb03-47a0-baa4-39be2d06ab7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs),losses)\n",
    "plt.ylabel(\"loss/error\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b5a7d3-f9e2-413e-a36b-e861a0655b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cb343f-378d-4406-b904-53e4babd7045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cc2ee0-70a9-46a6-8f91-37f8a389fd70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988b4083-671e-488c-94d6-3f6b588cff88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b5776c-1721-40f7-9852-7a577a7d7047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e518ce2f-934f-46fe-bcc7-adf2d86850df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Feed Forward ANN without HP\n",
    "## Two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadeadd1-df2f-4ae4-99c8-62f082d67a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Layers\n",
    "- Input 128 -> 64 -> 32 -> 1\n",
    "- Each layer use ReLU activation function.\n",
    "\"\"\"\n",
    "\n",
    "# ANN architecture\n",
    "class ANNModel(nn.Module):\n",
    "    # input_dim is the input features and are the same as the dataframe.\n",
    "    def __init__(self, input_dim): \n",
    "        super(ANNModel, self).__init__()\n",
    "        # Define layers. Full features as input and 128 outputs.\n",
    "        # Weight and biases are initialized automatically.\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        # Its techique that randomly set neurons to zero to avoid overfitting\n",
    "        # I must check it further. Propability 0.2 = 20%\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        # Next layer with 128 inputs and 64 outputs.\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        # Its techique that randomly set neurons to zero to avoid overfitting\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        # Next layer with 64 inputs and 32 outputs.\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        # Output layer with 64 inputs 1 output.\n",
    "        self.output = nn.Linear(32, 1)\n",
    "\n",
    "# Feedforward Network\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x)) # Pass the x throught the first dense fc1 with relu function\n",
    "        x = self.dropout1(x) # turn off neurons to prevent overfitting\n",
    "        x = torch.relu(self.fc2(x)) # Pass the x throught the first dense fc2 with relu function\n",
    "        x = self.dropout2(x) # turn off neurons to prevent overfitting\n",
    "        x = torch.relu(self.fc3(x)) # Pass the x throught the first dense fc3 with relu function\n",
    "        x = self.output(x) # output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dd8ca8-657d-4c62-8e81-428e4717d04e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Feed Forward ANN without HP\n",
    "## Three hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0746b18b-64fe-4a68-be00-cab1045c6b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ANNModel, self).__init__()\n",
    "        # Increase the width of the first two layers and add more layers\n",
    "        self.fc1 = nn.Linear(input_dim, 320)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(320, 192)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.fc3 = nn.Linear(192, 128)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        self.fc4 = nn.Linear(128, 96)  # Additional layer\n",
    "        self.dropout4 = nn.Dropout(0.2)  # Additional dropout\n",
    "        self.output = nn.Linear(96, 1)  # Output layer remains the same\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = torch.relu(self.fc4(x))  # Pass through additional layer\n",
    "        x = self.dropout4(x)  # Apply dropout\n",
    "        x = self.output(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cc3ef6-0e98-4931-95d3-a2a8130ec1f9",
   "metadata": {},
   "source": [
    "# HyperOpt Feed Forward ANN\n",
    "## Two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb7c154-aaed-4570-bb1c-47e6b13990ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available and set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the ANN model class\n",
    "class ANNModel(nn.Module):\n",
    "    def __init__(self, input_dim, layer1, layer2, dropout_rate):\n",
    "        super(ANNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, layer1)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(layer1, layer2)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.fc3 = nn.Linear(layer2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)  # No activation in the output layer for regression\n",
    "        return x\n",
    "\n",
    "# Define the objective function\n",
    "def objective(params):\n",
    "    # Unpack parameters\n",
    "    layer1 = int(params['layer1'])\n",
    "    layer2 = int(params['layer2'])\n",
    "    dropout_rate = params['dropout_rate']\n",
    "    learning_rate = params['learning_rate']\n",
    "\n",
    "    # Initialize the model\n",
    "    model = ANNModel(input_dim=X_train.shape[1], layer1=layer1, layer2=layer2, dropout_rate=dropout_rate)\n",
    "    model.to(device)  # Move model to GPU if available\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    epochs = 10  # Use a small number for quick evaluation\n",
    "    batch_size = 32\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for i in range(0, len(X_train), batch_size):\n",
    "            X_batch = X_train[i:i + batch_size].to(device)\n",
    "            y_batch = y_train[i:i + batch_size].unsqueeze(1).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(X_batch)\n",
    "            loss = criterion(predictions, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_predictions = model(X_validate.to(device))\n",
    "        val_loss = mean_squared_error(\n",
    "            y_validate.cpu().numpy(),\n",
    "            val_predictions.cpu().numpy()\n",
    "        )\n",
    "\n",
    "    # Return the loss as the optimization metric\n",
    "    return {'loss': val_loss, 'status': STATUS_OK}\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "param_space = {\n",
    "    'layer1': hp.quniform('layer1', 64, 256, 32),\n",
    "    'layer2': hp.quniform('layer2', 32, 128, 16),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -4, -2),  # log scale for small LR\n",
    "}\n",
    "\n",
    "# Initialize Trials object\n",
    "trials = Trials()\n",
    "\n",
    "# Perform hyperparameter search\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=param_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,  # Number of iterations\n",
    "    trials=trials\n",
    ")\n",
    "\n",
    "print(\"Best Hyperparameters:\", best)\n",
    "\n",
    "# Initialize the model with the best hyperparameters\n",
    "best_model = ANNModel(\n",
    "    input_dim=X_train.shape[1],\n",
    "    layer1=int(best['layer1']),\n",
    "    layer2=int(best['layer2']),\n",
    "    dropout_rate=best['dropout_rate']\n",
    ")\n",
    "best_model.to(device)\n",
    "\n",
    "# Train the best model on the entire training set\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=best['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca81800-791a-45d7-ad5b-5fd2924d367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with the best hyperparameters\n",
    "best_model = ANNModel(\n",
    "    input_dim=X_train.shape[1],\n",
    "    layer1=int(best['layer1']),\n",
    "    layer2=int(best['layer2']),\n",
    "    dropout_rate=best['dropout_rate']\n",
    ")\n",
    "best_model.to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=best['learning_rate'])\n",
    "\n",
    "# Train the final model\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    best_model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        X_batch = X_train[i:i+batch_size].to(device)\n",
    "        y_batch = y_train[i:i+batch_size].unsqueeze(1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = best_model(X_batch)\n",
    "        loss = criterion(predictions, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    best_model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_predictions = best_model(X_validate.to(device))\n",
    "        val_loss = criterion(val_predictions, y_validate.unsqueeze(1).to(device)).item()\n",
    "\n",
    "    train_losses.append(epoch_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {epoch_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Evaluate on test and external validation sets\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = best_model(X_test.to(device))\n",
    "    external_predictions = best_model(X_external.to(device))\n",
    "\n",
    "    # Convert predictions back to CPU for evaluation\n",
    "    test_predictions = test_predictions.cpu().numpy()\n",
    "    external_predictions = external_predictions.cpu().numpy()\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    mse_test = mean_squared_error(y_test.cpu(), test_predictions)\n",
    "    mae_test = mean_absolute_error(y_test.cpu(), test_predictions)\n",
    "    mse_external = mean_squared_error(y_external.cpu(), external_predictions)\n",
    "    mae_external = mean_absolute_error(y_external.cpu(), external_predictions)\n",
    "\n",
    "print(f\"Test Set - MSE: {mse_test:.4f}, MAE: {mae_test:.4f}\")\n",
    "print(f\"External Validation Set - MSE: {mse_external:.4f}, MAE: {mae_external:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4d5640-14d6-46d1-9bef-e81e460e073c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Feed forward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663de2e5-fc4a-4b7a-b02a-9911c8d0c222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "\n",
    "# prepare model to take inputs\n",
    "input_dim = X_train.shape[1] # retrive input features\n",
    "model = ANNModel(input_dim) # creates the model\n",
    "\n",
    "# computes how far from the true values are the predictions\n",
    "criterion = nn.MSELoss() # loss function MSE\n",
    "\n",
    "# update the weights to minimize loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # set Adam optimizer | lr = learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fe1918-0f8f-4359-8ac5-f5016706aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping parameters\n",
    "patience = 5  # Number of epochs to wait for improvement\n",
    "min_delta = 0.001  # Minimum change in validation loss to qualify as an improvement\n",
    "best_val_loss = float('inf')  # Initialize to a very large value\n",
    "patience_counter = 0  # Counter for epochs without improvement\n",
    "\n",
    "# Training the model with early stopping\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "early_stop = False\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "for epoch in range(epochs):\n",
    "    if early_stop:\n",
    "        print(\"Early stopping triggered!\")\n",
    "        break\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size].unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(X_batch)\n",
    "        loss = criterion(predictions, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_predictions = model(X_validate)\n",
    "        val_loss = criterion(val_predictions, y_validate.view(-1, 1))\n",
    "\n",
    "    # Append losses for plotting\n",
    "    train_losses.append(epoch_loss)\n",
    "    val_losses.append(val_loss.item())\n",
    "    \n",
    "    #print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {epoch_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Logging progress\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logging.info(f\"Epoch {epoch+1}/{epochs}, Training Loss: {epoch_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Check for improvement\n",
    "    if best_val_loss - val_loss.item() > min_delta:\n",
    "        best_val_loss = val_loss.item()\n",
    "        patience_counter = 0  # Reset the counter\n",
    "    else:\n",
    "        patience_counter += 1  # Increment the counter\n",
    "        if patience_counter >= patience:\n",
    "            early_stop = True\n",
    "\n",
    "# Plot training and validation losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs with Early Stopping')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c60895-0a6d-4ecc-956d-b742f5cb8f27",
   "metadata": {},
   "source": [
    "# Test & External Validation Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1922c8-3480-4b34-a4d7-6a75d149f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test and external validation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_test_pred = model(X_test).squeeze().numpy()\n",
    "    y_external_pred = model(X_external).squeeze().numpy()\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_r2 = r2_score(y_test, y_test_pred)*100\n",
    "\n",
    "external_mse = mean_squared_error(y_external, y_external_pred)\n",
    "external_mae = mean_absolute_error(y_external, y_external_pred)\n",
    "external_rmse = np.sqrt(external_mse)\n",
    "external_r2 = r2_score(y_external, y_external_pred)*100\n",
    "\n",
    "print(f\"Test Set - MSE: {test_mse:.2f}, MAE: {test_mae:.2f}, RMSE: {test_rmse:.2f}, R2: {test_r2:.2f}\")\n",
    "print(f\"External Validation - MSE: {external_mse:.2f}, MAE: {external_mae:.2f}, RMSE: {external_rmse:.2f}, R2: {external_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ba7784-37f6-4126-b512-c3e9b1a83b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics calculation\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "mae = mean_absolute_error(y_test, y_test_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_test_pred) * 100\n",
    "\n",
    "print(f\"Test Set MSE: {mse:.4f}\")\n",
    "print(f\"Test Set MAE: {mae:.4f}\")\n",
    "print(f\"Test Set RMSE: {rmse:.4f}\")\n",
    "print(f\"Test Set R2: {r2:.4f}\")\n",
    "\n",
    "# Initialize error metrics\n",
    "error_metrics = ['MSE', 'MAE', 'RMSE']\n",
    "values = [mse, mae, rmse]\n",
    "\n",
    "# Try to calculate MSLE\n",
    "try:\n",
    "    msle = mean_squared_log_error(y_test, y_test_pred)\n",
    "    print(f\"Test Set MSLE: {msle:.4f}\")\n",
    "    \n",
    "    # Add MSLE to the list of metrics if applicable\n",
    "    error_metrics.append('MSLE')\n",
    "    values.append(msle)\n",
    "except ValueError:\n",
    "    print(\"Mean Squared Logarithmic Error cannot be calculated because targets contain negative values.\")\n",
    "\n",
    "# Plot error metrics (with or without MSLE)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(error_metrics, values, color=['blue', 'green', 'red', 'orange'][:len(error_metrics)])\n",
    "plt.xlabel('Error Metric')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison of Error Metrics')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R-squared (R2) for the test set\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "if r2 >= 0:\n",
    "    plt.pie([r2, 100 - r2], \n",
    "            labels=['Explained Variance (R2)', 'Unexplained Variance'], \n",
    "            colors=['lightblue', 'lightgrey'], autopct='%1.1f%%')\n",
    "else:\n",
    "    plt.pie([100], labels=['Unexplained Variance'], colors=['lightgrey'], autopct='%1.1f%%')\n",
    "\n",
    "plt.title('Test Set Explained Variance by R-squared (R2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1530c7e1-73f1-4cad-8ce3-3bb218993da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for external validation set\n",
    "mse_external = mean_squared_error(y_external, y_external_pred)\n",
    "mae_external = mean_absolute_error(y_external, y_external_pred)\n",
    "rmse_external = np.sqrt(mse_external)\n",
    "r2_external = r2_score(y_external, y_external_pred) * 100\n",
    "\n",
    "print(f\"External Validation Set MSE: {mse_external:.4f}\")\n",
    "print(f\"External Validation Set MAE: {mae_external:.4f}\")\n",
    "print(f\"External Validation Set RMSE: {rmse_external:.4f}\")\n",
    "print(f\"External Validation Set R2: {r2_external:.4f}\")\n",
    "\n",
    "# Initialize error metrics\n",
    "error_metrics = ['MSE', 'MAE', 'RMSE']\n",
    "values = [mse_external, mae_external, rmse_external]\n",
    "\n",
    "# Try to calculate MSLE\n",
    "try:\n",
    "    msle_external = mean_squared_log_error(y_external, y_external_pred)\n",
    "    print(f\"External Validation Set MSLE: {msle_external:.4f}\")\n",
    "    \n",
    "    # Add MSLE to the list of metrics if applicable\n",
    "    error_metrics.append('MSLE')\n",
    "    values.append(msle_external)\n",
    "except ValueError:\n",
    "    print(\"Mean Squared Logarithmic Error cannot be calculated because targets contain negative values.\")\n",
    "\n",
    "# Plot error metrics (with or without MSLE)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(error_metrics, values, color=['blue', 'green', 'red', 'orange'][:len(error_metrics)])\n",
    "plt.xlabel('Error Metric')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison of Error Metrics')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R-squared (R2) for the external validation set\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "if r2_external >= 0:\n",
    "    plt.pie([r2_external, 100 - r2_external], \n",
    "            labels=['Explained Variance (R2)', 'Unexplained Variance'], \n",
    "            colors=['lightblue', 'lightgrey'], autopct='%1.1f%%')\n",
    "else:\n",
    "    plt.pie([100], labels=['Unexplained Variance'], colors=['lightgrey'], autopct='%1.1f%%')\n",
    "\n",
    "plt.title('Validation Set Explained Variance by R-squared (R2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2891ac33-2a3d-4dbe-a740-249a72defeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_test_pred, color='blue', label='Prediction')\n",
    "\n",
    "# Line for Perfect Prediction\n",
    "perfect_line = np.linspace(y_test.min(), y_test.max(), 100)\n",
    "plt.plot(perfect_line, perfect_line, color='red', linestyle='--', label='Perfect Prediction')\n",
    "\n",
    "# Labels, legend, and grid\n",
    "plt.xlabel('True LOS')\n",
    "plt.ylabel('Predicted LOS')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Predicted vs. True LOS (Test Set)')\n",
    "\n",
    "# Save the plot as a PNG image\n",
    "#plt.savefig(\"plots/02_Prediction_Plot/02_true_vs_pred/57_true_vs_pred_test_plot.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# External Validation Set Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_external, y_external_pred, color='blue', label='Prediction')\n",
    "\n",
    "# Line for Perfect Prediction (y = x)\n",
    "perfect_line_ext = np.linspace(y_external.min(), y_external.max(), 100)\n",
    "plt.plot(perfect_line_ext, perfect_line_ext, color='red', linestyle='--', label='Perfect Prediction')\n",
    "\n",
    "# Labels, legend, and grid\n",
    "plt.xlabel('True LOS')\n",
    "plt.ylabel('Predicted LOS')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Predicted vs. True LOS (External Validation Set)')\n",
    "\n",
    "# Save the plot as a PNG image\n",
    "#plt.savefig(\"plots/02_Prediction_Plot/02_true_vs_pred/57_true_vs_pred_external_plot.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033d76b1-d9af-4790-88d0-752b252b32f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_test to a 1D numpy array\n",
    "y_test = y_test.numpy().flatten()\n",
    "\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = y_test - y_test_pred\n",
    "\n",
    "# Plot residuals\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, residuals, color='blue', alpha=0.5, label=\"Residuals\")\n",
    "plt.axhline(y=0, color='red', linestyle='--', label=\"Zero Line\")\n",
    "plt.axhline(y=mae, color='green', linestyle='--', label=f\"MAE = {mae:.2f}\")\n",
    "plt.axhline(y=-mae, color='green', linestyle='--')\n",
    "plt.xlabel('True LOS')\n",
    "plt.ylabel('Residuals (True - Predicted)')\n",
    "plt.title('Residuals Plot with MAE Bounds')\n",
    "plt.grid(True)\n",
    "\n",
    "# Place the legend outside of the plot\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Save the plot as a PNG image\n",
    "#plt.savefig(\"plots/02_Prediction_Plot/01_residuals/57_residuals_plot.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdcb3a1-b975-4325-b2af-eaa3539f2b67",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4832b64-6291-4691-8919-ed8db53c19fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file\n",
    "subfolder = \"o01_feed_forward.pth\"\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), f\"models/{subfolder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fc07dc-610f-43da-bbc3-3f1951d15037",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262423c6-8c12-492e-b6cd-ab78ec3d7b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file\n",
    "subfolder = \"o01_feed_forward.pth\"\n",
    "\n",
    "# Reinitialize the model architecture\n",
    "input_dim = X_test.shape[1]  # Ensure this matches the original input dimension\n",
    "model = ANNModel(input_dim)\n",
    "\n",
    "# Load the saved model state\n",
    "model.load_state_dict(torch.load(f\"models/{subfolder}\"))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "\"\"\"\n",
    "After that I must run the block with layers.\n",
    "Be careful, the layers must be exaclty the same. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9418b819-e643-4f8e-9268-c6e1e45cbb78",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d389220-2d54-4e61-9331-c3ef98a4c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(X):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tensor_X = torch.tensor(X, dtype=torch.float32)\n",
    "        predictions = model(tensor_X).numpy()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d0defa-f61d-4841-831e-a65f62e163d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tensors to Pandas DataFrames\n",
    "X_sample_df = pd.DataFrame(X_sample_np, columns=[f\"Feature_{i}\" for i in range(X_sample_np.shape[1])])\n",
    "X_validate_df = pd.DataFrame(X_validate_np, columns=[f\"Feature_{i}\" for i in range(X_validate_np.shape[1])])\n",
    "\n",
    "# Use KernelExplainer with Pandas DataFrame\n",
    "explainer = shap.KernelExplainer(model_predict, X_sample_df)\n",
    "shap_values = explainer.shap_values(X_validate_df)\n",
    "\n",
    "# Summary plot\n",
    "shap.summary_plot(shap_values, X_validate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d6a10-d882-427f-bae1-eaa908c80ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
