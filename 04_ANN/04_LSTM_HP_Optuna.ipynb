{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6754cd06-f12e-4548-b461-5bf2d8ba7bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "import h5py # Save - Load 3D tensor\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "from tqdm import tqdm \n",
    "\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# display Matplotlib plots directly within the notebook interface\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_squared_log_error\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c99fbcd6-5e7e-480e-8cd7-5261b46ef4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"logging.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "500c05d2-855b-4867-a77c-677a0ddacc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'hierarchical_attempt_II'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cc0e25c-c96d-41c1-a831-67c7ef1c2b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 00:29:44,481 - INFO - Loading...\n",
      "2025-02-20 00:29:45,502 - INFO - Train: (122496, 345, 4), Los Label: (122496, 1), Mortality Label: (122496, 1)\n",
      "2025-02-20 00:29:45,503 - INFO - Validate: (15312, 345, 4), Los Label: (15312, 1), Mortality Label: (15312, 1)\n",
      "2025-02-20 00:29:45,504 - INFO - Test: (15312, 345, 4), Los Label: (15312, 1), Mortality Label: (15312, 1)\n",
      "2025-02-20 00:29:45,505 - INFO - External: (234720, 345, 4), Los Label: (234720, 1), Mortality Label: (234720, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load tensors from the HDF5 file\n",
    "load_path = 'CSV/exports/tensors/o4_3D_four_dataframe_hierarchical.h5'\n",
    "\n",
    "logging.info(f\"Loading...\")\n",
    "with h5py.File(load_path, 'r') as hf:\n",
    "    train_tensor = hf['train_tensor'][:]\n",
    "    validate_tensor = hf['validate_tensor'][:]\n",
    "    test_tensor = hf['test_tensor'][:]\n",
    "    external_tensor = hf['external_tensor'][:]\n",
    "    # los\n",
    "    train_los_label = hf['train_los_label'][:]\n",
    "    validate_los_label = hf['validate_los_label'][:]\n",
    "    test_los_label = hf['test_los_label'][:]\n",
    "    external_los_label = hf['external_los_label'][:]\n",
    "    # mortality\n",
    "    train_mortality_label = hf['train_mortality_label'][:]\n",
    "    validate_mortality_label = hf['validate_mortality_label'][:]\n",
    "    test_mortality_label = hf['test_mortality_label'][:]\n",
    "    external_mortality_label = hf['external_mortality_label'][:]\n",
    "\n",
    "logging.info(f\"Train: {train_tensor.shape}, Los Label: {train_los_label.shape}, Mortality Label: {train_mortality_label.shape}\")\n",
    "logging.info(f\"Validate: {validate_tensor.shape}, Los Label: {validate_los_label.shape}, Mortality Label: {validate_mortality_label.shape}\")\n",
    "logging.info(f\"Test: {test_tensor.shape}, Los Label: {test_los_label.shape}, Mortality Label: {test_mortality_label.shape}\")\n",
    "logging.info(f\"External: {external_tensor.shape}, Los Label: {external_los_label.shape}, Mortality Label: {external_mortality_label.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b108afd5-72de-4f89-bf28-d167de796761",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMAttentionMultiTask(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, num_layers, dropout):\n",
    "        super(LSTMAttentionMultiTask, self).__init__()\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Define LSTM layers dynamically\n",
    "        self.lstms = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            input_dim = input_size if i == 0 else hidden_sizes[i-1]\n",
    "            hidden_dim = hidden_sizes[i]\n",
    "\n",
    "            if num_layers > 1:\n",
    "                self.lstms.append(nn.LSTM(input_dim, hidden_dim, batch_first=True, dropout=dropout))\n",
    "            else:\n",
    "                self.lstms.append(nn.LSTM(input_dim, hidden_dim, batch_first=True))  # No dropout when num_layers=1\n",
    "\n",
    "        # Attention Layer\n",
    "        self.attn = nn.Linear(hidden_sizes[-1], 1)\n",
    "\n",
    "        # Fully Connected Layers for Multi-task Learning\n",
    "        self.fc_los = nn.Linear(hidden_sizes[-1], 1)  # Regression Output (LOS)\n",
    "        self.fc_mortality = nn.Linear(hidden_sizes[-1], 1)  # Classification Output (Mortality)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        out = x\n",
    "\n",
    "        # Initialize hidden and cell states dynamically for each LSTM layer\n",
    "        hidden_states = [(torch.zeros(1, batch_size, h).to(x.device), torch.zeros(1, batch_size, h).to(x.device)) \n",
    "                         for h in self.hidden_sizes]\n",
    "\n",
    "        for i, lstm in enumerate(self.lstms):\n",
    "            out, hidden_states[i] = lstm(out, hidden_states[i])\n",
    "\n",
    "        # Attention Mechanism\n",
    "        attn_weights = torch.tanh(self.attn(out))\n",
    "        attn_weights = torch.softmax(attn_weights, dim=1)\n",
    "        context_vector = torch.sum(attn_weights * out, dim=1)\n",
    "\n",
    "        # Multi-task outputs\n",
    "        los_output = self.fc_los(context_vector)  # Regression\n",
    "        mortality_output = torch.sigmoid(self.fc_mortality(context_vector))  # Classification\n",
    "\n",
    "        return los_output, mortality_output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "307b5a5b-a401-4d04-b786-bf5a72afa70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_train = torch.tensor(train_tensor, dtype=torch.float32)\n",
    "y_train = torch.tensor(train_los_label, dtype=torch.float32)\n",
    "\n",
    "X_validate = torch.tensor(validate_tensor, dtype=torch.float32)\n",
    "y_validate = torch.tensor(validate_los_label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe17edb-26f5-4de5-adeb-22e2bf9d017d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 00:29:51,809] A new study created in memory with name: no-name-7769b2a3-d27a-45d5-bcf5-ce1a4af762ce\n",
      "2025-02-20 00:29:51,813 - INFO - Using num_layers=2, dropout=0.15663027648114797\n",
      "C:\\Users\\Dimopoulos\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.15663027648114797 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "[I 2025-02-20 11:27:20,377] Trial 0 finished with value: 5.806441350729207 and parameters: {'num_layers': 2, 'hidden_size_0': 256, 'hidden_size_1': 256, 'dropout': 0.15663027648114797, 'lr': 0.0035481206428426945}. Best is trial 0 with value: 5.806441350729207.\n",
      "2025-02-20 11:27:20,379 - INFO - Using num_layers=3, dropout=0.16264335903732097\n",
      "C:\\Users\\Dimopoulos\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.16264335903732097 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "[I 2025-02-20 15:48:30,395] Trial 1 finished with value: 6.282200840653731 and parameters: {'num_layers': 3, 'hidden_size_0': 192, 'hidden_size_1': 192, 'hidden_size_2': 192, 'dropout': 0.16264335903732097, 'lr': 0.0001246853451084988}. Best is trial 0 with value: 5.806441350729207.\n",
      "2025-02-20 15:48:30,397 - INFO - Using num_layers=2, dropout=0.4230508201748824\n",
      "C:\\Users\\Dimopoulos\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4230508201748824 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "[I 2025-02-20 19:33:43,355] Trial 2 finished with value: 6.446342660398038 and parameters: {'num_layers': 2, 'hidden_size_0': 64, 'hidden_size_1': 256, 'dropout': 0.4230508201748824, 'lr': 0.0003839353261711168}. Best is trial 0 with value: 5.806441350729207.\n",
      "2025-02-20 19:33:43,358 - INFO - Using num_layers=3, dropout=0.3566632343517557\n",
      "C:\\Users\\Dimopoulos\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3566632343517557 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "[I 2025-02-21 05:59:43,315] Trial 3 finished with value: 6.51450477596489 and parameters: {'num_layers': 3, 'hidden_size_0': 192, 'hidden_size_1': 128, 'hidden_size_2': 192, 'dropout': 0.3566632343517557, 'lr': 0.006285279332654128}. Best is trial 0 with value: 5.806441350729207.\n",
      "2025-02-21 05:59:43,317 - INFO - Using num_layers=2, dropout=0.20472663373621247\n",
      "C:\\Users\\Dimopoulos\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.20472663373621247 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "[I 2025-02-21 12:39:55,595] Trial 4 finished with value: 5.732344487141468 and parameters: {'num_layers': 2, 'hidden_size_0': 256, 'hidden_size_1': 64, 'dropout': 0.20472663373621247, 'lr': 0.0008035299799532029}. Best is trial 4 with value: 5.732344487141468.\n",
      "2025-02-21 12:39:55,597 - INFO - Using num_layers=3, dropout=0.07957421191980074\n",
      "C:\\Users\\Dimopoulos\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.07957421191980074 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "[I 2025-02-22 04:58:50,385] Trial 5 finished with value: 5.653776487222793 and parameters: {'num_layers': 3, 'hidden_size_0': 256, 'hidden_size_1': 192, 'hidden_size_2': 64, 'dropout': 0.07957421191980074, 'lr': 0.002616176906323012}. Best is trial 5 with value: 5.653776487222793.\n",
      "2025-02-22 04:58:50,387 - INFO - Using num_layers=2, dropout=0.4136273121955126\n",
      "C:\\Users\\Dimopoulos\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4136273121955126 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "[I 2025-02-22 06:42:04,247] Trial 6 finished with value: 6.514079142385211 and parameters: {'num_layers': 2, 'hidden_size_0': 64, 'hidden_size_1': 192, 'dropout': 0.4136273121955126, 'lr': 0.0002069009677965323}. Best is trial 5 with value: 5.653776487222793.\n",
      "2025-02-22 06:42:04,249 - INFO - Using num_layers=2, dropout=0.44916605940827825\n",
      "C:\\Users\\Dimopoulos\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.44916605940827825 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "[I 2025-02-22 09:38:19,909] Trial 7 finished with value: 7.4123511180934925 and parameters: {'num_layers': 2, 'hidden_size_0': 192, 'hidden_size_1': 256, 'dropout': 0.44916605940827825, 'lr': 0.00012721241566451447}. Best is trial 5 with value: 5.653776487222793.\n",
      "2025-02-22 09:38:19,911 - INFO - Using num_layers=2, dropout=0.11183026828234355\n",
      "C:\\Users\\Dimopoulos\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.11183026828234355 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "# Objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Hyperparameters to optimize\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 2, 3)\n",
    "    hidden_sizes = [trial.suggest_int(f\"hidden_size_{i}\", 64, 256, step=64) for i in range(num_layers)]\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "    if num_layers == 1:\n",
    "        dropout = 0.0  # Explicitly override any suggested value\n",
    "\n",
    "    # Ensure the model never receives a nonzero dropout when num_layers=1\n",
    "    logging.info(f\"Using num_layers={num_layers}, dropout={dropout}\") \n",
    "\n",
    "\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)  # Updated fix for deprecated function\n",
    "\n",
    "    # Initialize model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = LSTMAttentionMultiTask(input_size=4, hidden_sizes=hidden_sizes, num_layers=num_layers, dropout=dropout).to(device)\n",
    "\n",
    "    # Define losses & optimizer\n",
    "    criterion_los = nn.MSELoss()\n",
    "    criterion_mortality = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Training Setup\n",
    "    epochs = 15\n",
    "    batch_size = 32\n",
    "    patience = 3\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    early_stop = False\n",
    "\n",
    "    # Load Data\n",
    "    train_dataset = TensorDataset(torch.tensor(train_tensor, dtype=torch.float32),\n",
    "                                  torch.tensor(train_los_label, dtype=torch.float32),\n",
    "                                  torch.tensor(train_mortality_label, dtype=torch.float32))\n",
    "\n",
    "    validate_dataset = TensorDataset(torch.tensor(validate_tensor, dtype=torch.float32),\n",
    "                                     torch.tensor(validate_los_label, dtype=torch.float32),\n",
    "                                     torch.tensor(validate_mortality_label, dtype=torch.float32))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    validate_loader = DataLoader(validate_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    # Training Loop\n",
    "    for epoch in range(epochs):\n",
    "        if early_stop:\n",
    "            break\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for X_batch, y_los_batch, y_mort_batch in train_loader:\n",
    "            X_batch, y_los_batch, y_mort_batch = X_batch.to(device), y_los_batch.to(device), y_mort_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred_los, pred_mortality, _ = model(X_batch)\n",
    "\n",
    "            loss_los = criterion_los(pred_los.squeeze(), y_los_batch.squeeze())\n",
    "            loss_mortality = criterion_mortality(pred_mortality.squeeze(), y_mort_batch.squeeze())\n",
    "\n",
    "            total_loss = loss_los + loss_mortality\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += total_loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_val_batch, y_val_los_batch, y_val_mort_batch in validate_loader:\n",
    "                X_val_batch, y_val_los_batch, y_val_mort_batch = X_val_batch.to(device), y_val_los_batch.to(device), y_val_mort_batch.to(device)\n",
    "\n",
    "                val_pred_los, val_pred_mort, _ = model(X_val_batch)\n",
    "\n",
    "                val_loss_los = criterion_los(val_pred_los.squeeze(), y_val_los_batch.squeeze())\n",
    "                val_loss_mortality = criterion_mortality(val_pred_mort.squeeze(), y_val_mort_batch.squeeze())\n",
    "\n",
    "                total_val_loss = val_loss_los + val_loss_mortality\n",
    "                val_loss += total_val_loss.item()\n",
    "\n",
    "        val_loss /= len(validate_loader)\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                early_stop = True\n",
    "\n",
    "    return best_val_loss\n",
    "\n",
    "# Run Optuna Hyperparameter Optimization\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Best hyperparameters found\n",
    "best_params = study.best_params\n",
    "logging.info(f\"Best Hyperparameters: {best_params}\")\n",
    "\n",
    "# Train final model using best parameters\n",
    "best_hidden_sizes = [best_params[f\"hidden_size_{i}\"] for i in range(best_params[\"num_layers\"])]\n",
    "best_model = LSTMAttentionMultiTask(input_size=4, hidden_sizes=best_hidden_sizes, num_layers=best_params[\"num_layers\"], dropout=best_params[\"dropout\"])\n",
    "best_model.to(device)\n",
    "\n",
    "# Save best model\n",
    "torch.save(best_model.state_dict(), \"models/lstm_attention_hyperopt.pth\")\n",
    "logging.info(\"Best model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaf4680-c966-467a-a984-bd91aa62717e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809c0dec-fc8d-4363-a6e3-2cbc740dfe3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83f9278-8054-4650-a9d7-1f307128c7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88bb57c-4811-4ee8-b3e4-e31c0b008357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0916b0f-8d38-498a-8583-2f966c888870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adeb9f1-42a2-4490-b518-6b7d761e2688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa4b42-51d9-4554-a4bd-a3a87b3bebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "input_size = X_train.shape[2]  # Number of features\n",
    "hidden_sizes = [256, 128, 64]  # LSTM layers sizes\n",
    "\n",
    "# Instantiate model\n",
    "model = LSTMAttentionMultiTask(input_size, hidden_sizes)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Print model architecture\n",
    "logging.info(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3f5ebe-4eb6-4d41-b1a5-2e32707b97b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Losses & Optimizer\n",
    "criterion_los = nn.MSELoss()  # Loss for LOS (Regression)\n",
    "criterion_mortality = nn.BCELoss()  # Loss for Mortality (Binary Classification)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "# Training Setup\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "patience = 5\n",
    "min_delta = 0.001\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "early_stop = False\n",
    "\n",
    "# DataLoaders\n",
    "train_dataset = TensorDataset(torch.tensor(train_tensor, dtype=torch.float32), \n",
    "                              torch.tensor(train_los_label, dtype=torch.float32),\n",
    "                              torch.tensor(train_mortality_label, dtype=torch.float32))\n",
    "\n",
    "validate_dataset = TensorDataset(torch.tensor(validate_tensor, dtype=torch.float32), \n",
    "                                 torch.tensor(validate_los_label, dtype=torch.float32),\n",
    "                                 torch.tensor(validate_mortality_label, dtype=torch.float32))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "validate_loader = DataLoader(validate_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e45444-8f07-4348-ae9e-8711c1448d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to CPU before saving\n",
    "model.to(\"cpu\")\n",
    "\n",
    "# Define the model save path\n",
    "model_save_path = f\"models/{file_name}_model.pth\"\n",
    "\n",
    "# Save the trained model's state dictionary\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "# Confirm model saving\n",
    "print(f\"Model saved successfully at {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0457e8d1-c979-41d4-be7b-bc8258350291",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Step 1: Get Attention Scores for a Sample\"\"\"\n",
    "# Select a random sample from the validation set\n",
    "sample_idx = np.random.randint(len(validate_dataset))\n",
    "X_sample, _, _ = validate_dataset[sample_idx]  # Only take the input tensor\n",
    "X_sample = X_sample.unsqueeze(0).to(device)  # Add batch dimension\n",
    "\n",
    "# Get model output and attention weights\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    _, _, attn_weights = model(X_sample)  # Get attention scores\n",
    "\n",
    "# Convert attention weights to numpy\n",
    "attn_weights = attn_weights.squeeze().cpu().numpy()  # Shape: (seq_len, 1)\n",
    "seq_len = attn_weights.shape[0]\n",
    "\n",
    "# Plot attention weights\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(range(seq_len), attn_weights, marker=\"o\", linestyle=\"-\", label=\"Attention Score\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Attention Score\")\n",
    "plt.title(\"Attention Weights Over Time for a Single Patient\")\n",
    "plt.legend()\n",
    "plt.savefig(f'plots/tensor/02_attention_weight/{file_name}_single_patient.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6357eda1-f564-41c5-93b3-9f8a3324f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Step 2: Compare Attention Across Multiple Patients\"\"\"\n",
    "num_samples = 5  # Number of patients to visualize\n",
    "all_attn_weights = []\n",
    "\n",
    "# Select multiple random samples\n",
    "random_indices = np.random.choice(len(validate_dataset), num_samples, replace=False)\n",
    "\n",
    "for idx in random_indices:\n",
    "    X_sample, _, _ = validate_dataset[idx]\n",
    "    X_sample = X_sample.unsqueeze(0).to(device)  # Add batch dimension\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _, _, attn_weights = model(X_sample)\n",
    "\n",
    "    attn_weights = attn_weights.squeeze().cpu().numpy()\n",
    "    all_attn_weights.append(attn_weights)\n",
    "\n",
    "# Convert to NumPy array and compute mean attention weights\n",
    "all_attn_weights = np.array(all_attn_weights)  # Shape: (num_samples, seq_len)\n",
    "mean_attn_weights = np.mean(all_attn_weights, axis=0)  # Average over patients\n",
    "\n",
    "# Plot Mean Attention Weights\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(range(seq_len), mean_attn_weights, marker=\"o\", linestyle=\"-\", color='red', label=\"Mean Attention Score\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Mean Attention Score\")\n",
    "plt.title(\"Average Attention Weights Over Multiple Patients\")\n",
    "plt.legend()\n",
    "plt.savefig(f'plots/tensor/02_attention_weight/{file_name}_multiple_patients.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a44689-ed24-4c14-a88c-6371a5e4013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Step 3: Visualize LOS vs. Mortality Attention Differences\"\"\"\n",
    "\n",
    "num_samples = 5  # Number of patients to visualize\n",
    "los_attn_weights = []\n",
    "mortality_attn_weights = []\n",
    "\n",
    "# Select multiple random samples\n",
    "random_indices = np.random.choice(len(validate_dataset), num_samples, replace=False)\n",
    "\n",
    "for idx in random_indices:\n",
    "    X_sample, _, _ = validate_dataset[idx]\n",
    "    X_sample = X_sample.unsqueeze(0).to(device)  # Add batch dimension\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        los_pred, mort_pred, attn_weights = model(X_sample)\n",
    "\n",
    "    attn_weights = attn_weights.squeeze().cpu().numpy()\n",
    "\n",
    "    # Separate LOS and Mortality predictions' attention scores\n",
    "    los_attn_weights.append(attn_weights * los_pred.item())  # Weight by LOS\n",
    "    mortality_attn_weights.append(attn_weights * mort_pred.item())  # Weight by Mortality\n",
    "\n",
    "# Compute mean attention scores\n",
    "los_attn_weights = np.mean(np.array(los_attn_weights), axis=0)\n",
    "mortality_attn_weights = np.mean(np.array(mortality_attn_weights), axis=0)\n",
    "\n",
    "# Plot both attention weights\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(range(seq_len), los_attn_weights, marker=\"o\", linestyle=\"-\", label=\"LOS Attention\", color=\"blue\")\n",
    "plt.plot(range(seq_len), mortality_attn_weights, marker=\"o\", linestyle=\"-\", label=\"Mortality Attention\", color=\"green\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Weighted Attention Score\")\n",
    "plt.title(\"Comparison of Attention Weights for LOS vs. Mortality\")\n",
    "plt.savefig(f'plots/tensor/02_attention_weight/{file_name}_los_vs_mortality.png')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f6980c-403c-4607-a7a0-69c09d5d5965",
   "metadata": {},
   "source": [
    "# Training Performance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fdca8c-6ccd-4add-ba20-5d884052b772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure train_losses and val_losses are aligned\n",
    "min_len = min(len(train_losses), len(val_losses))  # Align lengths if different\n",
    "train_losses = train_losses[:min_len]\n",
    "val_losses = val_losses[:min_len]\n",
    "\n",
    "# Identify the best epoch where early stopping occurred\n",
    "best_epoch = min_len - patience_counter  # patience_counter tracks epochs without improvement\n",
    "\n",
    "# Plot Training Loss\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))  # Initialize plot with size\n",
    "line1 = ax1.plot(range(1, min_len + 1), train_losses, label='Training Loss', color='b')\n",
    "ax1.set_xlabel('Epochs')  # Label for X-axis\n",
    "ax1.set_ylabel('Training Loss', color='b')  # Label for Y-axis on the left\n",
    "ax1.tick_params(axis='y', labelcolor='b')  # Left Y-axis tick color\n",
    "ax1.grid(visible=True, linestyle='--', alpha=0.6)  # Add grid for clarity\n",
    "\n",
    "# Plot Validation Loss on a Secondary Y-Axis\n",
    "ax2 = ax1.twinx()  # Create twin axes for validation loss\n",
    "line2 = ax2.plot(range(1, min_len + 1), val_losses, label='Validation Loss', color='orange')\n",
    "ax2.set_ylabel('Validation Loss', color='orange')  # Label for Y-axis on the right\n",
    "ax2.tick_params(axis='y', labelcolor='orange')  # Right Y-axis tick color\n",
    "\n",
    "# Highlight Early Stopping Point\n",
    "line3 = ax1.axvline(best_epoch, color='r', linestyle='--', label='Early Stopping Point')\n",
    "\n",
    "# Combine Legends from Both Axes\n",
    "lines = line1 + line2 + [line3]  # Combine lines from both Y-axes\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc='upper right')  # Display legend\n",
    "\n",
    "# Add Title and Final Touches\n",
    "plt.title('Training and Validation Loss Over Epochs with Early Stopping')\n",
    "fig.tight_layout()  # Adjust spacing to prevent overlap\n",
    "plt.savefig(f'plots/tensor/01_train_vall_loss/{file_name}_train_val_over_epoch.png')\n",
    "# Display the Plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddb9fd3-ce89-49cf-9e88-d1b8f1682c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Ensure external_tensor and external_los_label are PyTorch tensors\n",
    "if isinstance(external_tensor, np.ndarray):\n",
    "    external_tensor = torch.tensor(external_tensor, dtype=torch.float32)\n",
    "if isinstance(external_los_label, np.ndarray):\n",
    "    external_los_label = torch.tensor(external_los_label, dtype=torch.float32)\n",
    "\n",
    "# Print shapes to debug\n",
    "print(f\"external_tensor shape: {external_tensor.shape}\")\n",
    "print(f\"external_los_label shape: {external_los_label.shape}\")\n",
    "\n",
    "# Check if dimensions match\n",
    "if external_tensor.shape[0] != external_los_label.shape[0]:\n",
    "    raise ValueError(f\"Mismatch: external_tensor has {external_tensor.shape[0]} rows, \"\n",
    "                     f\"but external_los_label has {external_los_label.shape[0]} rows.\")\n",
    "\n",
    "# Create DataLoader for External Validation Set\n",
    "external_dataset = TensorDataset(external_tensor, external_los_label)\n",
    "external_loader = DataLoader(external_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "print(\"External DataLoader created successfully!\")\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Ensure external_tensor and external_los_label are PyTorch tensors\n",
    "if isinstance(external_tensor, np.ndarray):\n",
    "    external_tensor = torch.tensor(external_tensor, dtype=torch.float32)\n",
    "if isinstance(external_los_label, np.ndarray):\n",
    "    external_los_label = torch.tensor(external_los_label, dtype=torch.float32)\n",
    "\n",
    "# Reshape external_los_label to match the batch size\n",
    "external_los_label = external_los_label.view(-1)  # Flatten to (234720,)\n",
    "\n",
    "# Print shapes to debug\n",
    "print(f\"Final: external_tensor shape: {external_tensor.shape}\")  # (234720, 345, 4)\n",
    "print(f\"Final: external_los_label shape: {external_los_label.shape}\")  # (234720,)\n",
    "\n",
    "# Create DataLoader for External Validation Set\n",
    "external_dataset = TensorDataset(external_tensor, external_los_label)\n",
    "external_loader = DataLoader(external_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "print(\"External DataLoader created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c902be-ef4b-4d9d-a26d-ab4d1022ba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Create DataLoader for Test Set\n",
    "test_dataset = TensorDataset(test_tensor, test_los_label)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "# Create DataLoader for External Validation Set\n",
    "external_dataset = TensorDataset(external_tensor, external_los_label)\n",
    "external_loader = DataLoader(external_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "# Move model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize lists to store predictions and true labels\n",
    "y_test_preds, y_test_trues = [], []\n",
    "y_external_preds, y_external_trues = [], []\n",
    "\n",
    "# Run batch-wise inference for test set with progress bar\n",
    "logging.info(\"Running inference on the Test Set...\")\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in tqdm(test_loader, desc=\"Processing Test Set\", unit=\"batch\"):\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        y_pred_batch, _, _ = model(X_batch)  # Get predictions\n",
    "\n",
    "        # Store predictions and labels\n",
    "        y_test_preds.append(y_pred_batch.cpu().numpy())\n",
    "        y_test_trues.append(y_batch.cpu().numpy())\n",
    "\n",
    "# Run batch-wise inference for external validation set with progress bar\n",
    "logging.info(\"Running inference on the External Validation Set...\")\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in tqdm(external_loader, desc=\"Processing External Set\", unit=\"batch\"):\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        y_pred_batch, _, _ = model(X_batch)  # Get predictions\n",
    "\n",
    "        # Store predictions and labels\n",
    "        y_external_preds.append(y_pred_batch.cpu().numpy())\n",
    "        y_external_trues.append(y_batch.cpu().numpy())\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "y_test_true = np.concatenate(y_test_trues).squeeze()\n",
    "y_test_pred = np.concatenate(y_test_preds).squeeze()\n",
    "\n",
    "y_external_true = np.concatenate(y_external_trues).squeeze()\n",
    "y_external_pred = np.concatenate(y_external_preds).squeeze()\n",
    "\n",
    "# Calculate metrics for the Test Set\n",
    "logging.info(\"Calculating metrics for the Test Set...\")\n",
    "test_mse = mean_squared_error(y_test_true, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test_true, y_test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_r2 = r2_score(y_test_true, y_test_pred) * 100  # R² in percentage\n",
    "\n",
    "# Calculate metrics for the External Validation Set\n",
    "logging.info(\"Calculating metrics for the External Validation Set...\")\n",
    "external_mse = mean_squared_error(y_external_true, y_external_pred)\n",
    "external_mae = mean_absolute_error(y_external_true, y_external_pred)\n",
    "external_rmse = np.sqrt(external_mse)\n",
    "external_r2 = r2_score(y_external_true, y_external_pred) * 100  # R² in percentage\n",
    "\n",
    "# Print results with progress messages\n",
    "logging.info(\"Final Results:\")\n",
    "logging.info(f\"Test Set - MSE: {test_mse:.2f}, MAE: {test_mae:.2f}, RMSE: {test_rmse:.2f}, R2: {test_r2:.2f}%\")\n",
    "logging.info(f\"External Validation - MSE: {external_mse:.2f}, MAE: {external_mae:.2f}, RMSE: {external_rmse:.2f}, R2: {external_r2:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6439d3a4-6ed0-4de6-88ef-f445d9605e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging info\n",
    "logging.info(\"Calculating metrics for the Test Set...\")\n",
    "\n",
    "# Initialize error metrics\n",
    "error_metrics = ['MSE', 'MAE', 'RMSE']\n",
    "values = [test_mse, test_mae, test_rmse]\n",
    "\n",
    "# Try to calculate MSLE\n",
    "try:\n",
    "    test_msle = mean_squared_log_error(y_test_true, y_test_pred)\n",
    "    error_metrics.append('MSLE')\n",
    "    values.append(test_msle)\n",
    "except ValueError:\n",
    "    test_msle = None  # Handle cases where MSLE cannot be calculated\n",
    "\n",
    "# Plot error metrics\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(error_metrics, values, color=['blue', 'green', 'red', 'orange'][:len(error_metrics)])\n",
    "plt.xlabel('Error Metric')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison of Error Metrics (Test Set)')\n",
    "\n",
    "# Annotate values on top of the bars\n",
    "for bar, value in zip(bars, values):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{value:.2f}', \n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "plt.savefig(f'plots/tensor/03_metrics/{file_name}_test_set_metrics.png')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R-squared (R2) for the test set\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "if test_r2 >= 0:\n",
    "    plt.pie([test_r2, 100 - test_r2], \n",
    "            labels=['Explained Variance (R2)', 'Unexplained Variance'], \n",
    "            colors=['lightblue', 'lightgrey'], autopct='%1.1f%%')\n",
    "else:\n",
    "    plt.pie([100], labels=['Unexplained Variance'], colors=['lightgrey'], autopct='%1.1f%%')\n",
    "\n",
    "plt.title('Test Set Explained Variance by R-squared (R2)')\n",
    "plt.savefig(f'plots/tensor/03_metrics/{file_name}_test_set_r2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80bb59d-cb92-468c-b0a7-bc98893e5a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging info\n",
    "logging.info(\"Calculating metrics for the Test Set...\")\n",
    "\n",
    "# Initialize error metrics\n",
    "error_metrics = ['MSE', 'MAE', 'RMSE']\n",
    "values = [external_mse, external_mae, external_rmse]\n",
    "\n",
    "# Try to calculate MSLE\n",
    "try:\n",
    "    external_msle = mean_squared_log_error(y_external_true, y_external_pred)\n",
    "    error_metrics.append('MSLE')\n",
    "    values.append(test_msle)\n",
    "except ValueError:\n",
    "    external_msle = None  # Handle cases where MSLE cannot be calculated\n",
    "\n",
    "# Plot error metrics\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(error_metrics, values, color=['blue', 'green', 'red', 'orange'][:len(error_metrics)])\n",
    "plt.xlabel('Error Metric')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison of Error Metrics (Test Set)')\n",
    "\n",
    "# Annotate values on top of the bars\n",
    "for bar, value in zip(bars, values):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{value:.2f}', \n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "plt.savefig(f'plots/tensor/03_metrics/{file_name}_external_set_metrics.png')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R-squared (R2) for the test set\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "if test_r2 >= 0:\n",
    "    plt.pie([test_r2, 100 - test_r2], \n",
    "            labels=['Explained Variance (R2)', 'Unexplained Variance'], \n",
    "            colors=['lightblue', 'lightgrey'], autopct='%1.1f%%')\n",
    "else:\n",
    "    plt.pie([100], labels=['Unexplained Variance'], colors=['lightgrey'], autopct='%1.1f%%')\n",
    "\n",
    "plt.title('Test Set Explained Variance by R-squared (R2)')\n",
    "plt.savefig(f'plots/tensor/03_metrics/{file_name}_external_set_r2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6bdac6-33ab-4d84-9b5a-7ea4d73f6a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test_true, y_test_pred, color='blue', label='Prediction')\n",
    "\n",
    "# Line for Perfect Prediction\n",
    "perfect_line = np.linspace(y_test_true.min(), y_test_true.max(), 100)\n",
    "plt.plot(perfect_line, perfect_line, color='red', linestyle='--', label='Perfect Prediction')\n",
    "\n",
    "# Labels, legend, and grid\n",
    "plt.xlabel('True LOS')\n",
    "plt.ylabel('Predicted LOS')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Predicted vs. True LOS (Test Set)')\n",
    "\n",
    "# Save the plot as a PNG image\n",
    "plt.savefig(f\"plots/tensor/04_prediction_plot/01_true_vs_pred/{file_name}_test_plot.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# External Validation Set Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_external_true, y_external_pred, color='blue', label='Prediction')\n",
    "\n",
    "# Line for Perfect Prediction (y = x)\n",
    "perfect_line_ext = np.linspace(y_external_true.min(), y_external_true.max(), 100)\n",
    "plt.plot(perfect_line_ext, perfect_line_ext, color='red', linestyle='--', label='Perfect Prediction')\n",
    "\n",
    "# Labels, legend, and grid\n",
    "plt.xlabel('True LOS')\n",
    "plt.ylabel('Predicted LOS')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Predicted vs. True LOS (External Validation Set)')\n",
    "\n",
    "# Save the plot as a PNG image\n",
    "plt.savefig(f\"plots/tensor/04_prediction_plot/01_true_vs_pred/{file_name}_external_plot.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a189cc5-8a67-4ab4-a266-66d590653716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_test to a 1D numpy array\n",
    "#y_test_true = y_test_true.numpy().flatten()\n",
    "\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = y_test_true - y_test_pred\n",
    "\n",
    "# Plot residuals\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test_true, residuals, color='blue', alpha=0.5, label=\"Residuals\")\n",
    "plt.axhline(y=0, color='red', linestyle='--', label=\"Zero Line\")\n",
    "plt.axhline(y=test_mae, color='green', linestyle='--', label=f\"MAE = {test_mae:.2f}\")\n",
    "plt.axhline(y=-test_mae, color='green', linestyle='--')\n",
    "plt.xlabel('True LOS')\n",
    "plt.ylabel('Residuals (True - Predicted)')\n",
    "plt.title('Residuals Plot with MAE Bounds')\n",
    "plt.grid(True)\n",
    "\n",
    "# Place the legend outside of the plot\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Save the plot as a PNG image\n",
    "plt.savefig(f\"plots/tensor/04_prediction_plot/02_residuals/{file_name}_residuals_plot.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
