{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72ccde4d-7628-4c0f-abb4-0ff9122fbe9b",
   "metadata": {},
   "source": [
    "# Training - Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b022055-c7c3-4090-8f17-5b82e0fca420",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimop\\AppData\\Local\\Temp\\ipykernel_13740\\2646100300.py:4: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mean_df = pd.read_csv('CSV\\Exports\\datasets\\whole_set\\o01_final_mean_table.csv')\n",
      "C:\\Users\\dimop\\AppData\\Local\\Temp\\ipykernel_13740\\2646100300.py:5: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  median_df = pd.read_csv('CSV\\Exports\\datasets\\whole_set\\o02_final_median_table.csv')\n",
      "C:\\Users\\dimop\\AppData\\Local\\Temp\\ipykernel_13740\\2646100300.py:6: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  min_df = pd.read_csv('CSV\\Exports\\datasets\\whole_set\\o03_final_min_table.csv')\n",
      "C:\\Users\\dimop\\AppData\\Local\\Temp\\ipykernel_13740\\2646100300.py:7: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  max_df = pd.read_csv('CSV\\Exports\\datasets\\whole_set\\o04_final_max_table.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the exported for header chartevent CSV file\n",
    "mean_df = pd.read_csv('CSV\\Exports\\datasets\\whole_set\\o01_final_mean_table.csv')\n",
    "median_df = pd.read_csv('CSV\\Exports\\datasets\\whole_set\\o02_final_median_table.csv')\n",
    "min_df = pd.read_csv('CSV\\Exports\\datasets\\whole_set\\o03_final_min_table.csv')\n",
    "max_df = pd.read_csv('CSV\\Exports\\datasets\\whole_set\\o04_final_max_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80203d05-3da1-4832-8b10-f5c61d8d82e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training percentage. The difference goes to test set\n",
    "training_percentage = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f7d3ea-bf32-4189-aa3b-0c4d3b4b39d1",
   "metadata": {},
   "source": [
    "# Split Mean to Training - Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "347f3955-19f6-4f2e-a4a1-3730af408949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimop\\AppData\\Local\\Temp\\ipykernel_13740\\1903794067.py:21: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_df = pd.concat([train_df, subject_data])\n",
      "C:\\Users\\dimop\\AppData\\Local\\Temp\\ipykernel_13740\\1903794067.py:25: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  test_df = pd.concat([test_df, subject_data])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The last row of the training set is -> 60384'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It's already sorted. Just for precaution. Sort by 'patientunitstayid' and 'Time_Zone')\n",
    "mean_df = mean_df.sort_values(by=['patientunitstayid', 'Time_Zone'])\n",
    "\n",
    "# Calculate the total number of unique subject IDs\n",
    "unique_subject_ids = mean_df['patientunitstayid'].nunique()\n",
    "\n",
    "# Calculate the number of unique subject IDs to include in the training set\n",
    "train_subject_ids_count = int(training_percentage * unique_subject_ids)\n",
    "\n",
    "# Initialize variables to track the number of subject IDs included in the training set\n",
    "subject_ids_in_training = 0\n",
    "\n",
    "# Initialize empty DataFrames for the training and test sets\n",
    "train_df = pd.DataFrame(columns=mean_df.columns)\n",
    "test_df = pd.DataFrame(columns=mean_df.columns)\n",
    "\n",
    "# Iterate through the sorted DataFrame\n",
    "for patientunitstayid, subject_data in mean_df.groupby('patientunitstayid'):\n",
    "    if subject_ids_in_training < train_subject_ids_count:\n",
    "        # Add this subject's data to the training set\n",
    "        train_df = pd.concat([train_df, subject_data])\n",
    "        subject_ids_in_training += 1\n",
    "    else:\n",
    "        # Add this subject's data to the test set\n",
    "        test_df = pd.concat([test_df, subject_data])\n",
    "\n",
    "# Reset the index of the resulting DataFrames\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "# Export the merged DataFrame to a CSV file\n",
    "train_df.to_csv('CSV\\Exports\\datasets\\Train_test_sets\\o01_mean_train_.csv', index=False)\n",
    "test_df.to_csv('CSV\\Exports\\datasets\\Train_test_sets\\o01_mean_test_.csv', index=False)\n",
    "\n",
    "# I'm going to use those numbers as the split point in rapidminer filter operator\n",
    "display(\"The last row of the training set is -> \" + str(train_df.tail(1)[\"row_count\"].values[0]))\n",
    "\n",
    "# Delete dataframes and variables to free memory.\n",
    "del (unique_subject_ids, train_subject_ids_count, subject_ids_in_training, subject_data, train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0fc34e-7e6f-46a0-bb81-c18b45c9d98f",
   "metadata": {},
   "source": [
    "# Split Median to Training - Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2ab0982-1ef6-46c9-aa8a-31e5c18db264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimop\\AppData\\Local\\Temp\\ipykernel_13740\\3442935292.py:21: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_df = pd.concat([train_df, subject_data])\n",
      "C:\\Users\\dimop\\AppData\\Local\\Temp\\ipykernel_13740\\3442935292.py:25: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  test_df = pd.concat([test_df, subject_data])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The last row of the training set is -> 60384'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It's already sorted. Just for precaution. Sort by 'patientunitstayid' and 'Time_Zone')\n",
    "median_df = median_df.sort_values(by=['patientunitstayid', 'Time_Zone'])\n",
    "\n",
    "# Calculate the total number of unique subject IDs\n",
    "unique_subject_ids = median_df['patientunitstayid'].nunique()\n",
    "\n",
    "# Calculate the number of unique subject IDs to include in the training set\n",
    "train_subject_ids_count = int(training_percentage * unique_subject_ids)\n",
    "\n",
    "# Initialize variables to track the number of subject IDs included in the training set\n",
    "subject_ids_in_training = 0\n",
    "\n",
    "# Initialize empty DataFrames for the training and test sets\n",
    "train_df = pd.DataFrame(columns=median_df.columns)\n",
    "test_df = pd.DataFrame(columns=median_df.columns)\n",
    "\n",
    "# Iterate through the sorted DataFrame\n",
    "for patientunitstayid, subject_data in median_df.groupby('patientunitstayid'):\n",
    "    if subject_ids_in_training < train_subject_ids_count:\n",
    "        # Add this subject's data to the training set\n",
    "        train_df = pd.concat([train_df, subject_data])\n",
    "        subject_ids_in_training += 1\n",
    "    else:\n",
    "        # Add this subject's data to the test set\n",
    "        test_df = pd.concat([test_df, subject_data])\n",
    "\n",
    "# Reset the index of the resulting DataFrames\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "# Export the merged DataFrame to a CSV file\n",
    "train_df.to_csv('CSV\\Exports\\datasets\\Train_test_sets\\o02_median_train_.csv', index=False)\n",
    "test_df.to_csv('CSV\\Exports\\datasets\\Train_test_sets\\o02_median_test_.csv', index=False)\n",
    "\n",
    "# I'm going to use those numbers as the split point in rapidminer filter operator\n",
    "display(\"The last row of the training set is -> \" + str(train_df.tail(1)[\"row_count\"].values[0]))\n",
    "\n",
    "# Delete dataframes and variables to free memory.\n",
    "del (unique_subject_ids, train_subject_ids_count, subject_ids_in_training, subject_data, train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86871fc5-cc36-4126-be9f-aded6cb3e5c1",
   "metadata": {},
   "source": [
    "# Split Min to Training - Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05ebfe70-6265-4df5-8dc5-ec3018e0bb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimop\\AppData\\Local\\Temp\\ipykernel_13740\\1250766829.py:21: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_df = pd.concat([train_df, subject_data])\n",
      "C:\\Users\\dimop\\AppData\\Local\\Temp\\ipykernel_13740\\1250766829.py:25: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  test_df = pd.concat([test_df, subject_data])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The last row of the training set is -> 60384'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It's already sorted. Just for precaution. Sort by 'patientunitstayid' and 'Time_Zone')\n",
    "min_df = min_df.sort_values(by=['patientunitstayid', 'Time_Zone'])\n",
    "\n",
    "# Calculate the total number of unique subject IDs\n",
    "unique_subject_ids = min_df['patientunitstayid'].nunique()\n",
    "\n",
    "# Calculate the number of unique subject IDs to include in the training set\n",
    "train_subject_ids_count = int(training_percentage * unique_subject_ids)\n",
    "\n",
    "# Initialize variables to track the number of subject IDs included in the training set\n",
    "subject_ids_in_training = 0\n",
    "\n",
    "# Initialize empty DataFrames for the training and test sets\n",
    "train_df = pd.DataFrame(columns=min_df.columns)\n",
    "test_df = pd.DataFrame(columns=min_df.columns)\n",
    "\n",
    "# Iterate through the sorted DataFrame\n",
    "for patientunitstayid, subject_data in min_df.groupby('patientunitstayid'):\n",
    "    if subject_ids_in_training < train_subject_ids_count:\n",
    "        # Add this subject's data to the training set\n",
    "        train_df = pd.concat([train_df, subject_data])\n",
    "        subject_ids_in_training += 1\n",
    "    else:\n",
    "        # Add this subject's data to the test set\n",
    "        test_df = pd.concat([test_df, subject_data])\n",
    "\n",
    "# Reset the index of the resulting DataFrames\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "# Export the merged DataFrame to a CSV file\n",
    "train_df.to_csv('CSV\\Exports\\datasets\\Train_test_sets\\o03_min_train_.csv', index=False)\n",
    "test_df.to_csv('CSV\\Exports\\datasets\\Train_test_sets\\o03_min_test_.csv', index=False)\n",
    "\n",
    "# I'm going to use those numbers as the split point in rapidminer filter operator\n",
    "display(\"The last row of the training set is -> \" + str(train_df.tail(1)[\"row_count\"].values[0]))\n",
    "\n",
    "# Delete dataframes and variables to free memory.\n",
    "del (unique_subject_ids, train_subject_ids_count, subject_ids_in_training, subject_data, train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91ec5c7-fef7-45f3-ad15-99942057ff6d",
   "metadata": {},
   "source": [
    "# Split Max to Training - Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00a2b02c-2b5a-4781-a55a-8758fb0982de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dimop\\AppData\\Local\\Temp\\ipykernel_13740\\3371759604.py:21: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_df = pd.concat([train_df, subject_data])\n",
      "C:\\Users\\dimop\\AppData\\Local\\Temp\\ipykernel_13740\\3371759604.py:25: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  test_df = pd.concat([test_df, subject_data])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The last row of the training set is -> 60384'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It's already sorted. Just for precaution. Sort by 'patientunitstayid' and 'Time_Zone')\n",
    "max_df = max_df.sort_values(by=['patientunitstayid', 'Time_Zone'])\n",
    "\n",
    "# Calculate the total number of unique subject IDs\n",
    "unique_subject_ids = max_df['patientunitstayid'].nunique()\n",
    "\n",
    "# Calculate the number of unique subject IDs to include in the training set\n",
    "train_subject_ids_count = int(training_percentage * unique_subject_ids)\n",
    "\n",
    "# Initialize variables to track the number of subject IDs included in the training set\n",
    "subject_ids_in_training = 0\n",
    "\n",
    "# Initialize empty DataFrames for the training and test sets\n",
    "train_df = pd.DataFrame(columns=max_df.columns)\n",
    "test_df = pd.DataFrame(columns=max_df.columns)\n",
    "\n",
    "# Iterate through the sorted DataFrame\n",
    "for patientunitstayid, subject_data in max_df.groupby('patientunitstayid'):\n",
    "    if subject_ids_in_training < train_subject_ids_count:\n",
    "        # Add this subject's data to the training set\n",
    "        train_df = pd.concat([train_df, subject_data])\n",
    "        subject_ids_in_training += 1\n",
    "    else:\n",
    "        # Add this subject's data to the test set\n",
    "        test_df = pd.concat([test_df, subject_data])\n",
    "\n",
    "# Reset the index of the resulting DataFrames\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "# Export the merged DataFrame to a CSV file\n",
    "train_df.to_csv('CSV\\Exports\\datasets\\Train_test_sets\\o04_max_train_.csv', index=False)\n",
    "test_df.to_csv('CSV\\Exports\\datasets\\Train_test_sets\\o04_max_test_.csv', index=False)\n",
    "\n",
    "# I'm going to use those numbers as the split point in rapidminer filter operator\n",
    "display(\"The last row of the training set is -> \" + str(train_df.tail(1)[\"row_count\"].values[0]))\n",
    "\n",
    "# Delete dataframes and variables to free memory.\n",
    "del (unique_subject_ids, train_subject_ids_count, subject_ids_in_training, subject_data, train_df, test_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
