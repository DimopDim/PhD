{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d26192b3-b0d8-40da-8d63-865a67218f1c",
   "metadata": {},
   "source": [
    "# Creating and fill the final table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57c82ca0-8cf8-4f51-917b-4e4c6cebe9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100e215d-04a7-4c01-b80b-074f82a6c3ec",
   "metadata": {},
   "source": [
    "## Creating and fill the mean table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "507a9db6-a033-4a4c-a48e-904ebe5b1060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the exported for header chartevent CSV file\n",
    "head_df = pd.read_csv('CSV\\Exports\\groupby\\o01_eicu_grouped_mean.csv')\n",
    "\n",
    "# Read the exported for rows chartevent CSV file\n",
    "row_df = pd.read_csv('CSV\\Exports\\o09_table_rows.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09ff8c86-6b20-4587-a07a-3f13abb3ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating the concat column as an index\n",
    "from the combination of subject_id,\n",
    "hadm_id and Time_Zone.\n",
    "\"\"\"\n",
    "\n",
    "row_df[\"concat\"] = (row_df[\"uniquepid\"].astype(str)\n",
    "                    + row_df[\"patientunitstayid\"].astype(str)\n",
    "                    + row_df[\"Time_Zone\"].astype(str))\n",
    "    \n",
    "# I define the concat column as the index of the rows\n",
    "row_df = row_df.set_index('concat')\n",
    "\n",
    "\"\"\"\n",
    "Creating the concat column in the table as\n",
    "well which includes the measurements to be\n",
    "the common point between the two tables.\n",
    "\"\"\"\n",
    "\n",
    "head_df[\"concat\"] = (head_df[\"uniquepid\"].astype(str)\n",
    "                     + head_df[\"patientunitstayid\"].astype(str)\n",
    "                     + head_df[\"Time_Zone\"].astype(str))\n",
    "\n",
    "# I define the concat column as the index of the rows\n",
    "head_df = head_df.set_index('concat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f57e4a0f-0df4-425f-940e-702c905a1794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping the row_df unaffected by changes.\n",
    "new_df = row_df\n",
    "\n",
    "# Suppress the specific warning.\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# Filling the table\n",
    "for row in head_df.itertuples():\n",
    "    con = row.Index\n",
    "    item = row.observation\n",
    "    value = row.Mean_Chart\n",
    "    new_df.at['{}'.format(con), '{}'.format(item)] = value\n",
    "\n",
    "# Exclude the first 3 columns and add \" (Mean)\" after every other header\n",
    "new_df.columns = new_df.columns[:3].tolist() + [f'{col} (Mean)' for col in new_df.columns[3:]]\n",
    "\n",
    "# Removing rows that contains no values\n",
    "new_df = new_df.dropna(subset=row_df.columns[3:], how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cecb107-290c-405c-b063-8d8aaa871817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export the merged DataFrame to a CSV file\n",
    "new_df.to_csv('CSV\\Exports\\datasets\\Temp\\o01_mean_table.csv', index=False)\n",
    "\n",
    "# Free RAM\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82067754-236f-429d-95c8-e2c4dbc784cd",
   "metadata": {},
   "source": [
    "## Creating and fill the median table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c8c3061-74d6-4a8b-b286-599e5e755939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the exported for header chartevent CSV file\n",
    "head_df = pd.read_csv('CSV\\Exports\\groupby\\o02_eicu_grouped_median.csv')\n",
    "\n",
    "# Read the exported for rows chartevent CSV file\n",
    "row_df = pd.read_csv('CSV\\Exports\\o09_table_rows.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d816c5f4-2ef2-434c-b5af-51ecc5279170",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating the concat column as an index\n",
    "from the combination of subject_id,\n",
    "hadm_id and Time_Zone.\n",
    "\"\"\"\n",
    "\n",
    "row_df[\"concat\"] = (row_df[\"uniquepid\"].astype(str)\n",
    "                    + row_df[\"patientunitstayid\"].astype(str)\n",
    "                    + row_df[\"Time_Zone\"].astype(str))\n",
    "    \n",
    "# I define the concat column as the index of the rows\n",
    "row_df = row_df.set_index('concat')\n",
    "\n",
    "\"\"\"\n",
    "Creating the concat column in the table as\n",
    "well which includes the measurements to be\n",
    "the common point between the two tables.\n",
    "\"\"\"\n",
    "head_df[\"concat\"] = (head_df[\"uniquepid\"].astype(str)\n",
    "                     + head_df[\"patientunitstayid\"].astype(str)\n",
    "                     + head_df[\"Time_Zone\"].astype(str))\n",
    "\n",
    "# I define the concat column as the index of the rows\n",
    "head_df = head_df.set_index('concat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ec888f2-38d4-4df8-98bc-05bb9116ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping the row_df unaffected by changes.\n",
    "new_df = row_df\n",
    "\n",
    "# Suppress the specific warning.\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# Filling the table\n",
    "for row in head_df.itertuples():\n",
    "    con = row.Index\n",
    "    item = row.observation\n",
    "    value = row.Median_Chart\n",
    "    new_df.at['{}'.format(con), '{}'.format(item)] = value\n",
    "\n",
    "# Exclude the first 3 columns and add \" (Mean)\" after every other header\n",
    "new_df.columns = new_df.columns[:3].tolist() + [f'{col} (Median)' for col in new_df.columns[3:]]\n",
    "\n",
    "# Removing rows that contains no values\n",
    "new_df = new_df.dropna(subset=row_df.columns[3:], how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aff3df11-703b-43ed-9f0b-7bb6f0601b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export the merged DataFrame to a CSV file\n",
    "new_df.to_csv('CSV\\Exports\\datasets\\Temp\\o02_median_table.csv', index=False)\n",
    "\n",
    "# Free RAM\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a61116-fc73-4263-84ad-de6190bbcd7b",
   "metadata": {},
   "source": [
    "## Creating and fill the min table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b26d4d2-abce-41fc-b0ab-c10b8531f329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the exported for header chartevent CSV file\n",
    "head_df = pd.read_csv('CSV\\Exports\\groupby\\o03_eicu_grouped_min.csv')\n",
    "\n",
    "# Read the exported for rows chartevent CSV file\n",
    "row_df = pd.read_csv('CSV\\Exports\\o09_table_rows.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a272d8ef-17fc-4762-97ca-f6b2c5cf5acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating the concat column as an index\n",
    "from the combination of subject_id,\n",
    "hadm_id and Time_Zone.\n",
    "\"\"\"\n",
    "\n",
    "row_df[\"concat\"] = (row_df[\"uniquepid\"].astype(str)\n",
    "                    + row_df[\"patientunitstayid\"].astype(str)\n",
    "                    + row_df[\"Time_Zone\"].astype(str))\n",
    "    \n",
    "# I define the concat column as the index of the rows\n",
    "row_df = row_df.set_index('concat')\n",
    "\n",
    "\"\"\"\n",
    "Creating the concat column in the table as\n",
    "well which includes the measurements to be\n",
    "the common point between the two tables.\n",
    "\"\"\"\n",
    "head_df[\"concat\"] = (head_df[\"uniquepid\"].astype(str)\n",
    "                     + head_df[\"patientunitstayid\"].astype(str)\n",
    "                     + head_df[\"Time_Zone\"].astype(str))\n",
    "\n",
    "# I define the concat column as the index of the rows\n",
    "head_df = head_df.set_index('concat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea72b28b-e121-48d7-89aa-671fb691c74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping the row_df unaffected by changes.\n",
    "new_df = row_df\n",
    "\n",
    "# Suppress the specific warning.\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# Filling the table\n",
    "for row in head_df.itertuples():\n",
    "    con = row.Index\n",
    "    item = row.observation\n",
    "    value = row.Min_Chart\n",
    "    new_df.at['{}'.format(con), '{}'.format(item)] = value\n",
    "\n",
    "# Exclude the first 3 columns and add \" (Mean)\" after every other header\n",
    "new_df.columns = new_df.columns[:3].tolist() + [f'{col} (Min)' for col in new_df.columns[3:]]\n",
    "\n",
    "# Removing rows that contains no values\n",
    "new_df = new_df.dropna(subset=row_df.columns[3:], how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c27fc6e-6ab0-49e6-9915-5a2c20567092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export the merged DataFrame to a CSV file\n",
    "new_df.to_csv('CSV\\Exports\\datasets\\Temp\\o03_min_table.csv', index=False)\n",
    "\n",
    "# Free RAM\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb11b32-2dd1-437d-995f-4b4595581e27",
   "metadata": {},
   "source": [
    "# Creating and fill the max table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "913b6ea4-fdb0-421e-8878-c5706cdbe5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the exported for header chartevent CSV file\n",
    "head_df = pd.read_csv('CSV\\Exports\\groupby\\o04_eicu_grouped_max.csv')\n",
    "\n",
    "# Read the exported for rows chartevent CSV file\n",
    "row_df = pd.read_csv('CSV\\Exports\\o09_table_rows.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "101dc7d4-c2ce-4c9b-9810-4f9db69202ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating the concat column as an index\n",
    "from the combination of subject_id,\n",
    "hadm_id and Time_Zone.\n",
    "\"\"\"\n",
    "\n",
    "row_df[\"concat\"] = (row_df[\"uniquepid\"].astype(str)\n",
    "                    + row_df[\"patientunitstayid\"].astype(str)\n",
    "                    + row_df[\"Time_Zone\"].astype(str))\n",
    "    \n",
    "# I define the concat column as the index of the rows\n",
    "row_df = row_df.set_index('concat')\n",
    "\n",
    "\"\"\"\n",
    "Creating the concat column in the table as\n",
    "well which includes the measurements to be\n",
    "the common point between the two tables.\n",
    "\"\"\"\n",
    "head_df[\"concat\"] = (head_df[\"uniquepid\"].astype(str)\n",
    "                     + head_df[\"patientunitstayid\"].astype(str)\n",
    "                     + head_df[\"Time_Zone\"].astype(str))\n",
    "\n",
    "# I define the concat column as the index of the rows\n",
    "head_df = head_df.set_index('concat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a9bcd9e-1a19-426f-8fa8-84561fc472bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping the row_df unaffected by changes.\n",
    "new_df = row_df\n",
    "\n",
    "# Suppress the specific warning.\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# Filling the table\n",
    "for row in head_df.itertuples():\n",
    "    con = row.Index\n",
    "    item = row.observation\n",
    "    value = row.Max_Chart\n",
    "    new_df.at['{}'.format(con), '{}'.format(item)] = value\n",
    "\n",
    "# Exclude the first 3 columns and add \" (Mean)\" after every other header\n",
    "new_df.columns = new_df.columns[:3].tolist() + [f'{col} (Max)' for col in new_df.columns[3:]]\n",
    "\n",
    "# Removing rows that contains no values\n",
    "new_df = new_df.dropna(subset=row_df.columns[3:], how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "313c9ab2-5a76-46e9-9480-f7ce5522bfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export the merged DataFrame to a CSV file\n",
    "new_df.to_csv('CSV\\Exports\\datasets\\Temp\\o04_max_table.csv', index=False)\n",
    "\n",
    "# Free RAM\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
