{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6243b02-165d-496a-a198-f00704a71eb6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6671463d-f9c0-4542-b28c-eec0dfb36e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import textwrap\n",
    "import logging\n",
    "import glob\n",
    "\n",
    "from tqdm import tqdm\n",
    "#from matplotlib import pyplot\n",
    "#from skopt import BayesSearchCV\n",
    "#from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, ParameterGrid, train_test_split, ParameterSampler\n",
    "#from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error, mean_squared_log_error, r2_score\n",
    "\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import LSTM, Dense, Dropout, Input\n",
    "#from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22b8efbb-083c-4230-b048-59045707bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"logging.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b069035-3469-4e8c-8849-9225e0fad52e",
   "metadata": {},
   "source": [
    "# Load - Train - Save Models without HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2566b7a2-c82e-495f-bd3e-40eff4b34490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SETTINGS ===\n",
    "base_path = \"../../07_Imputation/CSV/exports/CIR-16/impute/\"\n",
    "observation_window = 'o4'\n",
    "label = 'los'\n",
    "model_output_dir = \"models/\"\n",
    "plot_dir_error = \"plots/03_Error_Metric_Plots\"\n",
    "plot_dir_most_important_shap = \"plots/01_Most_Important_SHAP\"\n",
    "plot_dir_true_vs_predict = \"plots/02_Prediction_Plot/02_true_vs_pred\"\n",
    "plot_dir_residuals = \"plots/02_Prediction_Plot/01_residuals\"\n",
    "plot_dir_calibration = \"plots/04_Calibration_Plots\"\n",
    "\n",
    "os.makedirs(model_output_dir, exist_ok=True)\n",
    "os.makedirs(plot_dir_error, exist_ok=True)\n",
    "os.makedirs(plot_dir_most_important_shap, exist_ok=True)\n",
    "os.makedirs(plot_dir_true_vs_predict, exist_ok=True)\n",
    "os.makedirs(plot_dir_residuals, exist_ok=True)\n",
    "os.makedirs(plot_dir_calibration, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80845ae1-62fa-45d8-8b69-a5a3c959c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HELPER FUNCTION TO MATCH FILES ===\n",
    "def find_file(path, pattern):\n",
    "    matches = glob.glob(os.path.join(path, pattern))\n",
    "    return matches[0] if matches else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98221951-2d0e-44bb-8b89-2ce79eac7ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FUNCTION TO RUN XGBOOST ===\n",
    "def run_xgboost():\n",
    "    all_metrics = []  # collect all results for summary pivot plot\n",
    "    seq_folders = sorted([f for f in os.listdir(base_path) if f.startswith(\"seq_\")])\n",
    "\n",
    "    for folder in seq_folders:\n",
    "        logging.info(f\"Processing folder: {folder}\")\n",
    "        load_path = os.path.join(base_path, folder)\n",
    "        load_path_label = os.path.join(base_path, \"labels\")\n",
    "\n",
    "        try:\n",
    "            # Load data\n",
    "            X_train = pd.read_csv(find_file(load_path, f\"{observation_window}_X_train*.csv\"))\n",
    "            y_train = pd.read_csv(find_file(load_path_label, f\"{observation_window}_y_train_{label}.csv\"))\n",
    "\n",
    "            X_validate = pd.read_csv(find_file(load_path, f\"{observation_window}_X_validate*.csv\"))\n",
    "            y_validate = pd.read_csv(find_file(load_path_label, f\"{observation_window}_y_validate_{label}.csv\"))\n",
    "\n",
    "            X_test = pd.read_csv(find_file(load_path, f\"{observation_window}_X_test*.csv\"))\n",
    "            y_test = pd.read_csv(find_file(load_path_label, f\"{observation_window}_y_test_{label}.csv\"))\n",
    "\n",
    "            X_external = pd.read_csv(find_file(load_path, f\"{observation_window}_X_external*.csv\"))\n",
    "            y_external = pd.read_csv(find_file(load_path_label, f\"{observation_window}_y_external_{label}.csv\"))\n",
    "\n",
    "            # Train model\n",
    "            model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Save model\n",
    "            file_prefix = f\"{folder}_{observation_window}_{label}\"\n",
    "            model.save_model(os.path.join(model_output_dir, f\"{file_prefix}_model.json\"))\n",
    "            logging.info(f\"Saved model to {model_output_dir}/{file_prefix}_model.json\")\n",
    "\n",
    "            # Predict\n",
    "            y_pred_test = model.predict(X_test)\n",
    "            y_pred_ext = model.predict(X_external)\n",
    "\n",
    "            # Plot True vs Pred for test and external sets\n",
    "            plot_true_vs_pred(y_test, y_pred_test, file_prefix, set_name=\"test\")\n",
    "            plot_true_vs_pred(y_external, y_pred_ext, file_prefix, set_name=\"external\")\n",
    "\n",
    "            # Log metrics\n",
    "            logging.info(f\"[{folder}] Test MSE: {mean_squared_error(y_test, y_pred_test):.4f} | MAE: {mean_absolute_error(y_test, y_pred_test):.4f} | RMSE:{np.sqrt(mean_squared_error(y_test, y_pred_test)):.4f} | R2: {r2_score(y_test, y_pred_test)*100:.2f}\")\n",
    "            logging.info(f\"[{folder}] External MSE: {mean_squared_error(y_external, y_pred_ext):.4f} | MAE: {mean_absolute_error(y_external, y_pred_ext):.4f} | RMSE: {np.sqrt(mean_squared_error(y_external, y_pred_ext)):.4f} | R2: {r2_score(y_external, y_pred_ext)*100:.2f}\")\n",
    "\n",
    "            # Residuals plot\n",
    "            plot_residuals(y_test, y_pred_test, mae=mean_absolute_error(y_test, y_pred_test), file_prefix=file_prefix)\n",
    "\n",
    "            # Calibration plots\n",
    "            plot_calibration(y_test, y_pred_test, file_prefix, set_name=\"internal\")\n",
    "            plot_calibration(y_external, y_pred_ext, file_prefix, set_name=\"external\")\n",
    "\n",
    "\n",
    "            # Plot + metrics\n",
    "            internal_metrics = plot_error_metrics(y_test, y_pred_test, file_prefix, plot_label='internal', config_label=\"no HP\")\n",
    "            external_metrics = plot_error_metrics(y_external, y_pred_ext, file_prefix, plot_label='external', config_label=\"no HP\")\n",
    "\n",
    "            # Plot top N feature importances\n",
    "            feature_importance_plot(model, X_train, file_prefix, top_n=20)\n",
    "\n",
    "            # Shap plot\n",
    "            generate_shap_plot(model, X_train, file_prefix, top_n=20)\n",
    "\n",
    "            all_metrics.append({\"folder\": folder, \"dataset\": \"internal\", **internal_metrics})\n",
    "            all_metrics.append({\"folder\": folder, \"dataset\": \"external\", **external_metrics})\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed in folder {folder}: {str(e)}\")\n",
    "\n",
    "\n",
    "    # === AFTER MAIN LOOP ===\n",
    "    metrics_df = pd.DataFrame(all_metrics)\n",
    "    summary_csv_path = os.path.join(plot_dir_error, \"all_seq_metrics.csv\")\n",
    "    metrics_df.to_csv(summary_csv_path, index=False)\n",
    "    logging.info(f\"Saved summary metrics to: {summary_csv_path}\")\n",
    "\n",
    "    metrics_melted = metrics_df.melt(\n",
    "        id_vars=[\"folder\", \"dataset\"],\n",
    "        value_vars=[\"MSE\", \"MAE\", \"RMSE\", \"R2\", \"MSLE\"],\n",
    "        var_name=\"Metric\",\n",
    "        value_name=\"Value\"\n",
    "    ).dropna()\n",
    "\n",
    "    for metric in metrics_melted[\"Metric\"].unique():\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        subset = metrics_melted[metrics_melted[\"Metric\"] == metric]\n",
    "\n",
    "        sns.barplot(data=subset, x=\"folder\", y=\"Value\", hue=\"dataset\", palette=\"Set2\", errorbar=None)\n",
    "        plt.title(f\"{metric} Comparison (Internal vs External)\")\n",
    "        plt.ylabel(metric)\n",
    "        plt.xlabel(\"Sequence Folder\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend(title=\"Dataset\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        metric_plot_path = os.path.join(plot_dir_error, f\"metric_{metric}_comparison_plot.png\")\n",
    "        plt.savefig(metric_plot_path, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "# === MAIN FUNCTION ENTRY POINT ===\n",
    "def main(model_type=\"xgboost\"):\n",
    "    if model_type.lower() == \"xgboost\":\n",
    "        run_xgboost()\n",
    "    else:\n",
    "        logging.error(f\"Model type '{model_type}' is not supported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dbe6c8-1f81-421c-9207-844c985baeef",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9bd7766-7b41-4042-96b2-c151da2288e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plots error metrics (MSE, MAE, RMSE, MSLE if possible) and R².\n",
    "\"\"\"\n",
    "\n",
    "def plot_error_metrics(y_true, y_pred, file_prefix: str, plot_label: str, config_label: str = \"no HP\"):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred) * 100\n",
    "\n",
    "    error_metrics = ['MSE', 'MAE', 'RMSE']\n",
    "    values = [mse, mae, rmse]\n",
    "\n",
    "    msle = np.nan\n",
    "    try:\n",
    "        msle = mean_squared_log_error(y_true, y_pred)\n",
    "        logging.info(f\"{plot_label.title()} Set MSLE: {msle:.4f}\")\n",
    "        error_metrics.append('MSLE')\n",
    "        values.append(msle)\n",
    "    except ValueError:\n",
    "        logging.info(f\"{plot_label.title()} Set MSLE: Not computable due to negative values.\")\n",
    "\n",
    "    # Bar plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(error_metrics, values, color=['blue', 'green', 'red', 'orange'][:len(error_metrics)])\n",
    "    plt.xlabel('Error Metric')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title(f'Error Metrics ({plot_label.title()} Set) - {config_label}')\n",
    "    plt.savefig(f\"{plot_dir_error}/{file_prefix}_{plot_label}_{config_label.replace(' ', '_')}_error_metrics.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # R² pie plot\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    if r2 >= 0:\n",
    "        plt.pie([r2, 100 - r2], labels=['Explained Variance (R2)', 'Unexplained Variance'],\n",
    "                colors=['lightblue', 'lightgrey'], autopct='%1.1f%%')\n",
    "    else:\n",
    "        plt.pie([100], labels=['Unexplained Variance'], colors=['lightgrey'], autopct='%1.1f%%')\n",
    "    plt.title(f'Explained Variance by R² ({plot_label.title()} Set) - {config_label}')\n",
    "    plt.savefig(f\"{plot_dir_error}/{file_prefix}_{plot_label}_{config_label.replace(' ', '_')}_R2.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    return {\n",
    "        \"MSE\": mse,\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R2\": r2,\n",
    "        \"MSLE\": msle\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b6feeb8-1c71-44e1-93b7-1f5817a0e3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate and save a plot of the top N most important features.\n",
    "\"\"\"\n",
    "\n",
    "def feature_importance_plot(model, X_train, file_prefix: str, top_n: int = 20):\n",
    "\n",
    "    importances = model.feature_importances_\n",
    "    feature_df = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Importance': importances\n",
    "    })\n",
    "\n",
    "    feature_df = feature_df.sort_values(by='Importance', ascending=False).head(top_n)\n",
    "    feature_df['Importance'] *= 100000  # Scale if you prefer\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    #sns.barplot(data=feature_df, x='Importance', y='Feature', palette='viridis')\n",
    "    sns.barplot(data=feature_df, x='Importance', y='Feature', color='steelblue')\n",
    "    plt.title(f'Top {top_n} Most Important Features - {file_prefix}')\n",
    "    plt.xlabel('Importance (scaled)')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot\n",
    "    importance_path = os.path.join(plot_dir_most_important_shap, f\"{file_prefix}_top{top_n}_feature_importance.png\")\n",
    "    plt.savefig(importance_path, dpi=300)\n",
    "    plt.close()\n",
    "    logging.info(f\"Saved top {top_n} feature importance plot to {importance_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c217a22-872b-4131-aca9-0bff0e8cce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate and save a SHAP summary plot (dot type) for the given model and training data.\n",
    "\"\"\"\n",
    "\n",
    "def generate_shap_plot(model, X_train, file_prefix: str, top_n: int = 20):\n",
    "\n",
    "    try:\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "        mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "        shap_df = pd.DataFrame({\n",
    "            'Feature': X_train.columns,\n",
    "            'Mean Absolute SHAP Value': mean_abs_shap\n",
    "        }).sort_values(by='Mean Absolute SHAP Value', ascending=False)\n",
    "\n",
    "        logging.info(f\"Top {top_n} features by SHAP importance for {file_prefix}:\")\n",
    "        logging.info(\"\\n\" + shap_df.head(top_n).to_string(index=False))\n",
    "\n",
    "        # SHAP summary plot\n",
    "        plt.figure()\n",
    "        shap.summary_plot(shap_values, X_train, plot_type=\"dot\", show=False)\n",
    "        plt.grid(True)\n",
    "\n",
    "        shap_path = os.path.join(plot_dir_most_important_shap, f\"{file_prefix}_shap_plot.png\")\n",
    "        plt.savefig(shap_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        logging.info(f\"Saved SHAP summary plot to {shap_path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to generate SHAP plot for {file_prefix}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e829e517-4399-4f73-819f-cb39cc25e8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot predicted vs. true values for LOS.\n",
    "\"\"\"\n",
    "\n",
    "def plot_true_vs_pred(y_true, y_pred, file_prefix: str, set_name: str):\n",
    "\n",
    "    # Ensure 1D arrays\n",
    "    y_true = np.ravel(y_true)\n",
    "    y_pred = np.ravel(y_pred)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(y_true, y_pred, color='blue', label='Prediction', alpha=0.6)\n",
    "\n",
    "    # Compute robust line range\n",
    "    min_val = float(np.min([y_true.min(), y_pred.min()]))\n",
    "    max_val = float(np.max([y_true.max(), y_pred.max()]))\n",
    "    line = np.linspace(min_val, max_val, 100)\n",
    "    plt.plot(line, line, color='red', linestyle='--', label='Perfect Prediction')\n",
    "\n",
    "    plt.xlabel('True LOS')\n",
    "    plt.ylabel('Predicted LOS')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.title(f'Predicted vs. True LOS ({set_name.title()})')\n",
    "\n",
    "    # Save plot\n",
    "    true_vs_pred = os.path.join(plot_dir_true_vs_predict, f\"{file_prefix}_true_vs_pred_{set_name}_plot.png\")\n",
    "    plt.savefig(true_vs_pred, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    logging.info(f\"Saved {set_name} True vs. Predicted plot to {plot_dir_true_vs_predict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83c19d23-f12c-4d5c-adaa-7ffdf7040f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot residuals (true - predicted) with MAE bounds and save to file.\n",
    "\"\"\"\n",
    "\n",
    "def plot_residuals(y_true, y_pred, mae: float, file_prefix: str):\n",
    "\n",
    "    y_true = np.ravel(y_true)\n",
    "    y_pred = np.ravel(y_pred)\n",
    "    residuals = y_true - y_pred\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(y_true, residuals, color='blue', alpha=0.5, label=\"Residuals\")\n",
    "    plt.axhline(y=0, color='red', linestyle='--', label=\"Zero Line\")\n",
    "    plt.axhline(y=mae, color='green', linestyle='--', label=f\"MAE = {mae:.2f}\")\n",
    "    plt.axhline(y=-mae, color='green', linestyle='--')\n",
    "    \n",
    "    plt.xlabel('True LOS')\n",
    "    plt.ylabel('Residuals (True - Predicted)')\n",
    "    plt.title('Residuals Plot with MAE Bounds')\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "\n",
    "    # Save plot\n",
    "    residuals = os.path.join(plot_dir_residuals, f\"{file_prefix}_residuals_plot.png\")\n",
    "    plt.savefig(residuals, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    logging.info(f\"Saved residuals plot to {plot_dir_residuals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1d68c96-50d8-4677-af41-99c4273b4384",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate and save a calibration plot comparing predicted and actual LOS values.\n",
    "\"\"\"\n",
    "\n",
    "def plot_calibration(y_true, y_pred, file_prefix: str, set_name: str):\n",
    "    y_true = np.ravel(y_true)\n",
    "    y_pred = np.ravel(y_pred)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.regplot(\n",
    "        x=y_true,\n",
    "        y=y_pred,\n",
    "        lowess=True,\n",
    "        line_kws={'color': 'red'},\n",
    "        scatter_kws={'alpha': 0.4}\n",
    "    )\n",
    "\n",
    "    # Perfect calibration line (y = x)\n",
    "    min_val = float(np.min([y_true.min(), y_pred.min()]))\n",
    "    max_val = float(np.max([y_true.max(), y_pred.max()]))\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=2)\n",
    "\n",
    "    plt.xlabel('Actual LOS')\n",
    "    plt.ylabel('Predicted LOS')\n",
    "    plt.title(f'Calibration Plot: {set_name.title()}')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Save plot\n",
    "    calibration = os.path.join(plot_dir_calibration, f\"{file_prefix}_calibration_{set_name}.png\")\n",
    "    plt.savefig(calibration, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    logging.info(f\"Saved calibration plot to {plot_dir_calibration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f62f381-6a90-49fc-8487-d635c412101d",
   "metadata": {},
   "source": [
    "# Call the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6125eb09-e5bd-406f-9ffd-8d91f8c84fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 22:06:30,189 - INFO - Processing folder: seq_00_mean_mean_xgboost_xgboost_lstm_lstm_gan\n",
      "2025-05-26 22:06:43,197 - INFO - Saved model to models//seq_00_mean_mean_xgboost_xgboost_lstm_lstm_gan_o4_los_model.json\n",
      "2025-05-26 22:06:44,339 - INFO - Saved test True vs. Predicted plot to plots/02_Prediction_Plot/02_true_vs_pred\n",
      "2025-05-26 22:06:46,699 - INFO - Saved external True vs. Predicted plot to plots/02_Prediction_Plot/02_true_vs_pred\n",
      "2025-05-26 22:06:46,714 - INFO - [seq_00_mean_mean_xgboost_xgboost_lstm_lstm_gan] Test MSE: 4.9665 | MAE: 1.7880 | RMSE:2.2286 | R2: 1.66\n",
      "2025-05-26 22:06:46,714 - INFO - [seq_00_mean_mean_xgboost_xgboost_lstm_lstm_gan] External MSE: 8.5075 | MAE: 2.5435 | RMSE: 2.9168 | R2: -94.11\n",
      "2025-05-26 22:06:47,432 - INFO - Saved residuals plot to plots/02_Prediction_Plot/01_residuals\n",
      "2025-05-26 22:06:48,303 - INFO - Saved calibration plot to plots/04_Calibration_Plots\n",
      "2025-05-26 22:06:58,969 - INFO - Saved calibration plot to plots/04_Calibration_Plots\n",
      "2025-05-26 22:06:58,985 - INFO - Internal Set MSLE: 0.3020\n",
      "2025-05-26 22:06:59,718 - INFO - External Set MSLE: 0.5793\n",
      "2025-05-26 22:07:01,476 - INFO - Saved top 20 feature importance plot to plots/01_Most_Important_SHAP\\seq_00_mean_mean_xgboost_xgboost_lstm_lstm_gan_o4_los_top20_feature_importance.png\n",
      "2025-05-26 22:07:17,846 - INFO - Top 20 features by SHAP importance for seq_00_mean_mean_xgboost_xgboost_lstm_lstm_gan_o4_los:\n",
      "2025-05-26 22:07:17,846 - INFO - \n",
      "                                          Feature  Mean Absolute SHAP Value\n",
      "                                  Uric_Acid_(Min)                  0.448471\n",
      "Pulmonary_Artery_Pressure_diastolic_(mmHg)_(Mean)                  0.213801\n",
      "                     Differential-Lymphs_(Median)                  0.200148\n",
      "                                        pH_(Mean)                  0.194136\n",
      "   Arterial_Blood_Pressure_diastolic_(mmHg)_(Max)                  0.165605\n",
      "                                 Pain_Level_(Max)                  0.099927\n",
      "                                  Phosphate_(Min)                  0.084080\n",
      "            Asparate_Aminotransferase_(AST)_(Max)                  0.081989\n",
      "                           Serum_Osmolality_(Min)                  0.064213\n",
      "                                         pH_(Min)                  0.063482\n",
      "                            O2_Flow_(L/min)_(Max)                  0.062369\n",
      "                                    INR(PT)_(Max)                  0.058609\n",
      "                            Ionized_Calcium_(Min)                  0.056210\n",
      "                                              age                  0.055704\n",
      "        Glucose_finger_stick_(range_70-100)_(Min)                  0.055259\n",
      "                            Ionized_Calcium_(Max)                  0.053977\n",
      "                       Differential-Lymphs_(Mean)                  0.053086\n",
      "        Glucose_finger_stick_(range_70-100)_(Max)                  0.051720\n",
      "                                         pH_(Max)                  0.050632\n",
      "                        Differential-Basos_(Mean)                  0.045345\n",
      "2025-05-26 22:07:36,816 - INFO - Saved SHAP summary plot to plots/01_Most_Important_SHAP\\seq_00_mean_mean_xgboost_xgboost_lstm_lstm_gan_o4_los_shap_plot.png\n",
      "2025-05-26 22:07:36,816 - INFO - Processing folder: seq_82_median_median_xgboost_xgboost_rnn_gan_gan\n",
      "2025-05-26 22:07:47,765 - INFO - Saved model to models//seq_82_median_median_xgboost_xgboost_rnn_gan_gan_o4_los_model.json\n",
      "2025-05-26 22:07:48,783 - INFO - Saved test True vs. Predicted plot to plots/02_Prediction_Plot/02_true_vs_pred\n",
      "2025-05-26 22:07:50,773 - INFO - Saved external True vs. Predicted plot to plots/02_Prediction_Plot/02_true_vs_pred\n",
      "2025-05-26 22:07:50,789 - INFO - [seq_82_median_median_xgboost_xgboost_rnn_gan_gan] Test MSE: 6.8798 | MAE: 2.1730 | RMSE:2.6229 | R2: -36.23\n",
      "2025-05-26 22:07:50,805 - INFO - [seq_82_median_median_xgboost_xgboost_rnn_gan_gan] External MSE: 14.2898 | MAE: 3.3992 | RMSE: 3.7802 | R2: -226.04\n",
      "2025-05-26 22:07:51,522 - INFO - Saved residuals plot to plots/02_Prediction_Plot/01_residuals\n",
      "2025-05-26 22:07:52,378 - INFO - Saved calibration plot to plots/04_Calibration_Plots\n",
      "2025-05-26 22:08:02,754 - INFO - Saved calibration plot to plots/04_Calibration_Plots\n",
      "2025-05-26 22:08:02,770 - INFO - Internal Set MSLE: 0.4364\n",
      "2025-05-26 22:08:03,441 - INFO - External Set MSLE: 0.8325\n",
      "2025-05-26 22:08:04,929 - INFO - Saved top 20 feature importance plot to plots/01_Most_Important_SHAP\\seq_82_median_median_xgboost_xgboost_rnn_gan_gan_o4_los_top20_feature_importance.png\n",
      "2025-05-26 22:08:20,190 - INFO - Top 20 features by SHAP importance for seq_82_median_median_xgboost_xgboost_rnn_gan_gan_o4_los:\n",
      "2025-05-26 22:08:20,192 - INFO - \n",
      "                                        Feature  Mean Absolute SHAP Value\n",
      "                                  Ammonia_(Max)                  0.646480\n",
      "                             Uric_Acid_(Median)                  0.186127\n",
      "                                      pH_(Mean)                  0.138478\n",
      "                              Haptoglobin_(Min)                  0.101122\n",
      "                                       pH_(Max)                  0.097604\n",
      "Pulmonary_Artery_Pressure_systolic_(mmHg)_(Min)                  0.094227\n",
      "                         O2_Flow_(L/min)_(Mean)                  0.080886\n",
      "                                    pH_(Median)                  0.080056\n",
      "                                      PTT_(Min)                  0.069747\n",
      "                      Differential-Eos_(Median)                  0.065062\n",
      "                                            age                  0.063313\n",
      " Arterial_Blood_Pressure_diastolic_(mmHg)_(Min)                  0.057301\n",
      "      Glucose_finger_stick_(range_70-100)_(Min)                  0.054632\n",
      "                   Differential-Lymphs_(Median)                  0.051258\n",
      "                              Pain_Level_(Mean)                  0.050989\n",
      "  Arterial_Blood_Pressure_systolic_(mmHg)_(Min)                  0.050566\n",
      "     Arterial_Blood_Pressure_mean_(mmHg)_(Mean)                  0.049300\n",
      "                                  Albumin_(Max)                  0.048906\n",
      "                        White_Blood_Cells_(Max)                  0.047651\n",
      "                       O2_Flow_(L/min)_(Median)                  0.046936\n",
      "2025-05-26 22:08:38,117 - INFO - Saved SHAP summary plot to plots/01_Most_Important_SHAP\\seq_82_median_median_xgboost_xgboost_rnn_gan_gan_o4_los_shap_plot.png\n",
      "2025-05-26 22:08:38,117 - INFO - Processing folder: seq_83_median_median_xgboost_xgboost_rnn_gan_rnn\n",
      "2025-05-26 22:08:50,380 - INFO - Saved model to models//seq_83_median_median_xgboost_xgboost_rnn_gan_rnn_o4_los_model.json\n",
      "2025-05-26 22:08:51,460 - INFO - Saved test True vs. Predicted plot to plots/02_Prediction_Plot/02_true_vs_pred\n",
      "2025-05-26 22:08:53,736 - INFO - Saved external True vs. Predicted plot to plots/02_Prediction_Plot/02_true_vs_pred\n",
      "2025-05-26 22:08:53,751 - INFO - [seq_83_median_median_xgboost_xgboost_rnn_gan_rnn] Test MSE: 8.5011 | MAE: 2.5048 | RMSE:2.9157 | R2: -68.33\n",
      "2025-05-26 22:08:53,751 - INFO - [seq_83_median_median_xgboost_xgboost_rnn_gan_rnn] External MSE: 11.4953 | MAE: 2.9811 | RMSE: 3.3905 | R2: -162.28\n",
      "2025-05-26 22:08:54,469 - INFO - Saved residuals plot to plots/02_Prediction_Plot/01_residuals\n",
      "2025-05-26 22:08:55,340 - INFO - Saved calibration plot to plots/04_Calibration_Plots\n",
      "2025-05-26 22:09:05,701 - INFO - Saved calibration plot to plots/04_Calibration_Plots\n",
      "2025-05-26 22:09:05,723 - INFO - Internal Set MSLE: 0.5081\n",
      "2025-05-26 22:09:06,403 - INFO - External Set MSLE: 0.7093\n",
      "2025-05-26 22:09:07,891 - INFO - Saved top 20 feature importance plot to plots/01_Most_Important_SHAP\\seq_83_median_median_xgboost_xgboost_rnn_gan_rnn_o4_los_top20_feature_importance.png\n",
      "2025-05-26 22:09:23,128 - INFO - Top 20 features by SHAP importance for seq_83_median_median_xgboost_xgboost_rnn_gan_rnn_o4_los:\n",
      "2025-05-26 22:09:23,130 - INFO - \n",
      "                                        Feature  Mean Absolute SHAP Value\n",
      "                                  Ammonia_(Max)                  0.653292\n",
      "                             Uric_Acid_(Median)                  0.149226\n",
      "                                       pH_(Max)                  0.146780\n",
      "                                    pH_(Median)                  0.102466\n",
      "                              Haptoglobin_(Min)                  0.097729\n",
      "                         O2_Flow_(L/min)_(Mean)                  0.082740\n",
      "  Arterial_Blood_Pressure_systolic_(mmHg)_(Min)                  0.075367\n",
      "                                     pO2_(Mean)                  0.071232\n",
      "                                            age                  0.070202\n",
      "                                      pH_(Mean)                  0.069299\n",
      "Pulmonary_Artery_Pressure_systolic_(mmHg)_(Min)                  0.066642\n",
      "                       O2_Flow_(L/min)_(Median)                  0.064997\n",
      "                      Differential-Eos_(Median)                  0.063893\n",
      "                                Phosphate_(Min)                  0.060343\n",
      "                       Differential-Monos_(Max)                  0.058796\n",
      "                                      PTT_(Min)                  0.054599\n",
      "                              Bicarbonate_(Min)                  0.054467\n",
      "     Arterial_Blood_Pressure_mean_(mmHg)_(Mean)                  0.052342\n",
      "                      Calcium_non-ionized_(Min)                  0.044549\n",
      "                                  Lactate_(Min)                  0.044208\n",
      "2025-05-26 22:09:40,964 - INFO - Saved SHAP summary plot to plots/01_Most_Important_SHAP\\seq_83_median_median_xgboost_xgboost_rnn_gan_rnn_o4_los_shap_plot.png\n",
      "2025-05-26 22:09:40,980 - INFO - Saved summary metrics to: plots/03_Error_Metric_Plots\\all_seq_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "main(model_type=\"xgboost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e7e9a8-f354-491c-adf7-994f0f63fd62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a46ee6-b312-46a3-91a0-7cc94b3829ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5dc56f-e817-4d79-a03d-fe965b3bb748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9175b32-fac4-4875-b1f2-f8e64eb9a43e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa322981-eeeb-4556-b672-3e8dfa4e7f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e994ccda-f0ac-4dc4-94b3-64335da6ae7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2445f552-ef19-4141-a4b2-06ff908f1213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4204f05d-1a46-4008-a679-8d456a015238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74908869-bd36-4ad7-962a-1282350a8921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc53466-a9ba-4bdb-8122-61d43c36d358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2b7c88-d88d-4b65-a92a-2ed976033f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915a85ce-332e-40d9-aa3f-4145ddcd15ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71755487-5db6-4b99-bc48-151e89cf0780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a26790-948e-4503-bd10-ab3f17979c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4c928a-f8bd-4e04-8081-f58864576a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368e904c-59f0-4c19-be34-728f3dea52ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8df8061-0d9e-4607-906e-06db392d6467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d4188a-e654-4c22-a3e9-9119ee9b18c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb72421-8e33-4429-a1d9-e180a15a1d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac7ad27-4477-461c-99b9-2f03787a15f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e16d8e0-d5c0-4e7e-a9c4-4ed697c852dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76faa84b-88b6-4b34-b000-8af0a4281216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044931cf-e025-4772-a5a5-31a5f1b5b4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7f727d0-6369-4e0e-9d2f-ae447500734d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# HP GridSearchCV\n",
    "## To slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3e5d12-f1bd-4242-9d64-35a14ba91996",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A smaller learning rate makes the boosting\n",
    "process more robust and can lead to better\n",
    "generalization but requires more trees\n",
    "(higher n_estimators) to achieve the same result.\n",
    "A larger learning rate speeds up training bu\n",
    "may risk overfitting.\n",
    "\"\"\"\n",
    "\n",
    "# Define the parameter grid\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300], # controls the total number of trees in the ensemble\n",
    "    'learning_rate': np.arange(0.01, 1.02, 0.2),\n",
    "    'max_depth': np.arange(1, 10, 1),\n",
    "    'reg_lambda': np.arange(0.1, 15.1, 1),\n",
    "    'reg_alpha': np.arange(0.1, 15.1, 1)\n",
    "}\n",
    "\n",
    "# Create an XGBoost Regressor\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \n",
    "                           scoring='neg_mean_squared_error', \n",
    "                           cv=3,  # Number of folds for cross-validation\n",
    "                           verbose=1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score (negative MSE):\", grid_search.best_score_)\n",
    "\n",
    "# Predict on the validation set with the best model\n",
    "y_pred_validate = grid_search.predict(X_validate)\n",
    "\n",
    "# Optionally: Evaluate the model on the validation set\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_validate, y_pred_validate)\n",
    "print(\"Validation MSE:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae09b09f-e87b-436b-bf5d-a35bb597659b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# HP RandomizedSearchCV & Train Model\n",
    "Choose randomly samples a subset of hyperparameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3316a365-114c-4f10-9553-469d66342b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_distributions = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': np.arange(0.01, 1.02, 0.2),\n",
    "    'max_depth': np.arange(1, 10, 1),\n",
    "    'reg_lambda': np.arange(0.1, 15.1, 1),\n",
    "    'reg_alpha': np.arange(0.1, 15.1, 1)\n",
    "}\n",
    "\n",
    "# Number of random samples\n",
    "n_iter = 50\n",
    "\n",
    "# Generate random combinations\n",
    "param_list = list(ParameterSampler(param_distributions, n_iter=n_iter, random_state=42))\n",
    "\n",
    "# Tracking best model\n",
    "best_score = float('inf')\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "# Progress bar\n",
    "for params in tqdm(param_list, desc=\"Hyperparameter tuning\"):\n",
    "    model = xgb.XGBRegressor(objective='reg:squarederror', **params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred_val = model.predict(X_validate)\n",
    "    \n",
    "    # Evaluate with MSE\n",
    "    mse = mean_squared_error(y_validate, y_pred_val)\n",
    "    \n",
    "    if mse < best_score:\n",
    "        best_score = mse\n",
    "        best_params = params\n",
    "        best_model = model\n",
    "\n",
    "# Evaluate best model on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Evaluate on external validation set\n",
    "y_pred_external = best_model.predict(X_external)\n",
    "mse_external = mean_squared_error(y_external, y_pred_external)\n",
    "mae_external = mean_absolute_error(y_external, y_pred_external)\n",
    "\n",
    "# Results\n",
    "logging.info(f\"Best parameters: {best_params}\")\n",
    "logging.info(f\"Best validation MSE: {best_score}\")\n",
    "logging.info(f\"Test Set - MSE: {mse_test}, MAE: {mae_test}\")\n",
    "logging.info(f\"External Validation Set - MSE: {mse_external}, MAE: {mae_external}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2110b1d7-7f38-42df-9eed-ed0829249eee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# HP Bayesian Optimization & Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09340dad-8d72-4555-9b84-07c6afa84bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tqdm progress bar\n",
    "pbar = tqdm(total=50, desc=\"Bayesian Optimization Progress\")\n",
    "\n",
    "# Callback to update tqdm\n",
    "def on_step(optim_result):\n",
    "    pbar.update(1)\n",
    "\n",
    "# Define the parameter search space\n",
    "param_space = {\n",
    "    'n_estimators': (100, 300),\n",
    "    'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "    'max_depth': (1, 10),\n",
    "    'reg_lambda': (0.1, 15.0),\n",
    "    'reg_alpha': (0.1, 15.0)\n",
    "}\n",
    "\n",
    "# Create the XGBoost Regressor\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Create BayesSearchCV for Bayesian Optimization\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    search_spaces=param_space,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_iter=50,\n",
    "    cv=3,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit BayesSearchCV with tqdm callback\n",
    "bayes_search.fit(X_train, y_train, callback=on_step)\n",
    "pbar.close()\n",
    "\n",
    "# Log best parameters and score\n",
    "logging.info(\"Best parameters: %s\", bayes_search.best_params_)\n",
    "logging.info(\"Best score (negative MSE): %.4f\", bayes_search.best_score_)\n",
    "\n",
    "# Predict on the validation set with the best model\n",
    "y_pred_validate = bayes_search.predict(X_validate)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "mse_validate = mean_squared_error(y_validate, y_pred_validate)\n",
    "mae_validate = mean_absolute_error(y_validate, y_pred_validate)\n",
    "logging.info(\"Validation MSE: %.4f\", mse_validate)\n",
    "logging.info(\"Validation MAE: %.4f\", mae_validate)\n",
    "\n",
    "# Extract the best hyperparameters from BayesSearchCV\n",
    "best_params = bayes_search.best_params_\n",
    "\n",
    "# Initialize the XGBoost model with the best hyperparameters\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    reg_lambda=best_params['reg_lambda'],\n",
    "    reg_alpha=best_params['reg_alpha']\n",
    ")\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Predict on the external validation set (eICU data)\n",
    "y_pred_external = model.predict(X_external)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on the external validation set\n",
    "mse_external = mean_squared_error(y_external, y_pred_external)\n",
    "mae_external = mean_absolute_error(y_external, y_pred_external)\n",
    "\n",
    "# Log final evaluation metrics\n",
    "logging.info(\"Test Set - MSE: %.4f, MAE: %.4f\", mse_test, mae_test)\n",
    "logging.info(\"External Validation Set (eICU) - MSE: %.4f, MAE: %.4f\", mse_external, mae_external)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63d430b-79c1-4340-835e-119a468f1483",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# HP HyperOpt & Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7b2115-569e-4929-90c0-da230a015f50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the number of evaluations\n",
    "MAX_EVALS = 50\n",
    "\n",
    "# Initialize tqdm progress bar\n",
    "pbar = tqdm(total=MAX_EVALS, desc=\"HyperOpt Progress\")\n",
    "\n",
    "# Define the wrapped objective function\n",
    "def objective(params):\n",
    "    model = xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        n_estimators=int(params['n_estimators']),\n",
    "        learning_rate=params['learning_rate'],\n",
    "        max_depth=int(params['max_depth']),\n",
    "        reg_lambda=params['reg_lambda'],\n",
    "        reg_alpha=params['reg_alpha']\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred_validate = model.predict(X_validate)\n",
    "    \n",
    "    # Compute the MSE\n",
    "    mse = mean_squared_error(y_validate, y_pred_validate)\n",
    "\n",
    "    # Log the result\n",
    "    logging.info(\"Params: %s | Validation MSE: %.4f\", params, mse)\n",
    "    \n",
    "    # Update progress bar\n",
    "    pbar.update(1)\n",
    "\n",
    "    return {'loss': mse, 'status': 'ok'}\n",
    "\n",
    "# Define the parameter search space\n",
    "param_space = {\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 100, 300, 50)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(1.0)),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.1, 15.0),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.1, 15.0)\n",
    "}\n",
    "\n",
    "# Create a Trials object to keep track of the search\n",
    "trials = Trials()\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=param_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=MAX_EVALS,\n",
    "    trials=trials,\n",
    "    show_progressbar=False  # Disable internal bar to avoid overlap with tqdm\n",
    ")\n",
    "\n",
    "# Close progress bar\n",
    "pbar.close()\n",
    "\n",
    "# Log the best parameters\n",
    "logging.info(\"Best parameters: %s\", best)\n",
    "\n",
    "# Initialize the XGBoost model with the best hyperparameters\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=int(best['n_estimators']),\n",
    "    learning_rate=best['learning_rate'],\n",
    "    max_depth=int(best['max_depth']),\n",
    "    reg_lambda=best['reg_lambda'],\n",
    "    reg_alpha=best['reg_alpha']\n",
    ")\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Predict on the external validation set (eICU data)\n",
    "y_pred_external = model.predict(X_external)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on the external validation set\n",
    "mse_external = mean_squared_error(y_external, y_pred_external)\n",
    "mae_external = mean_absolute_error(y_external, y_pred_external)\n",
    "\n",
    "# Log final evaluation results\n",
    "logging.info(\"Test Set - MSE: %.4f, MAE: %.4f\", mse_test, mae_test)\n",
    "logging.info(\"External Validation Set (eICU) - MSE: %.4f, MAE: %.4f\", mse_external, mae_external)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a810c9c-58b5-41f7-b700-e62558004bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "save_path = 'CSV/exports/impute/o03_Interpolation/'\n",
    "\n",
    "# Check if the directory exists, and if not, create it\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "# Save external validation set from eICU\n",
    "X_external.to_csv(save_path + 'X_external.csv', index=False)\n",
    "y_external.to_csv(save_path + 'y_external.csv', index=False)\n",
    "\n",
    "# Save training, validation, and test sets\n",
    "X_train.to_csv(save_path + 'X_train.csv', index=False)\n",
    "y_train.to_csv(save_path + 'y_train.csv', index=False)\n",
    "\n",
    "X_validate.to_csv(save_path + 'X_validate.csv', index=False)\n",
    "y_validate.to_csv(save_path + 'y_validate.csv', index=False)\n",
    "\n",
    "X_test.to_csv(save_path + 'X_test.csv', index=False)\n",
    "y_test.to_csv(save_path + 'y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1530e609-4239-4d84-88f6-48ed91bf5a28",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e03eb8-70ee-4578-bd93-2b7032252210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory and file path\n",
    "\n",
    "name = f\"{file_name}_model.json\"\n",
    "directory = 'models/'\n",
    "\n",
    "file_path = os.path.join(directory, name)\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Save the model as a JSON file\n",
    "model.save_model(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b303f38-a8c0-4488-8e9c-05a83768a275",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105cdba2-86f9-41a6-ba38-c11d492f9780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model file path\n",
    "file_name = \"06\"  # replace with the actual name you used before saving\n",
    "directory = 'models/'\n",
    "file_path = os.path.join(directory, f\"{file_name}_model.json\")\n",
    "\n",
    "# Load the model\n",
    "model = xgb.XGBRegressor()\n",
    "model.load_model(file_path)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Predict on the external validation set\n",
    "y_pred_external = model.predict(X_external)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
