{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6243b02-165d-496a-a198-f00704a71eb6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6671463d-f9c0-4542-b28c-eec0dfb36e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import textwrap\n",
    "import logging\n",
    "import glob\n",
    "\n",
    "from tqdm import tqdm\n",
    "#from matplotlib import pyplot\n",
    "#from skopt import BayesSearchCV\n",
    "#from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, ParameterGrid, train_test_split, ParameterSampler\n",
    "#from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error, mean_squared_log_error, r2_score\n",
    "\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import LSTM, Dense, Dropout, Input\n",
    "#from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22b8efbb-083c-4230-b048-59045707bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"logging.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b069035-3469-4e8c-8849-9225e0fad52e",
   "metadata": {},
   "source": [
    "# Load - Train - Save Models without HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2566b7a2-c82e-495f-bd3e-40eff4b34490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SETTINGS ===\n",
    "base_path = \"../../07_Imputation/CSV/exports/CIR-16/impute/\"\n",
    "observation_window = 'o4'\n",
    "label = 'los'\n",
    "model_output_dir = \"models/\"\n",
    "plot_dir = \"plots/03_Error_Metric_Plots\"\n",
    "\n",
    "os.makedirs(model_output_dir, exist_ok=True)\n",
    "os.makedirs(plot_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80845ae1-62fa-45d8-8b69-a5a3c959c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HELPER FUNCTION TO MATCH FILES ===\n",
    "def find_file(path, pattern):\n",
    "    matches = glob.glob(os.path.join(path, pattern))\n",
    "    return matches[0] if matches else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c8b212d-8bad-4d04-a725-1e8264a9f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_metrics(y_true, y_pred, file_prefix: str, plot_label: str, config_label: str = \"no HP\"):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred) * 100\n",
    "\n",
    "    error_metrics = ['MSE', 'MAE', 'RMSE']\n",
    "    values = [mse, mae, rmse]\n",
    "\n",
    "    msle = np.nan\n",
    "    try:\n",
    "        msle = mean_squared_log_error(y_true, y_pred)\n",
    "        logging.info(f\"{plot_label.title()} Set MSLE: {msle:.4f}\")\n",
    "        error_metrics.append('MSLE')\n",
    "        values.append(msle)\n",
    "    except ValueError:\n",
    "        logging.info(f\"{plot_label.title()} Set MSLE: Not computable due to negative values.\")\n",
    "\n",
    "    # Bar plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(error_metrics, values, color=['blue', 'green', 'red', 'orange'][:len(error_metrics)])\n",
    "    plt.xlabel('Error Metric')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title(f'Error Metrics ({plot_label.title()} Set) - {config_label}')\n",
    "    plt.savefig(f\"{plot_dir}/{file_prefix}_{plot_label}_{config_label.replace(' ', '_')}_error_metrics.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # R² pie plot\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    if r2 >= 0:\n",
    "        plt.pie([r2, 100 - r2], labels=['Explained Variance (R2)', 'Unexplained Variance'],\n",
    "                colors=['lightblue', 'lightgrey'], autopct='%1.1f%%')\n",
    "    else:\n",
    "        plt.pie([100], labels=['Unexplained Variance'], colors=['lightgrey'], autopct='%1.1f%%')\n",
    "    plt.title(f'Explained Variance by R² ({plot_label.title()} Set) - {config_label}')\n",
    "    plt.savefig(f\"{plot_dir}/{file_prefix}_{plot_label}_{config_label.replace(' ', '_')}_R2.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    return {\n",
    "        \"MSE\": mse,\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R2\": r2,\n",
    "        \"MSLE\": msle\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc6960ae-c227-4cf8-8f8c-8cd0c07151ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 00:14:54,439 - INFO - Processing folder: seq_00\n",
      "2025-05-16 00:15:11,089 - INFO - Saved model to models//seq_00_o4_los_model.json\n",
      "2025-05-16 00:15:11,574 - INFO - [seq_00] Test MSE: 4.8175 | MAE: 1.6727 | RMSE: 2.1949 | R2: 4.61\n",
      "2025-05-16 00:15:11,574 - INFO - [seq_00] External MSE: 7.1572 | MAE: 2.0611 | RMSE: 2.6753 | R2: -63.30\n",
      "2025-05-16 00:15:11,592 - INFO - Internal Set MSLE: 0.2984\n",
      "2025-05-16 00:15:12,906 - INFO - External Set MSLE: 0.4795\n",
      "2025-05-16 00:15:14,074 - INFO - Processing folder: seq_01\n",
      "2025-05-16 00:15:30,287 - INFO - Saved model to models//seq_01_o4_los_model.json\n",
      "2025-05-16 00:15:30,757 - INFO - [seq_01] Test MSE: 4.7063 | MAE: 1.7996 | RMSE: 2.1694 | R2: 6.81\n",
      "2025-05-16 00:15:30,759 - INFO - [seq_01] External MSE: 8.2710 | MAE: 2.4191 | RMSE: 2.8759 | R2: -88.72\n",
      "2025-05-16 00:15:30,773 - INFO - Internal Set MSLE: 0.3011\n",
      "2025-05-16 00:15:32,195 - INFO - External Set MSLE: 0.5460\n",
      "2025-05-16 00:15:33,349 - INFO - Processing folder: seq_02\n",
      "2025-05-16 00:15:47,987 - INFO - Saved model to models//seq_02_o4_los_model.json\n",
      "2025-05-16 00:15:48,533 - INFO - [seq_02] Test MSE: 4.6236 | MAE: 1.7272 | RMSE: 2.1503 | R2: 8.45\n",
      "2025-05-16 00:15:48,533 - INFO - [seq_02] External MSE: 9.0663 | MAE: 2.4103 | RMSE: 3.0110 | R2: -106.86\n",
      "2025-05-16 00:15:48,550 - INFO - Internal Set MSLE: 0.2970\n",
      "2025-05-16 00:15:49,740 - INFO - External Set MSLE: 0.5615\n",
      "2025-05-16 00:15:50,851 - INFO - Processing folder: seq_03\n",
      "2025-05-16 00:16:07,354 - INFO - Saved model to models//seq_03_o4_los_model.json\n",
      "2025-05-16 00:16:08,218 - INFO - [seq_03] Test MSE: 6.1420 | MAE: 2.1056 | RMSE: 2.4783 | R2: -21.62\n",
      "2025-05-16 00:16:08,218 - INFO - [seq_03] External MSE: 12.4873 | MAE: 2.8494 | RMSE: 3.5337 | R2: -184.92\n",
      "2025-05-16 00:16:08,234 - INFO - Internal Set MSLE: 0.4002\n",
      "2025-05-16 00:16:09,470 - INFO - External Set MSLE: 0.6954\n",
      "2025-05-16 00:16:10,642 - INFO - Processing folder: seq_04\n",
      "2025-05-16 00:16:26,700 - INFO - Saved model to models//seq_04_o4_los_model.json\n",
      "2025-05-16 00:16:27,183 - INFO - [seq_04] Test MSE: 7.9064 | MAE: 2.3706 | RMSE: 2.8118 | R2: -56.56\n",
      "2025-05-16 00:16:27,183 - INFO - [seq_04] External MSE: 14.9821 | MAE: 3.4449 | RMSE: 3.8707 | R2: -241.84\n",
      "2025-05-16 00:16:27,199 - INFO - Internal Set MSLE: 0.4520\n",
      "2025-05-16 00:16:28,379 - INFO - External Set MSLE: 0.8385\n",
      "2025-05-16 00:16:29,536 - INFO - Processing folder: seq_05\n",
      "2025-05-16 00:16:46,263 - INFO - Saved model to models//seq_05_o4_los_model.json\n",
      "2025-05-16 00:16:47,052 - INFO - [seq_05] Test MSE: 6.1021 | MAE: 2.0411 | RMSE: 2.4702 | R2: -20.83\n",
      "2025-05-16 00:16:47,054 - INFO - [seq_05] External MSE: 8.1415 | MAE: 2.4389 | RMSE: 2.8533 | R2: -85.76\n",
      "2025-05-16 00:16:47,070 - INFO - Internal Set MSLE: 0.3870\n",
      "2025-05-16 00:16:48,231 - INFO - External Set MSLE: 0.5399\n",
      "2025-05-16 00:16:49,355 - INFO - Processing folder: seq_06\n",
      "2025-05-16 00:17:05,668 - INFO - Saved model to models//seq_06_o4_los_model.json\n",
      "2025-05-16 00:17:06,180 - INFO - [seq_06] Test MSE: 5.3944 | MAE: 1.9033 | RMSE: 2.3226 | R2: -6.82\n",
      "2025-05-16 00:17:06,182 - INFO - [seq_06] External MSE: 9.4156 | MAE: 2.6137 | RMSE: 3.0685 | R2: -114.83\n",
      "2025-05-16 00:17:06,195 - INFO - Internal Set MSLE: 0.3427\n",
      "2025-05-16 00:17:07,337 - INFO - External Set MSLE: 0.6154\n",
      "2025-05-16 00:17:08,465 - INFO - Processing folder: seq_07\n",
      "2025-05-16 00:17:24,849 - INFO - Saved model to models//seq_07_o4_los_model.json\n",
      "2025-05-16 00:17:25,498 - INFO - [seq_07] Test MSE: 6.5472 | MAE: 2.1226 | RMSE: 2.5587 | R2: -29.64\n",
      "2025-05-16 00:17:25,498 - INFO - [seq_07] External MSE: 13.9855 | MAE: 3.2132 | RMSE: 3.7397 | R2: -219.10\n",
      "2025-05-16 00:17:25,514 - INFO - Internal Set MSLE: 0.4102\n",
      "2025-05-16 00:17:26,796 - INFO - External Set MSLE: 0.7970\n",
      "2025-05-16 00:17:27,968 - INFO - Processing folder: seq_08\n",
      "2025-05-16 00:17:45,187 - INFO - Saved model to models//seq_08_o4_los_model.json\n",
      "2025-05-16 00:17:45,799 - INFO - [seq_08] Test MSE: 5.8913 | MAE: 2.0382 | RMSE: 2.4272 | R2: -16.65\n",
      "2025-05-16 00:17:45,799 - INFO - [seq_08] External MSE: 10.2103 | MAE: 2.7320 | RMSE: 3.1954 | R2: -132.96\n",
      "2025-05-16 00:17:45,815 - INFO - Internal Set MSLE: 0.3711\n",
      "2025-05-16 00:17:46,991 - INFO - External Set MSLE: 0.6323\n",
      "2025-05-16 00:17:48,173 - INFO - Processing folder: seq_09\n",
      "2025-05-16 00:18:05,049 - INFO - Saved model to models//seq_09_o4_los_model.json\n",
      "2025-05-16 00:18:06,082 - INFO - [seq_09] Test MSE: 7.3933 | MAE: 2.3666 | RMSE: 2.7191 | R2: -46.40\n",
      "2025-05-16 00:18:06,082 - INFO - [seq_09] External MSE: 15.9496 | MAE: 3.4485 | RMSE: 3.9937 | R2: -263.91\n",
      "2025-05-16 00:18:06,098 - INFO - Internal Set MSLE: 0.4674\n",
      "2025-05-16 00:18:07,273 - INFO - External Set MSLE: 0.8597\n",
      "2025-05-16 00:18:08,431 - INFO - Processing folder: seq_10\n",
      "2025-05-16 00:18:24,510 - INFO - Saved model to models//seq_10_o4_los_model.json\n",
      "2025-05-16 00:18:25,035 - INFO - [seq_10] Test MSE: 5.5318 | MAE: 1.8992 | RMSE: 2.3520 | R2: -9.54\n",
      "2025-05-16 00:18:25,037 - INFO - [seq_10] External MSE: 6.8386 | MAE: 2.1528 | RMSE: 2.6151 | R2: -56.03\n",
      "2025-05-16 00:18:25,051 - INFO - Internal Set MSLE: 0.3362\n",
      "2025-05-16 00:18:26,161 - INFO - External Set MSLE: 0.4813\n",
      "2025-05-16 00:18:27,348 - INFO - Processing folder: seq_11\n",
      "2025-05-16 00:18:42,915 - INFO - Saved model to models//seq_11_o4_los_model.json\n",
      "2025-05-16 00:18:43,415 - INFO - [seq_11] Test MSE: 6.7607 | MAE: 2.2414 | RMSE: 2.6001 | R2: -33.87\n",
      "2025-05-16 00:18:43,415 - INFO - [seq_11] External MSE: 5.4429 | MAE: 1.8665 | RMSE: 2.3330 | R2: -24.19\n",
      "2025-05-16 00:18:43,430 - INFO - Internal Set MSLE: 0.4371\n",
      "2025-05-16 00:18:44,596 - INFO - External Set MSLE: 0.3839\n",
      "2025-05-16 00:18:45,772 - INFO - Processing folder: seq_12\n",
      "2025-05-16 00:19:00,975 - INFO - Saved model to models//seq_12_o4_los_model.json\n",
      "2025-05-16 00:19:01,573 - INFO - [seq_12] Test MSE: 4.6746 | MAE: 1.7241 | RMSE: 2.1621 | R2: 7.44\n",
      "2025-05-16 00:19:01,575 - INFO - [seq_12] External MSE: 7.1130 | MAE: 2.2846 | RMSE: 2.6670 | R2: -62.29\n",
      "2025-05-16 00:19:01,589 - INFO - Internal Set MSLE: 0.3112\n",
      "2025-05-16 00:19:02,837 - INFO - External Set MSLE: 0.5029\n",
      "2025-05-16 00:19:04,173 - INFO - Processing folder: seq_13\n",
      "2025-05-16 00:19:19,526 - INFO - Saved model to models//seq_13_o4_los_model.json\n",
      "2025-05-16 00:19:20,427 - INFO - [seq_13] Test MSE: 5.2983 | MAE: 1.8195 | RMSE: 2.3018 | R2: -4.91\n",
      "2025-05-16 00:19:20,427 - INFO - [seq_13] External MSE: 5.2253 | MAE: 1.7899 | RMSE: 2.2859 | R2: -19.22\n",
      "2025-05-16 00:19:20,442 - INFO - Internal Set MSLE: 0.3214\n",
      "2025-05-16 00:19:21,528 - INFO - External Set MSLE: 0.3672\n",
      "2025-05-16 00:19:22,654 - INFO - Processing folder: seq_14\n",
      "2025-05-16 00:19:37,613 - INFO - Saved model to models//seq_14_o4_los_model.json\n",
      "2025-05-16 00:19:38,103 - INFO - [seq_14] Test MSE: 5.2965 | MAE: 1.7594 | RMSE: 2.3014 | R2: -4.88\n",
      "2025-05-16 00:19:38,104 - INFO - [seq_14] External MSE: 5.0394 | MAE: 1.7501 | RMSE: 2.2449 | R2: -14.98\n",
      "2025-05-16 00:19:38,118 - INFO - Internal Set MSLE: Not computable due to negative values.\n",
      "2025-05-16 00:19:39,253 - INFO - External Set MSLE: 0.3475\n",
      "2025-05-16 00:19:40,452 - INFO - Saved summary metrics to: plots/03_Error_Metric_Plots/all_seq_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "# === MAIN LOOP ===\n",
    "all_metrics = []  # collect all results for summary pivot plot\n",
    "seq_folders = sorted([f for f in os.listdir(base_path) if f.startswith(\"seq_\")])\n",
    "\n",
    "for folder in seq_folders:\n",
    "    logging.info(f\"Processing folder: {folder}\")\n",
    "    load_path = os.path.join(base_path, folder)\n",
    "    load_path_label = os.path.join(base_path, \"labels\")\n",
    "\n",
    "    try:\n",
    "        # Load data\n",
    "        X_train = pd.read_csv(find_file(load_path, f\"{observation_window}_X_train*.csv\"))\n",
    "        y_train = pd.read_csv(find_file(load_path_label, f\"{observation_window}_y_train_{label}.csv\"))\n",
    "\n",
    "        X_validate = pd.read_csv(find_file(load_path, f\"{observation_window}_X_validate*.csv\"))\n",
    "        y_validate = pd.read_csv(find_file(load_path_label, f\"{observation_window}_y_validate_{label}.csv\"))\n",
    "\n",
    "        X_test = pd.read_csv(find_file(load_path, f\"{observation_window}_X_test*.csv\"))\n",
    "        y_test = pd.read_csv(find_file(load_path_label, f\"{observation_window}_y_test_{label}.csv\"))\n",
    "\n",
    "        X_external = pd.read_csv(find_file(load_path, f\"{observation_window}_X_external*.csv\"))\n",
    "        y_external = pd.read_csv(find_file(load_path_label, f\"{observation_window}_y_external_{label}.csv\"))\n",
    "\n",
    "        # Train model\n",
    "        model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Save model\n",
    "        file_prefix = f\"{folder}_{observation_window}_{label}\"\n",
    "        model.save_model(os.path.join(model_output_dir, f\"{file_prefix}_model.json\"))\n",
    "        logging.info(f\"Saved model to {model_output_dir}/{file_prefix}_model.json\")\n",
    "\n",
    "        # Predict\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        y_pred_ext = model.predict(X_external)\n",
    "\n",
    "        # Log basic metrics\n",
    "        mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "        mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "        rmse_test = np.sqrt(mse_test)\n",
    "        r2_test = r2_score(y_test, y_pred_test) * 100\n",
    "\n",
    "        mse_ext = mean_squared_error(y_external, y_pred_ext)\n",
    "        mae_ext = mean_absolute_error(y_external, y_pred_ext)\n",
    "        rmse_ext = np.sqrt(mse_ext)\n",
    "        r2_ext = r2_score(y_external, y_pred_ext) * 100\n",
    "\n",
    "        logging.info(f\"[{folder}] Test MSE: {mse_test:.4f} | MAE: {mae_test:.4f} | RMSE: {rmse_test:.4f} | R2: {r2_test:.2f}\")\n",
    "        logging.info(f\"[{folder}] External MSE: {mse_ext:.4f} | MAE: {mae_ext:.4f} | RMSE: {rmse_ext:.4f} | R2: {r2_ext:.2f}\")\n",
    "\n",
    "        # Generate plots and capture metrics\n",
    "        internal_metrics = plot_error_metrics(y_test, y_pred_test, file_prefix, plot_label='internal', config_label=\"no HP\")\n",
    "        external_metrics = plot_error_metrics(y_external, y_pred_ext, file_prefix, plot_label='external', config_label=\"no HP\")\n",
    "\n",
    "        # Append to all_metrics\n",
    "        all_metrics.append({\"folder\": folder, \"dataset\": \"internal\", **internal_metrics})\n",
    "        all_metrics.append({\"folder\": folder, \"dataset\": \"external\", **external_metrics})\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed in folder {folder}: {str(e)}\")\n",
    "\n",
    "# === AFTER MAIN LOOP ===\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "\n",
    "# Save metrics to CSV\n",
    "summary_csv_path = \"plots/03_Error_Metric_Plots/all_seq_metrics.csv\"\n",
    "metrics_df.to_csv(summary_csv_path, index=False)\n",
    "logging.info(f\"Saved summary metrics to: {summary_csv_path}\")\n",
    "\n",
    "\n",
    "# Melt the dataframe for plotting\n",
    "metrics_melted = metrics_df.melt(\n",
    "    id_vars=[\"folder\", \"dataset\"],\n",
    "    value_vars=[\"MSE\", \"MAE\", \"RMSE\", \"R2\", \"MSLE\"],\n",
    "    var_name=\"Metric\",\n",
    "    value_name=\"Value\"\n",
    ")\n",
    "\n",
    "# Drop missing MSLE rows (optional)\n",
    "metrics_melted = metrics_melted.dropna()\n",
    "\n",
    "# === CREATE ONE PLOT PER METRIC ===\n",
    "unique_metrics = metrics_melted[\"Metric\"].unique()\n",
    "\n",
    "for metric in unique_metrics:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    subset = metrics_melted[metrics_melted[\"Metric\"] == metric]\n",
    "    \n",
    "    sns.barplot(data=subset, x=\"folder\", y=\"Value\", hue=\"dataset\", palette=\"Set2\", errorbar=None)\n",
    "    plt.title(f\"{metric} Comparison (Internal vs External)\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel(\"Sequence Folder\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title=\"Dataset\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    metric_plot_path = f\"plots/03_Error_Metric_Plots/metric_{metric}_comparison_plot.png\"\n",
    "    plt.savefig(metric_plot_path, dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74908869-bd36-4ad7-962a-1282350a8921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc53466-a9ba-4bdb-8122-61d43c36d358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2b7c88-d88d-4b65-a92a-2ed976033f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915a85ce-332e-40d9-aa3f-4145ddcd15ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71755487-5db6-4b99-bc48-151e89cf0780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a26790-948e-4503-bd10-ab3f17979c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4c928a-f8bd-4e04-8081-f58864576a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368e904c-59f0-4c19-be34-728f3dea52ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8df8061-0d9e-4607-906e-06db392d6467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d4188a-e654-4c22-a3e9-9119ee9b18c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb72421-8e33-4429-a1d9-e180a15a1d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac7ad27-4477-461c-99b9-2f03787a15f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e16d8e0-d5c0-4e7e-a9c4-4ed697c852dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76faa84b-88b6-4b34-b000-8af0a4281216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044931cf-e025-4772-a5a5-31a5f1b5b4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e91fb7-40ba-4c2c-84ec-755bf92d24a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Base path and settings\n",
    "base_path = \"../../07_Imputation/CSV/exports/CIR-16/impute/\"\n",
    "observation_window = 'o4'\n",
    "label = 'los'\n",
    "model_output_dir = \"models/\"\n",
    "os.makedirs(model_output_dir, exist_ok=True)\n",
    "\n",
    "# Get all seq_* folders\n",
    "seq_folders = sorted([f for f in os.listdir(base_path) if f.startswith(\"seq_\")])\n",
    "\n",
    "# Helper to match files ignoring rank suffix\n",
    "def find_file(path, pattern):\n",
    "    matches = glob.glob(os.path.join(path, pattern))\n",
    "    return matches[0] if matches else None\n",
    "\n",
    "for folder in seq_folders:\n",
    "    logging.info(f\"Processing folder: {folder}\")\n",
    "    load_path = os.path.join(base_path, folder)\n",
    "\n",
    "    try:\n",
    "        # Dynamically find files\n",
    "        X_train_path = find_file(load_path, f\"{observation_window}_X_train*.csv\")\n",
    "        y_train_path = find_file(load_path, f\"{observation_window}_y_train_{label}.csv\")\n",
    "\n",
    "        X_validate_path = find_file(load_path, f\"{observation_window}_X_validate*.csv\")\n",
    "        y_validate_path = find_file(load_path, f\"{observation_window}_y_validate_{label}.csv\")\n",
    "\n",
    "        X_test_path = find_file(load_path, f\"{observation_window}_X_test*.csv\")\n",
    "        y_test_path = find_file(load_path, f\"{observation_window}_y_test_{label}.csv\")\n",
    "\n",
    "        X_external_path = find_file(load_path, f\"{observation_window}_X_external*.csv\")\n",
    "        y_external_path = find_file(load_path, f\"{observation_window}_y_external_{label}.csv\")\n",
    "\n",
    "        # Validate presence\n",
    "        if not all([X_train_path, y_train_path, X_validate_path, y_validate_path, X_test_path, y_test_path, X_external_path, y_external_path]):\n",
    "            raise FileNotFoundError(\"One or more required files not found in folder.\")\n",
    "\n",
    "        # Load data\n",
    "        X_train = pd.read_csv(X_train_path)\n",
    "        y_train = pd.read_csv(y_train_path)\n",
    "\n",
    "        X_validate = pd.read_csv(X_validate_path)\n",
    "        y_validate = pd.read_csv(y_validate_path)\n",
    "\n",
    "        X_test = pd.read_csv(X_test_path)\n",
    "        y_test = pd.read_csv(y_test_path)\n",
    "\n",
    "        X_external = pd.read_csv(X_external_path)\n",
    "        y_external = pd.read_csv(y_external_path)\n",
    "\n",
    "        # Train model\n",
    "        model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Save model\n",
    "        file_name = f\"{folder}_{observation_window}_{label}_model.json\"\n",
    "        file_path = os.path.join(model_output_dir, file_name)\n",
    "        model.save_model(file_path)\n",
    "        logging.info(f\"Saved model to {file_path}\")\n",
    "\n",
    "        # Evaluate on test\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "        mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "        rmse_test = np.sqrt(mse_test)\n",
    "        r2_test = r2_score(y_test, y_pred_test) * 100\n",
    "\n",
    "        # Evaluate on external\n",
    "        y_pred_ext = model.predict(X_external)\n",
    "        mse_ext = mean_squared_error(y_external, y_pred_ext)\n",
    "        mae_ext = mean_absolute_error(y_external, y_pred_ext)\n",
    "        rmse_ext = np.sqrt(mse_ext)\n",
    "        r2_ext = r2_score(y_external, y_pred_ext) * 100\n",
    "\n",
    "        # Log metrics\n",
    "        logging.info(f\"[{folder}] Test MSE: {mse_test:.4f} | MAE: {mae_test:.4f} | RMSE: {rmse_test:.4f} | R2: {r2_test:.2f}\")\n",
    "        logging.info(f\"[{folder}] External MSE: {mse_ext:.4f} | MAE: {mae_ext:.4f} | RMSE: {rmse_ext:.4f} | R2: {r2_ext:.2f}\")\n",
    "\n",
    "        file_prefix = f\"{folder}_{observation_window}_{label}\"\n",
    "\n",
    "        # For test set\n",
    "        plot_error_metrics(y_test, y_pred_test, file_prefix, plot_label='internal')\n",
    "\n",
    "        # For external validation set\n",
    "        plot_error_metrics(y_external, y_pred_ext, file_prefix, plot_label='external')\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed in folder {folder}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7d5eac-9a85-47ca-9b8b-e8a6ed5271a1",
   "metadata": {},
   "source": [
    "# Plot\n",
    "## Error Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501f0aa0-dde5-456e-ab1b-843e253fbbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plots error metrics (MSE, MAE, RMSE, MSLE if possible) and R² for a prediction set.\n",
    "    \n",
    "Args:\n",
    "    y_true (pd.Series or np.array): Ground truth values.\n",
    "    y_pred (np.array): Predicted values from the model.\n",
    "    file_prefix (str): Prefix for output file naming (e.g., 'seq_00_o4_los').\n",
    "    plot_label (str): 'internal' or 'external' or any identifier to mark the dataset.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def plot_error_metrics(y_true, y_pred, file_prefix: str, plot_label: str):\n",
    "    \n",
    "    # Metrics calculation\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred) * 100\n",
    "\n",
    "    print(f\"{plot_label.title()} Set MSE: {mse:.4f}\")\n",
    "    print(f\"{plot_label.title()} Set MAE: {mae:.4f}\")\n",
    "    print(f\"{plot_label.title()} Set RMSE: {rmse:.4f}\")\n",
    "    print(f\"{plot_label.title()} Set R2: {r2:.4f}\")\n",
    "\n",
    "    # Prepare metrics for bar plot\n",
    "    error_metrics = ['MSE', 'MAE', 'RMSE']\n",
    "    values = [mse, mae, rmse]\n",
    "\n",
    "    # Optional MSLE\n",
    "    try:\n",
    "        msle = mean_squared_log_error(y_true, y_pred)\n",
    "        print(f\"{plot_label.title()} Set MSLE: {msle:.4f}\")\n",
    "        error_metrics.append('MSLE')\n",
    "        values.append(msle)\n",
    "    except ValueError:\n",
    "        print(f\"{plot_label.title()} Set MSLE: Not computable due to negative values.\")\n",
    "\n",
    "    # Create output folder\n",
    "    plot_dir = \"plots/03_Error_Metric_Plots\"\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "    # Bar plot of error metrics\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(error_metrics, values, color=['blue', 'green', 'red', 'orange'][:len(error_metrics)])\n",
    "    plt.xlabel('Error Metric')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title(f'Comparison of Error Metrics ({plot_label.title()} Set)')\n",
    "    plt.savefig(f\"{plot_dir}/{file_prefix}_{plot_label}_error_metrics.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Pie chart for R²\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    if r2 >= 0:\n",
    "        plt.pie([r2, 100 - r2],\n",
    "                labels=['Explained Variance (R2)', 'Unexplained Variance'],\n",
    "                colors=['lightblue', 'lightgrey'],\n",
    "                autopct='%1.1f%%')\n",
    "    else:\n",
    "        plt.pie([100], labels=['Unexplained Variance'], colors=['lightgrey'], autopct='%1.1f%%')\n",
    "\n",
    "    plt.title(f'{plot_label.title()} Set Explained Variance by R²')\n",
    "    plt.savefig(f\"{plot_dir}/{file_prefix}_{plot_label}_R2.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb2f931-0881-4f54-a162-7183d3bb8465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270bfaee-7ccc-4c1a-b384-b8c225d2808b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8156f06-5783-423b-8c1b-d28814fecbfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982aa548-db18-4477-ac58-0921d1654c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168b89be-ddd5-47f8-b023-e22384727355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94418093-b5cd-47e0-88aa-e525b2db614a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff201a6-95e2-47db-b12c-f5ae99dcf15a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fe0978-e4b9-48f6-a45d-1fff9dea3118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c5a00f-d067-44d6-9aae-279d8bae89be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28177562-33f2-4ef9-a3f0-2beb2d36f26a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f73fbf-0765-4ba5-9a3a-106ff6a40e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0ab69b-99fe-4fa6-8ef2-1c687ab35cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bf7d36-26e5-4b29-ae41-dfbce2e07bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a30e6b-41e3-4bab-93fa-62125cb5ffe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "611aff28-e345-42d2-b5ce-0908f1686ce3",
   "metadata": {},
   "source": [
    "# Train Model without HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cc669b-d611-4a0e-8649-644016aebca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default XGBoost Model\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Predict on the external validation set (eICU data)\n",
    "y_pred_external = model.predict(X_external)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f727d0-6369-4e0e-9d2f-ae447500734d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# HP GridSearchCV\n",
    "## To slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3e5d12-f1bd-4242-9d64-35a14ba91996",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A smaller learning rate makes the boosting\n",
    "process more robust and can lead to better\n",
    "generalization but requires more trees\n",
    "(higher n_estimators) to achieve the same result.\n",
    "A larger learning rate speeds up training bu\n",
    "may risk overfitting.\n",
    "\"\"\"\n",
    "\n",
    "# Define the parameter grid\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300], # controls the total number of trees in the ensemble\n",
    "    'learning_rate': np.arange(0.01, 1.02, 0.2),\n",
    "    'max_depth': np.arange(1, 10, 1),\n",
    "    'reg_lambda': np.arange(0.1, 15.1, 1),\n",
    "    'reg_alpha': np.arange(0.1, 15.1, 1)\n",
    "}\n",
    "\n",
    "# Create an XGBoost Regressor\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \n",
    "                           scoring='neg_mean_squared_error', \n",
    "                           cv=3,  # Number of folds for cross-validation\n",
    "                           verbose=1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score (negative MSE):\", grid_search.best_score_)\n",
    "\n",
    "# Predict on the validation set with the best model\n",
    "y_pred_validate = grid_search.predict(X_validate)\n",
    "\n",
    "# Optionally: Evaluate the model on the validation set\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_validate, y_pred_validate)\n",
    "print(\"Validation MSE:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae09b09f-e87b-436b-bf5d-a35bb597659b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# HP RandomizedSearchCV & Train Model\n",
    "Choose randomly samples a subset of hyperparameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3316a365-114c-4f10-9553-469d66342b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_distributions = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': np.arange(0.01, 1.02, 0.2),\n",
    "    'max_depth': np.arange(1, 10, 1),\n",
    "    'reg_lambda': np.arange(0.1, 15.1, 1),\n",
    "    'reg_alpha': np.arange(0.1, 15.1, 1)\n",
    "}\n",
    "\n",
    "# Number of random samples\n",
    "n_iter = 50\n",
    "\n",
    "# Generate random combinations\n",
    "param_list = list(ParameterSampler(param_distributions, n_iter=n_iter, random_state=42))\n",
    "\n",
    "# Tracking best model\n",
    "best_score = float('inf')\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "# Progress bar\n",
    "for params in tqdm(param_list, desc=\"Hyperparameter tuning\"):\n",
    "    model = xgb.XGBRegressor(objective='reg:squarederror', **params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred_val = model.predict(X_validate)\n",
    "    \n",
    "    # Evaluate with MSE\n",
    "    mse = mean_squared_error(y_validate, y_pred_val)\n",
    "    \n",
    "    if mse < best_score:\n",
    "        best_score = mse\n",
    "        best_params = params\n",
    "        best_model = model\n",
    "\n",
    "# Evaluate best model on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Evaluate on external validation set\n",
    "y_pred_external = best_model.predict(X_external)\n",
    "mse_external = mean_squared_error(y_external, y_pred_external)\n",
    "mae_external = mean_absolute_error(y_external, y_pred_external)\n",
    "\n",
    "# Results\n",
    "logging.info(f\"Best parameters: {best_params}\")\n",
    "logging.info(f\"Best validation MSE: {best_score}\")\n",
    "logging.info(f\"Test Set - MSE: {mse_test}, MAE: {mae_test}\")\n",
    "logging.info(f\"External Validation Set - MSE: {mse_external}, MAE: {mae_external}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2110b1d7-7f38-42df-9eed-ed0829249eee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# HP Bayesian Optimization & Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09340dad-8d72-4555-9b84-07c6afa84bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tqdm progress bar\n",
    "pbar = tqdm(total=50, desc=\"Bayesian Optimization Progress\")\n",
    "\n",
    "# Callback to update tqdm\n",
    "def on_step(optim_result):\n",
    "    pbar.update(1)\n",
    "\n",
    "# Define the parameter search space\n",
    "param_space = {\n",
    "    'n_estimators': (100, 300),\n",
    "    'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "    'max_depth': (1, 10),\n",
    "    'reg_lambda': (0.1, 15.0),\n",
    "    'reg_alpha': (0.1, 15.0)\n",
    "}\n",
    "\n",
    "# Create the XGBoost Regressor\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Create BayesSearchCV for Bayesian Optimization\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    search_spaces=param_space,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_iter=50,\n",
    "    cv=3,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit BayesSearchCV with tqdm callback\n",
    "bayes_search.fit(X_train, y_train, callback=on_step)\n",
    "pbar.close()\n",
    "\n",
    "# Log best parameters and score\n",
    "logging.info(\"Best parameters: %s\", bayes_search.best_params_)\n",
    "logging.info(\"Best score (negative MSE): %.4f\", bayes_search.best_score_)\n",
    "\n",
    "# Predict on the validation set with the best model\n",
    "y_pred_validate = bayes_search.predict(X_validate)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "mse_validate = mean_squared_error(y_validate, y_pred_validate)\n",
    "mae_validate = mean_absolute_error(y_validate, y_pred_validate)\n",
    "logging.info(\"Validation MSE: %.4f\", mse_validate)\n",
    "logging.info(\"Validation MAE: %.4f\", mae_validate)\n",
    "\n",
    "# Extract the best hyperparameters from BayesSearchCV\n",
    "best_params = bayes_search.best_params_\n",
    "\n",
    "# Initialize the XGBoost model with the best hyperparameters\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    reg_lambda=best_params['reg_lambda'],\n",
    "    reg_alpha=best_params['reg_alpha']\n",
    ")\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Predict on the external validation set (eICU data)\n",
    "y_pred_external = model.predict(X_external)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on the external validation set\n",
    "mse_external = mean_squared_error(y_external, y_pred_external)\n",
    "mae_external = mean_absolute_error(y_external, y_pred_external)\n",
    "\n",
    "# Log final evaluation metrics\n",
    "logging.info(\"Test Set - MSE: %.4f, MAE: %.4f\", mse_test, mae_test)\n",
    "logging.info(\"External Validation Set (eICU) - MSE: %.4f, MAE: %.4f\", mse_external, mae_external)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63d430b-79c1-4340-835e-119a468f1483",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# HP HyperOpt & Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7b2115-569e-4929-90c0-da230a015f50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the number of evaluations\n",
    "MAX_EVALS = 50\n",
    "\n",
    "# Initialize tqdm progress bar\n",
    "pbar = tqdm(total=MAX_EVALS, desc=\"HyperOpt Progress\")\n",
    "\n",
    "# Define the wrapped objective function\n",
    "def objective(params):\n",
    "    model = xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        n_estimators=int(params['n_estimators']),\n",
    "        learning_rate=params['learning_rate'],\n",
    "        max_depth=int(params['max_depth']),\n",
    "        reg_lambda=params['reg_lambda'],\n",
    "        reg_alpha=params['reg_alpha']\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred_validate = model.predict(X_validate)\n",
    "    \n",
    "    # Compute the MSE\n",
    "    mse = mean_squared_error(y_validate, y_pred_validate)\n",
    "\n",
    "    # Log the result\n",
    "    logging.info(\"Params: %s | Validation MSE: %.4f\", params, mse)\n",
    "    \n",
    "    # Update progress bar\n",
    "    pbar.update(1)\n",
    "\n",
    "    return {'loss': mse, 'status': 'ok'}\n",
    "\n",
    "# Define the parameter search space\n",
    "param_space = {\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 100, 300, 50)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(1.0)),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.1, 15.0),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.1, 15.0)\n",
    "}\n",
    "\n",
    "# Create a Trials object to keep track of the search\n",
    "trials = Trials()\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=param_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=MAX_EVALS,\n",
    "    trials=trials,\n",
    "    show_progressbar=False  # Disable internal bar to avoid overlap with tqdm\n",
    ")\n",
    "\n",
    "# Close progress bar\n",
    "pbar.close()\n",
    "\n",
    "# Log the best parameters\n",
    "logging.info(\"Best parameters: %s\", best)\n",
    "\n",
    "# Initialize the XGBoost model with the best hyperparameters\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=int(best['n_estimators']),\n",
    "    learning_rate=best['learning_rate'],\n",
    "    max_depth=int(best['max_depth']),\n",
    "    reg_lambda=best['reg_lambda'],\n",
    "    reg_alpha=best['reg_alpha']\n",
    ")\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Predict on the external validation set (eICU data)\n",
    "y_pred_external = model.predict(X_external)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on the external validation set\n",
    "mse_external = mean_squared_error(y_external, y_pred_external)\n",
    "mae_external = mean_absolute_error(y_external, y_pred_external)\n",
    "\n",
    "# Log final evaluation results\n",
    "logging.info(\"Test Set - MSE: %.4f, MAE: %.4f\", mse_test, mae_test)\n",
    "logging.info(\"External Validation Set (eICU) - MSE: %.4f, MAE: %.4f\", mse_external, mae_external)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a810c9c-58b5-41f7-b700-e62558004bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "save_path = 'CSV/exports/impute/o03_Interpolation/'\n",
    "\n",
    "# Check if the directory exists, and if not, create it\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "# Save external validation set from eICU\n",
    "X_external.to_csv(save_path + 'X_external.csv', index=False)\n",
    "y_external.to_csv(save_path + 'y_external.csv', index=False)\n",
    "\n",
    "# Save training, validation, and test sets\n",
    "X_train.to_csv(save_path + 'X_train.csv', index=False)\n",
    "y_train.to_csv(save_path + 'y_train.csv', index=False)\n",
    "\n",
    "X_validate.to_csv(save_path + 'X_validate.csv', index=False)\n",
    "y_validate.to_csv(save_path + 'y_validate.csv', index=False)\n",
    "\n",
    "X_test.to_csv(save_path + 'X_test.csv', index=False)\n",
    "y_test.to_csv(save_path + 'y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1530e609-4239-4d84-88f6-48ed91bf5a28",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e03eb8-70ee-4578-bd93-2b7032252210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory and file path\n",
    "\n",
    "name = f\"{file_name}_model.json\"\n",
    "directory = 'models/'\n",
    "\n",
    "file_path = os.path.join(directory, name)\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Save the model as a JSON file\n",
    "model.save_model(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b303f38-a8c0-4488-8e9c-05a83768a275",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105cdba2-86f9-41a6-ba38-c11d492f9780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model file path\n",
    "file_name = \"06\"  # replace with the actual name you used before saving\n",
    "directory = 'models/'\n",
    "file_path = os.path.join(directory, f\"{file_name}_model.json\")\n",
    "\n",
    "# Load the model\n",
    "model = xgb.XGBRegressor()\n",
    "model.load_model(file_path)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Predict on the external validation set\n",
    "y_pred_external = model.predict(X_external)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c859dc-94ca-4033-a6cd-b91249f23693",
   "metadata": {},
   "source": [
    "# Test Set Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693bfe86-fa9d-4eae-b671-86c3c19ba10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics calculation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred) * 100\n",
    "\n",
    "print(f\"Test Set MSE: {mse:.4f}\")\n",
    "print(f\"Test Set MAE: {mae:.4f}\")\n",
    "print(f\"Test Set RMSE: {rmse:.4f}\")\n",
    "print(f\"Test Set R2: {r2:.4f}\")\n",
    "\n",
    "# Initialize error metrics\n",
    "error_metrics = ['MSE', 'MAE', 'RMSE']\n",
    "values = [mse, mae, rmse]\n",
    "\n",
    "# Try to calculate MSLE\n",
    "try:\n",
    "    msle = mean_squared_log_error(y_test, y_pred)\n",
    "    print(f\"Test Set MSLE: {msle:.4f}\")\n",
    "    \n",
    "    # Add MSLE to the list of metrics if applicable\n",
    "    error_metrics.append('MSLE')\n",
    "    values.append(msle)\n",
    "except ValueError:\n",
    "    print(\"Mean Squared Logarithmic Error cannot be calculated because targets contain negative values.\")\n",
    "\n",
    "# Plot error metrics (with or without MSLE)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(error_metrics, values, color=['blue', 'green', 'red', 'orange'][:len(error_metrics)])\n",
    "plt.xlabel('Error Metric')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison of Error Metrics')\n",
    "\n",
    "output_path = f\"plots/03_Error_Metric_Plots/{file_name}_internal_error_metrics.png\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R-squared (R2) for the test set\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "if r2 >= 0:\n",
    "    plt.pie([r2, 100 - r2], \n",
    "            labels=['Explained Variance (R2)', 'Unexplained Variance'], \n",
    "            colors=['lightblue', 'lightgrey'], autopct='%1.1f%%')\n",
    "else:\n",
    "    plt.pie([100], labels=['Unexplained Variance'], colors=['lightgrey'], autopct='%1.1f%%')\n",
    "\n",
    "plt.title('Test Set Explained Variance by R-squared (R2)')\n",
    "output_path = f\"plots/03_Error_Metric_Plots/{file_name}_internal_R2.png\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353110ac-0992-4807-9c0f-a88ec34b2c5a",
   "metadata": {},
   "source": [
    "# External Validation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077d35f0-0758-45ed-a510-b70a5e0af7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the external validation set (eICU data)\n",
    "y_pred_external = model.predict(X_external)\n",
    "\n",
    "# Metrics for external validation set\n",
    "mse_external = mean_squared_error(y_external, y_pred_external)\n",
    "mae_external = mean_absolute_error(y_external, y_pred_external)\n",
    "rmse_external = np.sqrt(mse_external)\n",
    "r2_external = r2_score(y_external, y_pred_external) * 100\n",
    "\n",
    "print(f\"External Validation Set MSE: {mse_external:.4f}\")\n",
    "print(f\"External Validation Set MAE: {mae_external:.4f}\")\n",
    "print(f\"External Validation Set RMSE: {rmse_external:.4f}\")\n",
    "print(f\"External Validation Set R2: {r2_external:.4f}\")\n",
    "\n",
    "# Initialize error metrics\n",
    "error_metrics = ['MSE', 'MAE', 'RMSE']\n",
    "values = [mse_external, mae_external, rmse_external]\n",
    "\n",
    "# Try to calculate MSLE\n",
    "try:\n",
    "    msle_external = mean_squared_log_error(y_external, y_pred_external)\n",
    "    print(f\"External Validation Set MSLE: {msle_external:.4f}\")\n",
    "    \n",
    "    # Add MSLE to the list of metrics if applicable\n",
    "    error_metrics.append('MSLE')\n",
    "    values.append(msle_external)\n",
    "except ValueError:\n",
    "    print(\"Mean Squared Logarithmic Error cannot be calculated because targets contain negative values.\")\n",
    "\n",
    "# Plot error metrics (with or without MSLE)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(error_metrics, values, color=['blue', 'green', 'red', 'orange'][:len(error_metrics)])\n",
    "plt.xlabel('Error Metric')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison of Error Metrics')\n",
    "\n",
    "\n",
    "output_path = f\"plots/03_Error_Metric_Plots/{file_name}_external_error_metrics.png\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R-squared (R2) for the external validation set\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "if r2_external >= 0:\n",
    "    plt.pie([r2_external, 100 - r2_external], \n",
    "            labels=['Explained Variance (R2)', 'Unexplained Variance'], \n",
    "            colors=['lightblue', 'lightgrey'], autopct='%1.1f%%')\n",
    "else:\n",
    "    plt.pie([100], labels=['Unexplained Variance'], colors=['lightgrey'], autopct='%1.1f%%')\n",
    "\n",
    "plt.title('Validation Set Explained Variance by R-squared (R2)')\n",
    "\n",
    "output_path = f\"plots/03_Error_Metric_Plots/{file_name}_external_R2.png\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ba566d-6b67-480f-a4bb-e394d8c01fce",
   "metadata": {},
   "source": [
    "# Calibration Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeba03a-8721-4a77-a1d2-557ac782c024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create calibration plot\n",
    "def plot_calibration(y_true, y_pred, title, filename):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.regplot(x=y_true, y=y_pred, lowess=True, line_kws={'color': 'red'}, scatter_kws={'alpha': 0.4})\n",
    "    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], 'k--', lw=2)\n",
    "    plt.xlabel('Actual LOS')\n",
    "    plt.ylabel('Predicted LOS')\n",
    "    plt.title(f'Calibration Plot: {title}')\n",
    "    plt.grid(True)\n",
    "\n",
    "    output_path = f\"plots/04_Calibration_Plots/{filename}.png\"\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Plot for test set\n",
    "plot_calibration(y_test, y_pred, \"Internal Test Set\", f\"{file_name}_calibration_internal\")\n",
    "\n",
    "# Plot for external set\n",
    "plot_calibration(y_external, y_pred_external, \"External Validation Set\", f\"{file_name}_calibration_external\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e5ee89-6e54-49fa-8e9b-40c5629f7ee6",
   "metadata": {},
   "source": [
    "# Most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f15d96-8eab-4129-9b21-4932c1701469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "most_important_df = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store feature importances along with their corresponding names\n",
    "most_important_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': most_important_df})\n",
    "\n",
    "# Sort the DataFrame by feature importance in descending order\n",
    "most_important_df = most_important_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Scale the importance\n",
    "most_important_df['Importance'] *= 100000\n",
    "\n",
    "# Print the top N most important features\n",
    "top_n = 20  # set features number\n",
    "print(f\"Top {top_n} most important features:\")\n",
    "print(most_important_df.head(top_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbf81e5-689e-4426-80ac-52c1c4ce470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_features = most_important_df.head(20).copy()  # Create a copy explicitly\n",
    "top_20_features['Feature'] = top_20_features['Feature'].apply(lambda x: '\\n'.join(textwrap.wrap(x, width=20)))\n",
    "\n",
    "# Set seaborn style and remove gridlines\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Top 20 most important features (create a copy)\n",
    "top_20_features = most_important_df.head(20).copy()\n",
    "\n",
    "# Wrap long feature names\n",
    "top_20_features['Feature'] = top_20_features['Feature'].apply(lambda x: '\\n'.join(textwrap.wrap(x, width=20)))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(18, 11))  # Increase figure size for better visibility\n",
    "plot = sns.barplot(x='Importance', y='Feature', data=top_20_features, hue='Feature', palette=\"Blues\", legend=False)\n",
    "\n",
    "# Set font size for labels and title\n",
    "plt.xlabel('Importance', fontsize=16)\n",
    "plt.ylabel('Feature', fontsize=16)\n",
    "plt.title('Top 20 Features with Highest Importance', fontsize=20)\n",
    "\n",
    "# Save the plot in high resolution\n",
    "output_path = f\"plots/01_Most_Important_SHAP/{file_name}_most_important_features.png\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f11674-d136-4426-926e-b759f5035a26",
   "metadata": {},
   "source": [
    "# Shap plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e76068-a999-43e9-a02f-7b565c2b6a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain the model's predictions using SHAP values\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# Mean absolute SHAP values to rank feature importance\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Mean Absolute SHAP Value': mean_abs_shap\n",
    "}).sort_values(by='Mean Absolute SHAP Value', ascending=False)\n",
    "\n",
    "# Display the top N most important features\n",
    "top_n = 20\n",
    "print(f\"Top {top_n} features by SHAP importance:\")\n",
    "print(feature_importance_df.head(top_n))\n",
    "\n",
    "# Create a Matplotlib figure\n",
    "plt.figure()\n",
    "\n",
    "# SHAP Summary Plot with Bee Swarm (distribution of feature impacts)\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"dot\", show=False)\n",
    "\n",
    "# Add grid to the plot\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the plot as a PNG image\n",
    "output_path = f\"plots/01_Most_Important_SHAP/{file_name}_shap_plot.png\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a20b9d-5a4b-45e5-b4e3-a828f0bbee44",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Create Shap by saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d72135-8af6-497a-8eed-594ef923aaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the XGBoost model from the JSON file\n",
    "model = xgb.Booster()  # Initialize the Booster object\n",
    "model.load_model(\"models\\\\02_Mean_Impute\\\\o11_Mean_Scale_Norm_Bayes_.json\")\n",
    "\n",
    "# I must load training - test set\n",
    "\n",
    "# Create a SHAP explainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# Generate SHAP summary plot\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"dot\", show=False)\n",
    "\n",
    "# Add grid to the plot\n",
    "plt.grid(True)\n",
    "\n",
    "# If i want to save the plot I must change in line 14 the show=True to False\n",
    "# plt.savefig(\"shap_summary_plot.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f616729d-6efe-452c-b36b-28b1d20bc257",
   "metadata": {},
   "source": [
    "# Plotting True vs. Predicted LOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d0bd3b-6125-44e6-a46d-a0f6c2acd1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, color='blue', label='Prediction')\n",
    "\n",
    "# Line for Perfect Prediction\n",
    "perfect_line = np.linspace(y_test.min(), y_test.max(), 100)\n",
    "plt.plot(perfect_line, perfect_line, color='red', linestyle='--', label='Perfect Prediction')\n",
    "\n",
    "# Labels, legend, and grid\n",
    "plt.xlabel('True LOS')\n",
    "plt.ylabel('Predicted LOS')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Predicted vs. True LOS (Test Set)')\n",
    "\n",
    "# Save the plot as a PNG image\n",
    "output_path = f\"plots/02_Prediction_Plot/02_true_vs_pred/{file_name}_true_vs_pred_test_plot.png\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# External Validation Set Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_external, y_pred_external, color='blue', label='Prediction')\n",
    "\n",
    "# Line for Perfect Prediction (y = x)\n",
    "perfect_line_ext = np.linspace(y_external.min(), y_external.max(), 100)\n",
    "plt.plot(perfect_line_ext, perfect_line_ext, color='red', linestyle='--', label='Perfect Prediction')\n",
    "\n",
    "# Labels, legend, and grid\n",
    "plt.xlabel('True LOS')\n",
    "plt.ylabel('Predicted LOS')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Predicted vs. True LOS (External Validation Set)')\n",
    "\n",
    "# Save the plot as a PNG image\n",
    "output_path = f\"plots/02_Prediction_Plot/02_true_vs_pred/{file_name}_true_vs_pred_external_plot.png\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8f9ec6-43a2-41b0-9a37-317c4db7bb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_test to a 1D numpy array\n",
    "y_test = y_test.values.flatten()\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# Plot residuals\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, residuals, color='blue', alpha=0.5, label=\"Residuals\")\n",
    "plt.axhline(y=0, color='red', linestyle='--', label=\"Zero Line\")\n",
    "plt.axhline(y=mae, color='green', linestyle='--', label=f\"MAE = {mae:.2f}\")\n",
    "plt.axhline(y=-mae, color='green', linestyle='--')\n",
    "plt.xlabel('True LOS')\n",
    "plt.ylabel('Residuals (True - Predicted)')\n",
    "plt.title('Residuals Plot with MAE Bounds')\n",
    "plt.grid(True)\n",
    "\n",
    "# Place the legend outside of the plot\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Save the plot as a PNG image\n",
    "output_path = f\"plots/02_Prediction_Plot/01_residuals/{file_name}_residuals_plot.png\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab45ed80-6c84-47ba-b7ed-34631763e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"y_pred shape:\", y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade636b8-35d8-4726-8587-7776029df178",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ba9b93-f41d-40cb-9e02-d7caaf2e647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_test to a 1D numpy array\n",
    "y_test = y_test.values.flatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
