{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6243b02-165d-496a-a198-f00704a71eb6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6671463d-f9c0-4542-b28c-eec0dfb36e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import textwrap\n",
    "import logging\n",
    "import glob\n",
    "\n",
    "from tqdm import tqdm\n",
    "#from matplotlib import pyplot\n",
    "#from skopt import BayesSearchCV\n",
    "#from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, ParameterGrid, train_test_split, ParameterSampler\n",
    "#from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error, mean_squared_log_error, r2_score\n",
    "\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import LSTM, Dense, Dropout, Input\n",
    "#from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22b8efbb-083c-4230-b048-59045707bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"logging.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b069035-3469-4e8c-8849-9225e0fad52e",
   "metadata": {},
   "source": [
    "# Load - Train - Save Models without HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2566b7a2-c82e-495f-bd3e-40eff4b34490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SETTINGS ===\n",
    "base_path = \"../../07_Imputation/CSV/exports/CIR-16/impute/\"\n",
    "observation_window = 'o4'\n",
    "label = 'los'\n",
    "model_output_dir = \"models/\"\n",
    "plot_dir = \"plots/03_Error_Metric_Plots\"\n",
    "\n",
    "os.makedirs(model_output_dir, exist_ok=True)\n",
    "os.makedirs(plot_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80845ae1-62fa-45d8-8b69-a5a3c959c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HELPER FUNCTION TO MATCH FILES ===\n",
    "def find_file(path, pattern):\n",
    "    matches = glob.glob(os.path.join(path, pattern))\n",
    "    return matches[0] if matches else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98221951-2d0e-44bb-8b89-2ce79eac7ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FUNCTION TO RUN XGBOOST ===\n",
    "def run_xgboost():\n",
    "    all_metrics = []  # collect all results for summary pivot plot\n",
    "    seq_folders = sorted([f for f in os.listdir(base_path) if f.startswith(\"seq_\")])\n",
    "\n",
    "    for folder in seq_folders:\n",
    "        logging.info(f\"Processing folder: {folder}\")\n",
    "        load_path = os.path.join(base_path, folder)\n",
    "        load_path_label = os.path.join(base_path, \"labels\")\n",
    "\n",
    "        try:\n",
    "            # Load data\n",
    "            X_train = pd.read_csv(find_file(load_path, f\"{observation_window}_X_train*.csv\"))\n",
    "            y_train = pd.read_csv(find_file(load_path_label, f\"{observation_window}_y_train_{label}.csv\"))\n",
    "\n",
    "            X_validate = pd.read_csv(find_file(load_path, f\"{observation_window}_X_validate*.csv\"))\n",
    "            y_validate = pd.read_csv(find_file(load_path_label, f\"{observation_window}_y_validate_{label}.csv\"))\n",
    "\n",
    "            X_test = pd.read_csv(find_file(load_path, f\"{observation_window}_X_test*.csv\"))\n",
    "            y_test = pd.read_csv(find_file(load_path_label, f\"{observation_window}_y_test_{label}.csv\"))\n",
    "\n",
    "            X_external = pd.read_csv(find_file(load_path, f\"{observation_window}_X_external*.csv\"))\n",
    "            y_external = pd.read_csv(find_file(load_path_label, f\"{observation_window}_y_external_{label}.csv\"))\n",
    "\n",
    "            # Train model\n",
    "            model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Save model\n",
    "            file_prefix = f\"{folder}_{observation_window}_{label}\"\n",
    "            model.save_model(os.path.join(model_output_dir, f\"{file_prefix}_model.json\"))\n",
    "            logging.info(f\"Saved model to {model_output_dir}/{file_prefix}_model.json\")\n",
    "\n",
    "            # Predict\n",
    "            y_pred_test = model.predict(X_test)\n",
    "            y_pred_ext = model.predict(X_external)\n",
    "\n",
    "            # Log metrics\n",
    "            logging.info(f\"[{folder}] Test MSE: {mean_squared_error(y_test, y_pred_test):.4f} | MAE: {mean_absolute_error(y_test, y_pred_test):.4f} | RMSE:{np.sqrt(mean_squared_error(y_test, y_pred_test)):.4f} | R2: {r2_score(y_test, y_pred_test)*100:.2f}\")\n",
    "            logging.info(f\"[{folder}] External MSE: {mean_squared_error(y_external, y_pred_ext):.4f} | MAE: {mean_absolute_error(y_external, y_pred_ext):.4f} | RMSE: {np.sqrt(mean_squared_error(y_external, y_pred_ext)):.4f} | R2: {r2_score(y_external, y_pred_ext)*100:.2f}\")\n",
    "\n",
    "            # Plot + metrics\n",
    "            internal_metrics = plot_error_metrics(y_test, y_pred_test, file_prefix, plot_label='internal', config_label=\"no HP\")\n",
    "            external_metrics = plot_error_metrics(y_external, y_pred_ext, file_prefix, plot_label='external', config_label=\"no HP\")\n",
    "\n",
    "            all_metrics.append({\"folder\": folder, \"dataset\": \"internal\", **internal_metrics})\n",
    "            all_metrics.append({\"folder\": folder, \"dataset\": \"external\", **external_metrics})\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed in folder {folder}: {str(e)}\")\n",
    "\n",
    "    # === AFTER MAIN LOOP ===\n",
    "    metrics_df = pd.DataFrame(all_metrics)\n",
    "    summary_csv_path = os.path.join(plot_dir, \"all_seq_metrics.csv\")\n",
    "    metrics_df.to_csv(summary_csv_path, index=False)\n",
    "    logging.info(f\"Saved summary metrics to: {summary_csv_path}\")\n",
    "\n",
    "    metrics_melted = metrics_df.melt(\n",
    "        id_vars=[\"folder\", \"dataset\"],\n",
    "        value_vars=[\"MSE\", \"MAE\", \"RMSE\", \"R2\", \"MSLE\"],\n",
    "        var_name=\"Metric\",\n",
    "        value_name=\"Value\"\n",
    "    ).dropna()\n",
    "\n",
    "    for metric in metrics_melted[\"Metric\"].unique():\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        subset = metrics_melted[metrics_melted[\"Metric\"] == metric]\n",
    "\n",
    "        sns.barplot(data=subset, x=\"folder\", y=\"Value\", hue=\"dataset\", palette=\"Set2\", errorbar=None)\n",
    "        plt.title(f\"{metric} Comparison (Internal vs External)\")\n",
    "        plt.ylabel(metric)\n",
    "        plt.xlabel(\"Sequence Folder\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend(title=\"Dataset\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        metric_plot_path = os.path.join(plot_dir, f\"metric_{metric}_comparison_plot.png\")\n",
    "        plt.savefig(metric_plot_path, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "# === MAIN FUNCTION ENTRY POINT ===\n",
    "def main(model_type=\"xgboost\"):\n",
    "    if model_type.lower() == \"xgboost\":\n",
    "        run_xgboost()\n",
    "    else:\n",
    "        logging.error(f\"Model type '{model_type}' is not supported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bd7766-7b41-4042-96b2-c151da2288e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6125eb09-e5bd-406f-9ffd-8d91f8c84fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e7e9a8-f354-491c-adf7-994f0f63fd62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a46ee6-b312-46a3-91a0-7cc94b3829ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5dc56f-e817-4d79-a03d-fe965b3bb748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9175b32-fac4-4875-b1f2-f8e64eb9a43e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa322981-eeeb-4556-b672-3e8dfa4e7f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e994ccda-f0ac-4dc4-94b3-64335da6ae7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2445f552-ef19-4141-a4b2-06ff908f1213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4204f05d-1a46-4008-a679-8d456a015238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c8b212d-8bad-4d04-a725-1e8264a9f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_metrics(y_true, y_pred, file_prefix: str, plot_label: str, config_label: str = \"no HP\"):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred) * 100\n",
    "\n",
    "    error_metrics = ['MSE', 'MAE', 'RMSE']\n",
    "    values = [mse, mae, rmse]\n",
    "\n",
    "    msle = np.nan\n",
    "    try:\n",
    "        msle = mean_squared_log_error(y_true, y_pred)\n",
    "        logging.info(f\"{plot_label.title()} Set MSLE: {msle:.4f}\")\n",
    "        error_metrics.append('MSLE')\n",
    "        values.append(msle)\n",
    "    except ValueError:\n",
    "        logging.info(f\"{plot_label.title()} Set MSLE: Not computable due to negative values.\")\n",
    "\n",
    "    # Bar plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(error_metrics, values, color=['blue', 'green', 'red', 'orange'][:len(error_metrics)])\n",
    "    plt.xlabel('Error Metric')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title(f'Error Metrics ({plot_label.title()} Set) - {config_label}')\n",
    "    plt.savefig(f\"{plot_dir}/{file_prefix}_{plot_label}_{config_label.replace(' ', '_')}_error_metrics.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # R² pie plot\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    if r2 >= 0:\n",
    "        plt.pie([r2, 100 - r2], labels=['Explained Variance (R2)', 'Unexplained Variance'],\n",
    "                colors=['lightblue', 'lightgrey'], autopct='%1.1f%%')\n",
    "    else:\n",
    "        plt.pie([100], labels=['Unexplained Variance'], colors=['lightgrey'], autopct='%1.1f%%')\n",
    "    plt.title(f'Explained Variance by R² ({plot_label.title()} Set) - {config_label}')\n",
    "    plt.savefig(f\"{plot_dir}/{file_prefix}_{plot_label}_{config_label.replace(' ', '_')}_R2.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    return {\n",
    "        \"MSE\": mse,\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R2\": r2,\n",
    "        \"MSLE\": msle\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc6960ae-c227-4cf8-8f8c-8cd0c07151ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 09:12:31,781 - INFO - Processing folder: seq_00_mean_mean_xgboost_xgboost_lstm_lstm_gan\n",
      "2025-05-25 09:12:34,816 - ERROR - Failed in folder seq_00_mean_mean_xgboost_xgboost_lstm_lstm_gan: Invalid file path or buffer object type: <class 'NoneType'>\n",
      "2025-05-25 09:12:34,816 - INFO - Processing folder: seq_01_mean_mean_xgboost_xgboost_lstm_lstm_rnn\n",
      "2025-05-25 09:12:37,995 - ERROR - Failed in folder seq_01_mean_mean_xgboost_xgboost_lstm_lstm_rnn: Invalid file path or buffer object type: <class 'NoneType'>\n",
      "2025-05-25 09:12:37,995 - INFO - Processing folder: seq_02_mean_mean_xgboost_xgboost_lstm_rnn_gan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m load_path_label \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(find_file(load_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobservation_window\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_X_train*.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     13\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(find_file(load_path_label, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobservation_window\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_y_train_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     15\u001b[0m     X_validate \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(find_file(load_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobservation_window\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_X_validate*.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m         nrows\n\u001b[0;32m   1925\u001b[0m     )\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\codecs.py:319\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_buffer_decode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, errors, final):\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;66;03m# Overwrite this method in subclasses: It must decode input\u001b[39;00m\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;66;03m# and return an (output, length consumed) tuple\u001b[39;00m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[0;32m    321\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m    322\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_decode(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors, final)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# === MAIN LOOP ===\n",
    "all_metrics = []  # collect all results for summary pivot plot\n",
    "seq_folders = sorted([f for f in os.listdir(base_path) if f.startswith(\"seq_\")])\n",
    "\n",
    "for folder in seq_folders:\n",
    "    logging.info(f\"Processing folder: {folder}\")\n",
    "    load_path = os.path.join(base_path, folder)\n",
    "    load_path_label = os.path.join(base_path, \"../labels\")\n",
    "\n",
    "    try:\n",
    "        # Load data\n",
    "        X_train = pd.read_csv(find_file(load_path, f\"{observation_window}_X_train*.csv\"))\n",
    "        y_train = pd.read_csv(find_file(load_path_label, f\"{observation_window}_y_train_{label}.csv\"))\n",
    "\n",
    "        X_validate = pd.read_csv(find_file(load_path, f\"{observation_window}_X_validate*.csv\"))\n",
    "        y_validate = pd.read_csv(find_file(load_path_label, f\"{observation_window}_y_validate_{label}.csv\"))\n",
    "\n",
    "        X_test = pd.read_csv(find_file(load_path, f\"{observation_window}_X_test*.csv\"))\n",
    "        y_test = pd.read_csv(find_file(load_path_label, f\"{observation_window}_y_test_{label}.csv\"))\n",
    "\n",
    "        X_external = pd.read_csv(find_file(load_path, f\"{observation_window}_X_external*.csv\"))\n",
    "        y_external = pd.read_csv(find_file(load_path_label, f\"{observation_window}_y_external_{label}.csv\"))\n",
    "\n",
    "        # Train model\n",
    "        model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Save model\n",
    "        file_prefix = f\"{folder}_{observation_window}_{label}\"\n",
    "        model.save_model(os.path.join(model_output_dir, f\"{file_prefix}_model.json\"))\n",
    "        logging.info(f\"Saved model to {model_output_dir}/{file_prefix}_model.json\")\n",
    "\n",
    "        # Predict\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        y_pred_ext = model.predict(X_external)\n",
    "\n",
    "        # Log basic metrics\n",
    "        mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "        mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "        rmse_test = np.sqrt(mse_test)\n",
    "        r2_test = r2_score(y_test, y_pred_test) * 100\n",
    "\n",
    "        mse_ext = mean_squared_error(y_external, y_pred_ext)\n",
    "        mae_ext = mean_absolute_error(y_external, y_pred_ext)\n",
    "        rmse_ext = np.sqrt(mse_ext)\n",
    "        r2_ext = r2_score(y_external, y_pred_ext) * 100\n",
    "\n",
    "        logging.info(f\"[{folder}] Test MSE: {mse_test:.4f} | MAE: {mae_test:.4f} | RMSE: {rmse_test:.4f} | R2: {r2_test:.2f}\")\n",
    "        logging.info(f\"[{folder}] External MSE: {mse_ext:.4f} | MAE: {mae_ext:.4f} | RMSE: {rmse_ext:.4f} | R2: {r2_ext:.2f}\")\n",
    "\n",
    "        # Generate plots and capture metrics\n",
    "        internal_metrics = plot_error_metrics(y_test, y_pred_test, file_prefix, plot_label='internal', config_label=\"no HP\")\n",
    "        external_metrics = plot_error_metrics(y_external, y_pred_ext, file_prefix, plot_label='external', config_label=\"no HP\")\n",
    "\n",
    "        # Append to all_metrics\n",
    "        all_metrics.append({\"folder\": folder, \"dataset\": \"internal\", **internal_metrics})\n",
    "        all_metrics.append({\"folder\": folder, \"dataset\": \"external\", **external_metrics})\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed in folder {folder}: {str(e)}\")\n",
    "\n",
    "# === AFTER MAIN LOOP ===\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "\n",
    "# Save metrics to CSV\n",
    "summary_csv_path = \"plots/03_Error_Metric_Plots/all_seq_metrics.csv\"\n",
    "metrics_df.to_csv(summary_csv_path, index=False)\n",
    "logging.info(f\"Saved summary metrics to: {summary_csv_path}\")\n",
    "\n",
    "\n",
    "# Melt the dataframe for plotting\n",
    "metrics_melted = metrics_df.melt(\n",
    "    id_vars=[\"folder\", \"dataset\"],\n",
    "    value_vars=[\"MSE\", \"MAE\", \"RMSE\", \"R2\", \"MSLE\"],\n",
    "    var_name=\"Metric\",\n",
    "    value_name=\"Value\"\n",
    ")\n",
    "\n",
    "# Drop missing MSLE rows (optional)\n",
    "metrics_melted = metrics_melted.dropna()\n",
    "\n",
    "# === CREATE ONE PLOT PER METRIC ===\n",
    "unique_metrics = metrics_melted[\"Metric\"].unique()\n",
    "\n",
    "for metric in unique_metrics:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    subset = metrics_melted[metrics_melted[\"Metric\"] == metric]\n",
    "    \n",
    "    sns.barplot(data=subset, x=\"folder\", y=\"Value\", hue=\"dataset\", palette=\"Set2\", errorbar=None)\n",
    "    plt.title(f\"{metric} Comparison (Internal vs External)\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel(\"Sequence Folder\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title=\"Dataset\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    metric_plot_path = f\"plots/03_Error_Metric_Plots/metric_{metric}_comparison_plot.png\"\n",
    "    plt.savefig(metric_plot_path, dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74908869-bd36-4ad7-962a-1282350a8921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc53466-a9ba-4bdb-8122-61d43c36d358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2b7c88-d88d-4b65-a92a-2ed976033f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915a85ce-332e-40d9-aa3f-4145ddcd15ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71755487-5db6-4b99-bc48-151e89cf0780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a26790-948e-4503-bd10-ab3f17979c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4c928a-f8bd-4e04-8081-f58864576a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368e904c-59f0-4c19-be34-728f3dea52ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8df8061-0d9e-4607-906e-06db392d6467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d4188a-e654-4c22-a3e9-9119ee9b18c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb72421-8e33-4429-a1d9-e180a15a1d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac7ad27-4477-461c-99b9-2f03787a15f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e16d8e0-d5c0-4e7e-a9c4-4ed697c852dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76faa84b-88b6-4b34-b000-8af0a4281216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044931cf-e025-4772-a5a5-31a5f1b5b4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37e91fb7-40ba-4c2c-84ec-755bf92d24a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 09:13:40,021 - INFO - Processing folder: seq_00_mean_mean_xgboost_xgboost_lstm_lstm_gan\n",
      "2025-05-25 09:13:40,037 - ERROR - Failed in folder seq_00_mean_mean_xgboost_xgboost_lstm_lstm_gan: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,037 - INFO - Processing folder: seq_01_mean_mean_xgboost_xgboost_lstm_lstm_rnn\n",
      "2025-05-25 09:13:40,037 - ERROR - Failed in folder seq_01_mean_mean_xgboost_xgboost_lstm_lstm_rnn: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,037 - INFO - Processing folder: seq_02_mean_mean_xgboost_xgboost_lstm_rnn_gan\n",
      "2025-05-25 09:13:40,053 - ERROR - Failed in folder seq_02_mean_mean_xgboost_xgboost_lstm_rnn_gan: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,053 - INFO - Processing folder: seq_03_mean_mean_xgboost_xgboost_lstm_rnn_rnn\n",
      "2025-05-25 09:13:40,053 - ERROR - Failed in folder seq_03_mean_mean_xgboost_xgboost_lstm_rnn_rnn: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,053 - INFO - Processing folder: seq_04_mean_mean_xgboost_xgboost_lstm_gan_gan\n",
      "2025-05-25 09:13:40,072 - ERROR - Failed in folder seq_04_mean_mean_xgboost_xgboost_lstm_gan_gan: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,075 - INFO - Processing folder: seq_122_knn_mean_xgboost_xgboost_gan_rnn_gan\n",
      "2025-05-25 09:13:40,087 - ERROR - Failed in folder seq_122_knn_mean_xgboost_xgboost_gan_rnn_gan: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,087 - INFO - Processing folder: seq_123_knn_mean_xgboost_xgboost_gan_rnn_rnn\n",
      "2025-05-25 09:13:40,087 - ERROR - Failed in folder seq_123_knn_mean_xgboost_xgboost_gan_rnn_rnn: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,087 - INFO - Processing folder: seq_124_knn_mean_xgboost_xgboost_gan_gan_gan\n",
      "2025-05-25 09:13:40,101 - ERROR - Failed in folder seq_124_knn_mean_xgboost_xgboost_gan_gan_gan: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,101 - INFO - Processing folder: seq_125_knn_mean_xgboost_xgboost_gan_gan_rnn\n",
      "2025-05-25 09:13:40,101 - ERROR - Failed in folder seq_125_knn_mean_xgboost_xgboost_gan_gan_rnn: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,101 - INFO - Processing folder: seq_126_knn_median_xgboost_xgboost_lstm_lstm_gan\n",
      "2025-05-25 09:13:40,116 - ERROR - Failed in folder seq_126_knn_median_xgboost_xgboost_lstm_lstm_gan: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,116 - INFO - Processing folder: seq_127_knn_median_xgboost_xgboost_lstm_lstm_rnn\n",
      "2025-05-25 09:13:40,116 - ERROR - Failed in folder seq_127_knn_median_xgboost_xgboost_lstm_lstm_rnn: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,116 - INFO - Processing folder: seq_128_knn_median_xgboost_xgboost_lstm_rnn_gan\n",
      "2025-05-25 09:13:40,116 - ERROR - Failed in folder seq_128_knn_median_xgboost_xgboost_lstm_rnn_gan: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,116 - INFO - Processing folder: seq_41_mean_knn_xgboost_xgboost_lstm_gan_rnn\n",
      "2025-05-25 09:13:40,132 - ERROR - Failed in folder seq_41_mean_knn_xgboost_xgboost_lstm_gan_rnn: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,132 - INFO - Processing folder: seq_42_mean_knn_xgboost_xgboost_rnn_lstm_gan\n",
      "2025-05-25 09:13:40,132 - ERROR - Failed in folder seq_42_mean_knn_xgboost_xgboost_rnn_lstm_gan: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,132 - INFO - Processing folder: seq_43_mean_knn_xgboost_xgboost_rnn_lstm_rnn\n",
      "2025-05-25 09:13:40,132 - ERROR - Failed in folder seq_43_mean_knn_xgboost_xgboost_rnn_lstm_rnn: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,132 - INFO - Processing folder: seq_44_mean_knn_xgboost_xgboost_rnn_rnn_gan\n",
      "2025-05-25 09:13:40,148 - ERROR - Failed in folder seq_44_mean_knn_xgboost_xgboost_rnn_rnn_gan: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,148 - INFO - Processing folder: seq_45_mean_knn_xgboost_xgboost_rnn_rnn_rnn\n",
      "2025-05-25 09:13:40,148 - ERROR - Failed in folder seq_45_mean_knn_xgboost_xgboost_rnn_rnn_rnn: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,148 - INFO - Processing folder: seq_46_mean_knn_xgboost_xgboost_rnn_gan_gan\n",
      "2025-05-25 09:13:40,148 - ERROR - Failed in folder seq_46_mean_knn_xgboost_xgboost_rnn_gan_gan: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,164 - INFO - Processing folder: seq_47_mean_knn_xgboost_xgboost_rnn_gan_rnn\n",
      "2025-05-25 09:13:40,164 - ERROR - Failed in folder seq_47_mean_knn_xgboost_xgboost_rnn_gan_rnn: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,164 - INFO - Processing folder: seq_48_mean_knn_xgboost_xgboost_gan_lstm_gan\n",
      "2025-05-25 09:13:40,164 - ERROR - Failed in folder seq_48_mean_knn_xgboost_xgboost_gan_lstm_gan: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,164 - INFO - Processing folder: seq_82_median_median_xgboost_xgboost_rnn_gan_gan\n",
      "2025-05-25 09:13:40,164 - ERROR - Failed in folder seq_82_median_median_xgboost_xgboost_rnn_gan_gan: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,180 - INFO - Processing folder: seq_83_median_median_xgboost_xgboost_rnn_gan_rnn\n",
      "2025-05-25 09:13:40,180 - ERROR - Failed in folder seq_83_median_median_xgboost_xgboost_rnn_gan_rnn: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,180 - INFO - Processing folder: seq_84_median_median_xgboost_xgboost_gan_lstm_gan\n",
      "2025-05-25 09:13:40,180 - ERROR - Failed in folder seq_84_median_median_xgboost_xgboost_gan_lstm_gan: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,180 - INFO - Processing folder: seq_85_median_median_xgboost_xgboost_gan_lstm_rnn\n",
      "2025-05-25 09:13:40,196 - ERROR - Failed in folder seq_85_median_median_xgboost_xgboost_gan_lstm_rnn: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,196 - INFO - Processing folder: seq_86_median_median_xgboost_xgboost_gan_rnn_gan\n",
      "2025-05-25 09:13:40,196 - ERROR - Failed in folder seq_86_median_median_xgboost_xgboost_gan_rnn_gan: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,196 - INFO - Processing folder: seq_87_median_median_xgboost_xgboost_gan_rnn_rnn\n",
      "2025-05-25 09:13:40,196 - ERROR - Failed in folder seq_87_median_median_xgboost_xgboost_gan_rnn_rnn: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,211 - INFO - Processing folder: seq_88_median_median_xgboost_xgboost_gan_gan_gan\n",
      "2025-05-25 09:13:40,216 - ERROR - Failed in folder seq_88_median_median_xgboost_xgboost_gan_gan_gan: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,216 - INFO - Processing folder: seq_89_median_median_xgboost_xgboost_gan_gan_rnn\n",
      "2025-05-25 09:13:40,216 - ERROR - Failed in folder seq_89_median_median_xgboost_xgboost_gan_gan_rnn: One or more required files not found in folder.\n",
      "2025-05-25 09:13:40,216 - INFO - Processing folder: seq_90_median_knn_xgboost_xgboost_lstm_lstm_gan\n",
      "2025-05-25 09:13:40,227 - ERROR - Failed in folder seq_90_median_knn_xgboost_xgboost_lstm_lstm_gan: One or more required files not found in folder.\n"
     ]
    }
   ],
   "source": [
    "# Base path and settings\n",
    "base_path = \"../../07_Imputation/CSV/exports/CIR-16/impute/\"\n",
    "observation_window = 'o4'\n",
    "label = 'los'\n",
    "model_output_dir = \"models/\"\n",
    "os.makedirs(model_output_dir, exist_ok=True)\n",
    "\n",
    "# Get all seq_* folders\n",
    "seq_folders = sorted([f for f in os.listdir(base_path) if f.startswith(\"seq_\")])\n",
    "\n",
    "# Helper to match files ignoring rank suffix\n",
    "def find_file(path, pattern):\n",
    "    matches = glob.glob(os.path.join(path, pattern))\n",
    "    return matches[0] if matches else None\n",
    "\n",
    "for folder in seq_folders:\n",
    "    logging.info(f\"Processing folder: {folder}\")\n",
    "    load_path = os.path.join(base_path, folder)\n",
    "\n",
    "    try:\n",
    "        # Dynamically find files\n",
    "        X_train_path = find_file(load_path, f\"{observation_window}_X_train*.csv\")\n",
    "        y_train_path = find_file(load_path, f\"{observation_window}_y_train_{label}.csv\")\n",
    "\n",
    "        X_validate_path = find_file(load_path, f\"{observation_window}_X_validate*.csv\")\n",
    "        y_validate_path = find_file(load_path, f\"{observation_window}_y_validate_{label}.csv\")\n",
    "\n",
    "        X_test_path = find_file(load_path, f\"{observation_window}_X_test*.csv\")\n",
    "        y_test_path = find_file(load_path, f\"{observation_window}_y_test_{label}.csv\")\n",
    "\n",
    "        X_external_path = find_file(load_path, f\"{observation_window}_X_external*.csv\")\n",
    "        y_external_path = find_file(load_path, f\"{observation_window}_y_external_{label}.csv\")\n",
    "\n",
    "        # Validate presence\n",
    "        if not all([X_train_path, y_train_path, X_validate_path, y_validate_path, X_test_path, y_test_path, X_external_path, y_external_path]):\n",
    "            raise FileNotFoundError(\"One or more required files not found in folder.\")\n",
    "\n",
    "        # Load data\n",
    "        X_train = pd.read_csv(X_train_path)\n",
    "        y_train = pd.read_csv(y_train_path)\n",
    "\n",
    "        X_validate = pd.read_csv(X_validate_path)\n",
    "        y_validate = pd.read_csv(y_validate_path)\n",
    "\n",
    "        X_test = pd.read_csv(X_test_path)\n",
    "        y_test = pd.read_csv(y_test_path)\n",
    "\n",
    "        X_external = pd.read_csv(X_external_path)\n",
    "        y_external = pd.read_csv(y_external_path)\n",
    "\n",
    "        # Train model\n",
    "        model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Save model\n",
    "        file_name = f\"{folder}_{observation_window}_{label}_model.json\"\n",
    "        file_path = os.path.join(model_output_dir, file_name)\n",
    "        model.save_model(file_path)\n",
    "        logging.info(f\"Saved model to {file_path}\")\n",
    "\n",
    "        # Evaluate on test\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "        mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "        rmse_test = np.sqrt(mse_test)\n",
    "        r2_test = r2_score(y_test, y_pred_test) * 100\n",
    "\n",
    "        # Evaluate on external\n",
    "        y_pred_ext = model.predict(X_external)\n",
    "        mse_ext = mean_squared_error(y_external, y_pred_ext)\n",
    "        mae_ext = mean_absolute_error(y_external, y_pred_ext)\n",
    "        rmse_ext = np.sqrt(mse_ext)\n",
    "        r2_ext = r2_score(y_external, y_pred_ext) * 100\n",
    "\n",
    "        # Log metrics\n",
    "        logging.info(f\"[{folder}] Test MSE: {mse_test:.4f} | MAE: {mae_test:.4f} | RMSE: {rmse_test:.4f} | R2: {r2_test:.2f}\")\n",
    "        logging.info(f\"[{folder}] External MSE: {mse_ext:.4f} | MAE: {mae_ext:.4f} | RMSE: {rmse_ext:.4f} | R2: {r2_ext:.2f}\")\n",
    "\n",
    "        file_prefix = f\"{folder}_{observation_window}_{label}\"\n",
    "\n",
    "        # For test set\n",
    "        plot_error_metrics(y_test, y_pred_test, file_prefix, plot_label='internal')\n",
    "\n",
    "        # For external validation set\n",
    "        plot_error_metrics(y_external, y_pred_ext, file_prefix, plot_label='external')\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed in folder {folder}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7d5eac-9a85-47ca-9b8b-e8a6ed5271a1",
   "metadata": {},
   "source": [
    "# Plot\n",
    "## Error Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501f0aa0-dde5-456e-ab1b-843e253fbbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plots error metrics (MSE, MAE, RMSE, MSLE if possible) and R² for a prediction set.\n",
    "    \n",
    "Args:\n",
    "    y_true (pd.Series or np.array): Ground truth values.\n",
    "    y_pred (np.array): Predicted values from the model.\n",
    "    file_prefix (str): Prefix for output file naming (e.g., 'seq_00_o4_los').\n",
    "    plot_label (str): 'internal' or 'external' or any identifier to mark the dataset.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def plot_error_metrics(y_true, y_pred, file_prefix: str, plot_label: str):\n",
    "    \n",
    "    # Metrics calculation\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred) * 100\n",
    "\n",
    "    print(f\"{plot_label.title()} Set MSE: {mse:.4f}\")\n",
    "    print(f\"{plot_label.title()} Set MAE: {mae:.4f}\")\n",
    "    print(f\"{plot_label.title()} Set RMSE: {rmse:.4f}\")\n",
    "    print(f\"{plot_label.title()} Set R2: {r2:.4f}\")\n",
    "\n",
    "    # Prepare metrics for bar plot\n",
    "    error_metrics = ['MSE', 'MAE', 'RMSE']\n",
    "    values = [mse, mae, rmse]\n",
    "\n",
    "    # Optional MSLE\n",
    "    try:\n",
    "        msle = mean_squared_log_error(y_true, y_pred)\n",
    "        print(f\"{plot_label.title()} Set MSLE: {msle:.4f}\")\n",
    "        error_metrics.append('MSLE')\n",
    "        values.append(msle)\n",
    "    except ValueError:\n",
    "        print(f\"{plot_label.title()} Set MSLE: Not computable due to negative values.\")\n",
    "\n",
    "    # Create output folder\n",
    "    plot_dir = \"plots/03_Error_Metric_Plots\"\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "    # Bar plot of error metrics\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(error_metrics, values, color=['blue', 'green', 'red', 'orange'][:len(error_metrics)])\n",
    "    plt.xlabel('Error Metric')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title(f'Comparison of Error Metrics ({plot_label.title()} Set)')\n",
    "    plt.savefig(f\"{plot_dir}/{file_prefix}_{plot_label}_error_metrics.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Pie chart for R²\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    if r2 >= 0:\n",
    "        plt.pie([r2, 100 - r2],\n",
    "                labels=['Explained Variance (R2)', 'Unexplained Variance'],\n",
    "                colors=['lightblue', 'lightgrey'],\n",
    "                autopct='%1.1f%%')\n",
    "    else:\n",
    "        plt.pie([100], labels=['Unexplained Variance'], colors=['lightgrey'], autopct='%1.1f%%')\n",
    "\n",
    "    plt.title(f'{plot_label.title()} Set Explained Variance by R²')\n",
    "    plt.savefig(f\"{plot_dir}/{file_prefix}_{plot_label}_R2.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb2f931-0881-4f54-a162-7183d3bb8465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270bfaee-7ccc-4c1a-b384-b8c225d2808b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8156f06-5783-423b-8c1b-d28814fecbfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982aa548-db18-4477-ac58-0921d1654c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168b89be-ddd5-47f8-b023-e22384727355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94418093-b5cd-47e0-88aa-e525b2db614a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff201a6-95e2-47db-b12c-f5ae99dcf15a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fe0978-e4b9-48f6-a45d-1fff9dea3118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c5a00f-d067-44d6-9aae-279d8bae89be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28177562-33f2-4ef9-a3f0-2beb2d36f26a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f73fbf-0765-4ba5-9a3a-106ff6a40e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0ab69b-99fe-4fa6-8ef2-1c687ab35cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bf7d36-26e5-4b29-ae41-dfbce2e07bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a30e6b-41e3-4bab-93fa-62125cb5ffe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "611aff28-e345-42d2-b5ce-0908f1686ce3",
   "metadata": {},
   "source": [
    "# Train Model without HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cc669b-d611-4a0e-8649-644016aebca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default XGBoost Model\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Predict on the external validation set (eICU data)\n",
    "y_pred_external = model.predict(X_external)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f727d0-6369-4e0e-9d2f-ae447500734d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# HP GridSearchCV\n",
    "## To slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3e5d12-f1bd-4242-9d64-35a14ba91996",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A smaller learning rate makes the boosting\n",
    "process more robust and can lead to better\n",
    "generalization but requires more trees\n",
    "(higher n_estimators) to achieve the same result.\n",
    "A larger learning rate speeds up training bu\n",
    "may risk overfitting.\n",
    "\"\"\"\n",
    "\n",
    "# Define the parameter grid\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300], # controls the total number of trees in the ensemble\n",
    "    'learning_rate': np.arange(0.01, 1.02, 0.2),\n",
    "    'max_depth': np.arange(1, 10, 1),\n",
    "    'reg_lambda': np.arange(0.1, 15.1, 1),\n",
    "    'reg_alpha': np.arange(0.1, 15.1, 1)\n",
    "}\n",
    "\n",
    "# Create an XGBoost Regressor\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \n",
    "                           scoring='neg_mean_squared_error', \n",
    "                           cv=3,  # Number of folds for cross-validation\n",
    "                           verbose=1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score (negative MSE):\", grid_search.best_score_)\n",
    "\n",
    "# Predict on the validation set with the best model\n",
    "y_pred_validate = grid_search.predict(X_validate)\n",
    "\n",
    "# Optionally: Evaluate the model on the validation set\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_validate, y_pred_validate)\n",
    "print(\"Validation MSE:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae09b09f-e87b-436b-bf5d-a35bb597659b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# HP RandomizedSearchCV & Train Model\n",
    "Choose randomly samples a subset of hyperparameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3316a365-114c-4f10-9553-469d66342b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_distributions = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': np.arange(0.01, 1.02, 0.2),\n",
    "    'max_depth': np.arange(1, 10, 1),\n",
    "    'reg_lambda': np.arange(0.1, 15.1, 1),\n",
    "    'reg_alpha': np.arange(0.1, 15.1, 1)\n",
    "}\n",
    "\n",
    "# Number of random samples\n",
    "n_iter = 50\n",
    "\n",
    "# Generate random combinations\n",
    "param_list = list(ParameterSampler(param_distributions, n_iter=n_iter, random_state=42))\n",
    "\n",
    "# Tracking best model\n",
    "best_score = float('inf')\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "# Progress bar\n",
    "for params in tqdm(param_list, desc=\"Hyperparameter tuning\"):\n",
    "    model = xgb.XGBRegressor(objective='reg:squarederror', **params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred_val = model.predict(X_validate)\n",
    "    \n",
    "    # Evaluate with MSE\n",
    "    mse = mean_squared_error(y_validate, y_pred_val)\n",
    "    \n",
    "    if mse < best_score:\n",
    "        best_score = mse\n",
    "        best_params = params\n",
    "        best_model = model\n",
    "\n",
    "# Evaluate best model on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Evaluate on external validation set\n",
    "y_pred_external = best_model.predict(X_external)\n",
    "mse_external = mean_squared_error(y_external, y_pred_external)\n",
    "mae_external = mean_absolute_error(y_external, y_pred_external)\n",
    "\n",
    "# Results\n",
    "logging.info(f\"Best parameters: {best_params}\")\n",
    "logging.info(f\"Best validation MSE: {best_score}\")\n",
    "logging.info(f\"Test Set - MSE: {mse_test}, MAE: {mae_test}\")\n",
    "logging.info(f\"External Validation Set - MSE: {mse_external}, MAE: {mae_external}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2110b1d7-7f38-42df-9eed-ed0829249eee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# HP Bayesian Optimization & Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09340dad-8d72-4555-9b84-07c6afa84bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tqdm progress bar\n",
    "pbar = tqdm(total=50, desc=\"Bayesian Optimization Progress\")\n",
    "\n",
    "# Callback to update tqdm\n",
    "def on_step(optim_result):\n",
    "    pbar.update(1)\n",
    "\n",
    "# Define the parameter search space\n",
    "param_space = {\n",
    "    'n_estimators': (100, 300),\n",
    "    'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "    'max_depth': (1, 10),\n",
    "    'reg_lambda': (0.1, 15.0),\n",
    "    'reg_alpha': (0.1, 15.0)\n",
    "}\n",
    "\n",
    "# Create the XGBoost Regressor\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Create BayesSearchCV for Bayesian Optimization\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    search_spaces=param_space,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_iter=50,\n",
    "    cv=3,\n",
    "    verbose=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit BayesSearchCV with tqdm callback\n",
    "bayes_search.fit(X_train, y_train, callback=on_step)\n",
    "pbar.close()\n",
    "\n",
    "# Log best parameters and score\n",
    "logging.info(\"Best parameters: %s\", bayes_search.best_params_)\n",
    "logging.info(\"Best score (negative MSE): %.4f\", bayes_search.best_score_)\n",
    "\n",
    "# Predict on the validation set with the best model\n",
    "y_pred_validate = bayes_search.predict(X_validate)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "mse_validate = mean_squared_error(y_validate, y_pred_validate)\n",
    "mae_validate = mean_absolute_error(y_validate, y_pred_validate)\n",
    "logging.info(\"Validation MSE: %.4f\", mse_validate)\n",
    "logging.info(\"Validation MAE: %.4f\", mae_validate)\n",
    "\n",
    "# Extract the best hyperparameters from BayesSearchCV\n",
    "best_params = bayes_search.best_params_\n",
    "\n",
    "# Initialize the XGBoost model with the best hyperparameters\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    reg_lambda=best_params['reg_lambda'],\n",
    "    reg_alpha=best_params['reg_alpha']\n",
    ")\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Predict on the external validation set (eICU data)\n",
    "y_pred_external = model.predict(X_external)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on the external validation set\n",
    "mse_external = mean_squared_error(y_external, y_pred_external)\n",
    "mae_external = mean_absolute_error(y_external, y_pred_external)\n",
    "\n",
    "# Log final evaluation metrics\n",
    "logging.info(\"Test Set - MSE: %.4f, MAE: %.4f\", mse_test, mae_test)\n",
    "logging.info(\"External Validation Set (eICU) - MSE: %.4f, MAE: %.4f\", mse_external, mae_external)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63d430b-79c1-4340-835e-119a468f1483",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# HP HyperOpt & Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7b2115-569e-4929-90c0-da230a015f50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the number of evaluations\n",
    "MAX_EVALS = 50\n",
    "\n",
    "# Initialize tqdm progress bar\n",
    "pbar = tqdm(total=MAX_EVALS, desc=\"HyperOpt Progress\")\n",
    "\n",
    "# Define the wrapped objective function\n",
    "def objective(params):\n",
    "    model = xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        n_estimators=int(params['n_estimators']),\n",
    "        learning_rate=params['learning_rate'],\n",
    "        max_depth=int(params['max_depth']),\n",
    "        reg_lambda=params['reg_lambda'],\n",
    "        reg_alpha=params['reg_alpha']\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred_validate = model.predict(X_validate)\n",
    "    \n",
    "    # Compute the MSE\n",
    "    mse = mean_squared_error(y_validate, y_pred_validate)\n",
    "\n",
    "    # Log the result\n",
    "    logging.info(\"Params: %s | Validation MSE: %.4f\", params, mse)\n",
    "    \n",
    "    # Update progress bar\n",
    "    pbar.update(1)\n",
    "\n",
    "    return {'loss': mse, 'status': 'ok'}\n",
    "\n",
    "# Define the parameter search space\n",
    "param_space = {\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 100, 300, 50)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(1.0)),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.1, 15.0),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.1, 15.0)\n",
    "}\n",
    "\n",
    "# Create a Trials object to keep track of the search\n",
    "trials = Trials()\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=param_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=MAX_EVALS,\n",
    "    trials=trials,\n",
    "    show_progressbar=False  # Disable internal bar to avoid overlap with tqdm\n",
    ")\n",
    "\n",
    "# Close progress bar\n",
    "pbar.close()\n",
    "\n",
    "# Log the best parameters\n",
    "logging.info(\"Best parameters: %s\", best)\n",
    "\n",
    "# Initialize the XGBoost model with the best hyperparameters\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=int(best['n_estimators']),\n",
    "    learning_rate=best['learning_rate'],\n",
    "    max_depth=int(best['max_depth']),\n",
    "    reg_lambda=best['reg_lambda'],\n",
    "    reg_alpha=best['reg_alpha']\n",
    ")\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Predict on the external validation set (eICU data)\n",
    "y_pred_external = model.predict(X_external)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on the external validation set\n",
    "mse_external = mean_squared_error(y_external, y_pred_external)\n",
    "mae_external = mean_absolute_error(y_external, y_pred_external)\n",
    "\n",
    "# Log final evaluation results\n",
    "logging.info(\"Test Set - MSE: %.4f, MAE: %.4f\", mse_test, mae_test)\n",
    "logging.info(\"External Validation Set (eICU) - MSE: %.4f, MAE: %.4f\", mse_external, mae_external)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a810c9c-58b5-41f7-b700-e62558004bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "save_path = 'CSV/exports/impute/o03_Interpolation/'\n",
    "\n",
    "# Check if the directory exists, and if not, create it\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "# Save external validation set from eICU\n",
    "X_external.to_csv(save_path + 'X_external.csv', index=False)\n",
    "y_external.to_csv(save_path + 'y_external.csv', index=False)\n",
    "\n",
    "# Save training, validation, and test sets\n",
    "X_train.to_csv(save_path + 'X_train.csv', index=False)\n",
    "y_train.to_csv(save_path + 'y_train.csv', index=False)\n",
    "\n",
    "X_validate.to_csv(save_path + 'X_validate.csv', index=False)\n",
    "y_validate.to_csv(save_path + 'y_validate.csv', index=False)\n",
    "\n",
    "X_test.to_csv(save_path + 'X_test.csv', index=False)\n",
    "y_test.to_csv(save_path + 'y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1530e609-4239-4d84-88f6-48ed91bf5a28",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e03eb8-70ee-4578-bd93-2b7032252210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory and file path\n",
    "\n",
    "name = f\"{file_name}_model.json\"\n",
    "directory = 'models/'\n",
    "\n",
    "file_path = os.path.join(directory, name)\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Save the model as a JSON file\n",
    "model.save_model(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b303f38-a8c0-4488-8e9c-05a83768a275",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105cdba2-86f9-41a6-ba38-c11d492f9780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model file path\n",
    "file_name = \"06\"  # replace with the actual name you used before saving\n",
    "directory = 'models/'\n",
    "file_path = os.path.join(directory, f\"{file_name}_model.json\")\n",
    "\n",
    "# Load the model\n",
    "model = xgb.XGBRegressor()\n",
    "model.load_model(file_path)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Predict on the external validation set\n",
    "y_pred_external = model.predict(X_external)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c859dc-94ca-4033-a6cd-b91249f23693",
   "metadata": {},
   "source": [
    "# Test Set Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693bfe86-fa9d-4eae-b671-86c3c19ba10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics calculation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred) * 100\n",
    "\n",
    "print(f\"Test Set MSE: {mse:.4f}\")\n",
    "print(f\"Test Set MAE: {mae:.4f}\")\n",
    "print(f\"Test Set RMSE: {rmse:.4f}\")\n",
    "print(f\"Test Set R2: {r2:.4f}\")\n",
    "\n",
    "# Initialize error metrics\n",
    "error_metrics = ['MSE', 'MAE', 'RMSE']\n",
    "values = [mse, mae, rmse]\n",
    "\n",
    "# Try to calculate MSLE\n",
    "try:\n",
    "    msle = mean_squared_log_error(y_test, y_pred)\n",
    "    print(f\"Test Set MSLE: {msle:.4f}\")\n",
    "    \n",
    "    # Add MSLE to the list of metrics if applicable\n",
    "    error_metrics.append('MSLE')\n",
    "    values.append(msle)\n",
    "except ValueError:\n",
    "    print(\"Mean Squared Logarithmic Error cannot be calculated because targets contain negative values.\")\n",
    "\n",
    "# Plot error metrics (with or without MSLE)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(error_metrics, values, color=['blue', 'green', 'red', 'orange'][:len(error_metrics)])\n",
    "plt.xlabel('Error Metric')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison of Error Metrics')\n",
    "\n",
    "output_path = f\"plots/03_Error_Metric_Plots/{file_name}_internal_error_metrics.png\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R-squared (R2) for the test set\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "if r2 >= 0:\n",
    "    plt.pie([r2, 100 - r2], \n",
    "            labels=['Explained Variance (R2)', 'Unexplained Variance'], \n",
    "            colors=['lightblue', 'lightgrey'], autopct='%1.1f%%')\n",
    "else:\n",
    "    plt.pie([100], labels=['Unexplained Variance'], colors=['lightgrey'], autopct='%1.1f%%')\n",
    "\n",
    "plt.title('Test Set Explained Variance by R-squared (R2)')\n",
    "output_path = f\"plots/03_Error_Metric_Plots/{file_name}_internal_R2.png\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353110ac-0992-4807-9c0f-a88ec34b2c5a",
   "metadata": {},
   "source": [
    "# External Validation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077d35f0-0758-45ed-a510-b70a5e0af7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the external validation set (eICU data)\n",
    "y_pred_external = model.predict(X_external)\n",
    "\n",
    "# Metrics for external validation set\n",
    "mse_external = mean_squared_error(y_external, y_pred_external)\n",
    "mae_external = mean_absolute_error(y_external, y_pred_external)\n",
    "rmse_external = np.sqrt(mse_external)\n",
    "r2_external = r2_score(y_external, y_pred_external) * 100\n",
    "\n",
    "print(f\"External Validation Set MSE: {mse_external:.4f}\")\n",
    "print(f\"External Validation Set MAE: {mae_external:.4f}\")\n",
    "print(f\"External Validation Set RMSE: {rmse_external:.4f}\")\n",
    "print(f\"External Validation Set R2: {r2_external:.4f}\")\n",
    "\n",
    "# Initialize error metrics\n",
    "error_metrics = ['MSE', 'MAE', 'RMSE']\n",
    "values = [mse_external, mae_external, rmse_external]\n",
    "\n",
    "# Try to calculate MSLE\n",
    "try:\n",
    "    msle_external = mean_squared_log_error(y_external, y_pred_external)\n",
    "    print(f\"External Validation Set MSLE: {msle_external:.4f}\")\n",
    "    \n",
    "    # Add MSLE to the list of metrics if applicable\n",
    "    error_metrics.append('MSLE')\n",
    "    values.append(msle_external)\n",
    "except ValueError:\n",
    "    print(\"Mean Squared Logarithmic Error cannot be calculated because targets contain negative values.\")\n",
    "\n",
    "# Plot error metrics (with or without MSLE)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(error_metrics, values, color=['blue', 'green', 'red', 'orange'][:len(error_metrics)])\n",
    "plt.xlabel('Error Metric')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison of Error Metrics')\n",
    "\n",
    "\n",
    "output_path = f\"plots/03_Error_Metric_Plots/{file_name}_external_error_metrics.png\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R-squared (R2) for the external validation set\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "if r2_external >= 0:\n",
    "    plt.pie([r2_external, 100 - r2_external], \n",
    "            labels=['Explained Variance (R2)', 'Unexplained Variance'], \n",
    "            colors=['lightblue', 'lightgrey'], autopct='%1.1f%%')\n",
    "else:\n",
    "    plt.pie([100], labels=['Unexplained Variance'], colors=['lightgrey'], autopct='%1.1f%%')\n",
    "\n",
    "plt.title('Validation Set Explained Variance by R-squared (R2)')\n",
    "\n",
    "output_path = f\"plots/03_Error_Metric_Plots/{file_name}_external_R2.png\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ba566d-6b67-480f-a4bb-e394d8c01fce",
   "metadata": {},
   "source": [
    "# Calibration Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeba03a-8721-4a77-a1d2-557ac782c024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create calibration plot\n",
    "def plot_calibration(y_true, y_pred, title, filename):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.regplot(x=y_true, y=y_pred, lowess=True, line_kws={'color': 'red'}, scatter_kws={'alpha': 0.4})\n",
    "    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], 'k--', lw=2)\n",
    "    plt.xlabel('Actual LOS')\n",
    "    plt.ylabel('Predicted LOS')\n",
    "    plt.title(f'Calibration Plot: {title}')\n",
    "    plt.grid(True)\n",
    "\n",
    "    output_path = f\"plots/04_Calibration_Plots/{filename}.png\"\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Plot for test set\n",
    "plot_calibration(y_test, y_pred, \"Internal Test Set\", f\"{file_name}_calibration_internal\")\n",
    "\n",
    "# Plot for external set\n",
    "plot_calibration(y_external, y_pred_external, \"External Validation Set\", f\"{file_name}_calibration_external\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e5ee89-6e54-49fa-8e9b-40c5629f7ee6",
   "metadata": {},
   "source": [
    "# Most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f15d96-8eab-4129-9b21-4932c1701469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "most_important_df = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store feature importances along with their corresponding names\n",
    "most_important_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': most_important_df})\n",
    "\n",
    "# Sort the DataFrame by feature importance in descending order\n",
    "most_important_df = most_important_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Scale the importance\n",
    "most_important_df['Importance'] *= 100000\n",
    "\n",
    "# Print the top N most important features\n",
    "top_n = 20  # set features number\n",
    "print(f\"Top {top_n} most important features:\")\n",
    "print(most_important_df.head(top_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbf81e5-689e-4426-80ac-52c1c4ce470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_features = most_important_df.head(20).copy()  # Create a copy explicitly\n",
    "top_20_features['Feature'] = top_20_features['Feature'].apply(lambda x: '\\n'.join(textwrap.wrap(x, width=20)))\n",
    "\n",
    "# Set seaborn style and remove gridlines\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Top 20 most important features (create a copy)\n",
    "top_20_features = most_important_df.head(20).copy()\n",
    "\n",
    "# Wrap long feature names\n",
    "top_20_features['Feature'] = top_20_features['Feature'].apply(lambda x: '\\n'.join(textwrap.wrap(x, width=20)))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(18, 11))  # Increase figure size for better visibility\n",
    "plot = sns.barplot(x='Importance', y='Feature', data=top_20_features, hue='Feature', palette=\"Blues\", legend=False)\n",
    "\n",
    "# Set font size for labels and title\n",
    "plt.xlabel('Importance', fontsize=16)\n",
    "plt.ylabel('Feature', fontsize=16)\n",
    "plt.title('Top 20 Features with Highest Importance', fontsize=20)\n",
    "\n",
    "# Save the plot in high resolution\n",
    "output_path = f\"plots/01_Most_Important_SHAP/{file_name}_most_important_features.png\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f11674-d136-4426-926e-b759f5035a26",
   "metadata": {},
   "source": [
    "# Shap plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e76068-a999-43e9-a02f-7b565c2b6a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain the model's predictions using SHAP values\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# Mean absolute SHAP values to rank feature importance\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Mean Absolute SHAP Value': mean_abs_shap\n",
    "}).sort_values(by='Mean Absolute SHAP Value', ascending=False)\n",
    "\n",
    "# Display the top N most important features\n",
    "top_n = 20\n",
    "print(f\"Top {top_n} features by SHAP importance:\")\n",
    "print(feature_importance_df.head(top_n))\n",
    "\n",
    "# Create a Matplotlib figure\n",
    "plt.figure()\n",
    "\n",
    "# SHAP Summary Plot with Bee Swarm (distribution of feature impacts)\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"dot\", show=False)\n",
    "\n",
    "# Add grid to the plot\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the plot as a PNG image\n",
    "output_path = f\"plots/01_Most_Important_SHAP/{file_name}_shap_plot.png\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a20b9d-5a4b-45e5-b4e3-a828f0bbee44",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Create Shap by saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d72135-8af6-497a-8eed-594ef923aaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the XGBoost model from the JSON file\n",
    "model = xgb.Booster()  # Initialize the Booster object\n",
    "model.load_model(\"models\\\\02_Mean_Impute\\\\o11_Mean_Scale_Norm_Bayes_.json\")\n",
    "\n",
    "# I must load training - test set\n",
    "\n",
    "# Create a SHAP explainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# Generate SHAP summary plot\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"dot\", show=False)\n",
    "\n",
    "# Add grid to the plot\n",
    "plt.grid(True)\n",
    "\n",
    "# If i want to save the plot I must change in line 14 the show=True to False\n",
    "# plt.savefig(\"shap_summary_plot.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f616729d-6efe-452c-b36b-28b1d20bc257",
   "metadata": {},
   "source": [
    "# Plotting True vs. Predicted LOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d0bd3b-6125-44e6-a46d-a0f6c2acd1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, color='blue', label='Prediction')\n",
    "\n",
    "# Line for Perfect Prediction\n",
    "perfect_line = np.linspace(y_test.min(), y_test.max(), 100)\n",
    "plt.plot(perfect_line, perfect_line, color='red', linestyle='--', label='Perfect Prediction')\n",
    "\n",
    "# Labels, legend, and grid\n",
    "plt.xlabel('True LOS')\n",
    "plt.ylabel('Predicted LOS')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Predicted vs. True LOS (Test Set)')\n",
    "\n",
    "# Save the plot as a PNG image\n",
    "output_path = f\"plots/02_Prediction_Plot/02_true_vs_pred/{file_name}_true_vs_pred_test_plot.png\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# External Validation Set Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_external, y_pred_external, color='blue', label='Prediction')\n",
    "\n",
    "# Line for Perfect Prediction (y = x)\n",
    "perfect_line_ext = np.linspace(y_external.min(), y_external.max(), 100)\n",
    "plt.plot(perfect_line_ext, perfect_line_ext, color='red', linestyle='--', label='Perfect Prediction')\n",
    "\n",
    "# Labels, legend, and grid\n",
    "plt.xlabel('True LOS')\n",
    "plt.ylabel('Predicted LOS')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Predicted vs. True LOS (External Validation Set)')\n",
    "\n",
    "# Save the plot as a PNG image\n",
    "output_path = f\"plots/02_Prediction_Plot/02_true_vs_pred/{file_name}_true_vs_pred_external_plot.png\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8f9ec6-43a2-41b0-9a37-317c4db7bb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_test to a 1D numpy array\n",
    "y_test = y_test.values.flatten()\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# Plot residuals\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, residuals, color='blue', alpha=0.5, label=\"Residuals\")\n",
    "plt.axhline(y=0, color='red', linestyle='--', label=\"Zero Line\")\n",
    "plt.axhline(y=mae, color='green', linestyle='--', label=f\"MAE = {mae:.2f}\")\n",
    "plt.axhline(y=-mae, color='green', linestyle='--')\n",
    "plt.xlabel('True LOS')\n",
    "plt.ylabel('Residuals (True - Predicted)')\n",
    "plt.title('Residuals Plot with MAE Bounds')\n",
    "plt.grid(True)\n",
    "\n",
    "# Place the legend outside of the plot\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Save the plot as a PNG image\n",
    "output_path = f\"plots/02_Prediction_Plot/01_residuals/{file_name}_residuals_plot.png\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab45ed80-6c84-47ba-b7ed-34631763e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"y_pred shape:\", y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade636b8-35d8-4726-8587-7776029df178",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ba9b93-f41d-40cb-9e02-d7caaf2e647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_test to a 1D numpy array\n",
    "y_test = y_test.values.flatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
