{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "964f3ae7-16f9-47b1-9c1a-37be5087b131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92f034e9-9230-4ddc-a638-695f37d6b100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compressed file paths\n",
    "eicu_file_path = r\"../04_ANN/CSV/exports/whole_set/o3_hour_overlap_window_eicu.csv\"\n",
    "mimic_file_path = r\"../04_ANN/CSV/exports/whole_set/o3_hour_overlap_window_mimic.csv\"\n",
    "\n",
    "file_sofa_path= r\"CSV/Imports/sofa.csv\"\n",
    "file_first_day_sofa_path= r\"CSV/Imports/first_day_sofa.csv\"\n",
    "first_stay_path= r\"CSV/Imports/o03_icu_first_stay.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3490dbd8-7947-428e-ba5b-552a54e7ecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOFA data\n",
    "stroke_sofa = pd.read_csv(file_sofa_path)\n",
    "stroke_first_day_sofa = pd.read_csv(file_first_day_sofa_path)\n",
    "stroke_first_stay = pd.read_csv(first_stay_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f790e0ba-b9be-4634-82f9-bc46192992ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "eicu_df = pd.read_csv(eicu_file_path)\n",
    "mimic_df = pd.read_csv(mimic_file_path)\n",
    "\n",
    "mimic_df = mimic_df[mimic_df[\"los\"] <= 10].copy()\n",
    "eicu_df = eicu_df[eicu_df[\"los\"] <= 10].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cc1fe8-09cd-4f6f-a213-f9dbfa6b08ae",
   "metadata": {},
   "source": [
    "# Keep doctors features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d28bc714-e7bd-429d-942f-93414ea51f99",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[mimic_df] kept 205/205 columns | missing: 0\n",
      "\n",
      "[eicu_df] kept 205/205 columns | missing: 0\n",
      "\n",
      "Shapes:\n",
      "mimic_df_small: (51040, 205)\n",
      "eicu_df_small : (78256, 205)\n",
      "\n",
      "Targets check:\n",
      "mimic: has hospital_expire_flag? True | has los? True\n",
      "eicu: has hospital_expire_flag? True | has los? True\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 1) Columns to keep (as provided)\n",
    "# ----------------------------\n",
    "wanted_cols_text = \"\"\"\n",
    "row_count\n",
    "subject_id\n",
    "hadm_id\n",
    "Time_Zone\n",
    "gender\n",
    "age\n",
    "race\n",
    "Alanine_Aminotransferase_(ALT)_(Max)\n",
    "Alanine_Aminotransferase_(ALT)_(Mean)\n",
    "Alanine_Aminotransferase_(ALT)_(Median)\n",
    "Alanine_Aminotransferase_(ALT)_(Min)\n",
    "Albumin_(Max)\n",
    "Albumin_(Mean)\n",
    "Albumin_(Median)\n",
    "Albumin_(Min)\n",
    "Ammonia_(Max)\n",
    "Ammonia_(Mean)\n",
    "Ammonia_(Median)\n",
    "Ammonia_(Min)\n",
    "Anion_Gap_(Max)\n",
    "Anion_Gap_(Mean)\n",
    "Anion_Gap_(Median)\n",
    "Anion_Gap_(Min)\n",
    "Arterial_Blood_Pressure_diastolic_(mmHg)_(Max)\n",
    "Arterial_Blood_Pressure_diastolic_(mmHg)_(Mean)\n",
    "Arterial_Blood_Pressure_diastolic_(mmHg)_(Median)\n",
    "Arterial_Blood_Pressure_diastolic_(mmHg)_(Min)\n",
    "Arterial_Blood_Pressure_mean_(mmHg)_(Max)\n",
    "Arterial_Blood_Pressure_mean_(mmHg)_(Mean)\n",
    "Arterial_Blood_Pressure_mean_(mmHg)_(Median)\n",
    "Arterial_Blood_Pressure_mean_(mmHg)_(Min)\n",
    "Arterial_Blood_Pressure_systolic_(mmHg)_(Max)\n",
    "Arterial_Blood_Pressure_systolic_(mmHg)_(Mean)\n",
    "Arterial_Blood_Pressure_systolic_(mmHg)_(Median)\n",
    "Arterial_Blood_Pressure_systolic_(mmHg)_(Min)\n",
    "Asparate_Aminotransferase_(AST)_(Max)\n",
    "Asparate_Aminotransferase_(AST)_(Mean)\n",
    "Asparate_Aminotransferase_(AST)_(Median)\n",
    "Asparate_Aminotransferase_(AST)_(Min)\n",
    "Base_Excess_(Max)\n",
    "Base_Excess_(Mean)\n",
    "Base_Excess_(Median)\n",
    "Base_Excess_(Min)\n",
    "Bicarbonate_(Max)\n",
    "Bicarbonate_(Mean)\n",
    "Bicarbonate_(Median)\n",
    "Bicarbonate_(Min)\n",
    "BUN_(Max)\n",
    "BUN_(Mean)\n",
    "BUN_(Median)\n",
    "BUN_(Min)\n",
    "C_Reactive_Protein_(CRP)_(Max)\n",
    "C_Reactive_Protein_(CRP)_(Mean)\n",
    "C_Reactive_Protein_(CRP)_(Min)\n",
    "C_Reactive_Protein_(CRP)_(Median)\n",
    "Central_Venous_Pressure_(mmHg)_(Max)\n",
    "Central_Venous_Pressure_(mmHg)_(Mean)\n",
    "Central_Venous_Pressure_(mmHg)_(Median)\n",
    "Central_Venous_Pressure_(mmHg)_(Min)\n",
    "Chloride_(Max)\n",
    "Chloride_(Mean)\n",
    "Chloride_(Median)\n",
    "Chloride_(Min)\n",
    "Chloride_(serum)_(Max)\n",
    "Chloride_(serum)_(Mean)\n",
    "Chloride_(serum)_(Median)\n",
    "Chloride_(serum)_(Min)\n",
    "CK_(CPK)_(Max)\n",
    "CK_(CPK)_(Mean)\n",
    "CK_(CPK)_(Median)\n",
    "CK_(CPK)_(Min)\n",
    "CK-MB_(Max)\n",
    "CK-MB_(Mean)\n",
    "CK-MB_(Median)\n",
    "CK-MB_(Min)\n",
    "Creatinine_(Max)\n",
    "Creatinine_(Mean)\n",
    "Creatinine_(Median)\n",
    "Creatinine_(Min)\n",
    "Differential-Lymphs_(Max)\n",
    "Differential-Lymphs_(Mean)\n",
    "Differential-Lymphs_(Median)\n",
    "Differential-Lymphs_(Min)\n",
    "Differential-Neuts_(Max)\n",
    "Differential-Neuts_(Mean)\n",
    "Differential-Neuts_(Median)\n",
    "Differential-Neuts_(Min)\n",
    "Fibrinogen_(Max)\n",
    "Fibrinogen_(Mean)\n",
    "Fibrinogen_(Median)\n",
    "Fibrinogen_(Min)\n",
    "GCS_(Max)\n",
    "GCS_(Mean)\n",
    "GCS_(Median)\n",
    "GCS_(Min)\n",
    "Glucose_finger_stick_(range_70-100)_(Max)\n",
    "Glucose_finger_stick_(range_70-100)_(Mean)\n",
    "Glucose_finger_stick_(range_70-100)_(Median)\n",
    "Glucose_finger_stick_(range_70-100)_(Min)\n",
    "Heart_Rate_(bpm)_(Max)\n",
    "Heart_Rate_(bpm)_(Mean)\n",
    "Heart_Rate_(bpm)_(Median)\n",
    "Heart_Rate_(bpm)_(Min)\n",
    "Hemoglobin_(Max)\n",
    "Hemoglobin_(Mean)\n",
    "Hemoglobin_(Median)\n",
    "Hemoglobin_(Min)\n",
    "INR(PT)_(Max)\n",
    "INR(PT)_(Mean)\n",
    "INR(PT)_(Median)\n",
    "INR(PT)_(Min)\n",
    "Inspired_O2_Fraction_(Max)\n",
    "Inspired_O2_Fraction_(Mean)\n",
    "Inspired_O2_Fraction_(Median)\n",
    "Inspired_O2_Fraction_(Min)\n",
    "Lactate_(Max)\n",
    "Lactate_(Mean)\n",
    "Lactate_(Median)\n",
    "Lactate_(Min)\n",
    "LDH_(Max)\n",
    "LDH_(Mean)\n",
    "LDH_(Median)\n",
    "LDH_(Min)\n",
    "MCH_(Max)\n",
    "MCH_(Mean)\n",
    "MCH_(Median)\n",
    "MCH_(Min)\n",
    "MCHC_(Max)\n",
    "MCHC_(Mean)\n",
    "MCHC_(Median)\n",
    "MCHC_(Min)\n",
    "MCV_(Max)\n",
    "MCV_(Mean)\n",
    "MCV_(Median)\n",
    "MCV_(Min)\n",
    "Non_Invasive_Blood_Pressure_diastolic_(mmHg)_(Max)\n",
    "Non_Invasive_Blood_Pressure_diastolic_(mmHg)_(Mean)\n",
    "Non_Invasive_Blood_Pressure_diastolic_(mmHg)_(Median)\n",
    "Non_Invasive_Blood_Pressure_diastolic_(mmHg)_(Min)\n",
    "Non_Invasive_Blood_Pressure_mean_(mmHg)_(Max)\n",
    "Non_Invasive_Blood_Pressure_mean_(mmHg)_(Mean)\n",
    "Non_Invasive_Blood_Pressure_mean_(mmHg)_(Median)\n",
    "Non_Invasive_Blood_Pressure_mean_(mmHg)_(Min)\n",
    "Non_Invasive_Blood_Pressure_systolic_(mmHg)_(Max)\n",
    "Non_Invasive_Blood_Pressure_systolic_(mmHg)_(Mean)\n",
    "Non_Invasive_Blood_Pressure_systolic_(mmHg)_(Median)\n",
    "Non_Invasive_Blood_Pressure_systolic_(mmHg)_(Min)\n",
    "O2_saturation_pulseoxymetry_(%)_(Max)\n",
    "O2_saturation_pulseoxymetry_(%)_(Mean)\n",
    "O2_saturation_pulseoxymetry_(%)_(Median)\n",
    "O2_saturation_pulseoxymetry_(%)_(Min)\n",
    "Platelet_Count_(Max)\n",
    "Platelet_Count_(Mean)\n",
    "Platelet_Count_(Median)\n",
    "Platelet_Count_(Min)\n",
    "pO2_(Max)\n",
    "pO2_(Mean)\n",
    "pO2_(Median)\n",
    "pO2_(Min)\n",
    "Potassium_(Max)\n",
    "Potassium_(Mean)\n",
    "Potassium_(Median)\n",
    "Potassium_(Min)\n",
    "PT_(Max)\n",
    "PT_(Mean)\n",
    "PT_(Median)\n",
    "PT_(Min)\n",
    "PTT_(Max)\n",
    "PTT_(Mean)\n",
    "PTT_(Median)\n",
    "PTT_(Min)\n",
    "RDW_(Max)\n",
    "RDW_(Mean)\n",
    "RDW_(Median)\n",
    "RDW_(Min)\n",
    "Respiratory_Rate_(insp/min)_(Max)\n",
    "Respiratory_Rate_(insp/min)_(Mean)\n",
    "Respiratory_Rate_(insp/min)_(Median)\n",
    "Respiratory_Rate_(insp/min)_(Min)\n",
    "Sodium_(Max)\n",
    "Sodium_(Mean)\n",
    "Sodium_(Median)\n",
    "Sodium_(Min)\n",
    "Temperature_Fahrenheit_(F)_(Max)\n",
    "Temperature_Fahrenheit_(F)_(Mean)\n",
    "Temperature_Fahrenheit_(F)_(Median)\n",
    "Temperature_Fahrenheit_(F)_(Min)\n",
    "Total_Bilirubin_(Max)\n",
    "Total_Bilirubin_(Mean)\n",
    "Total_Bilirubin_(Median)\n",
    "Total_Bilirubin_(Min)\n",
    "Troponin-T_(Max)\n",
    "Troponin-T_(Mean)\n",
    "Troponin-T_(Median)\n",
    "Troponin-T_(Min)\n",
    "White_Blood_Cells_(Max)\n",
    "White_Blood_Cells_(Mean)\n",
    "White_Blood_Cells_(Median)\n",
    "White_Blood_Cells_(Min)\n",
    "Glucose_(Max)\n",
    "Glucose_(Mean)\n",
    "Glucose_(Median)\n",
    "Glucose_(Min)\n",
    "hospital_expire_flag\n",
    "los\n",
    "\"\"\".strip()\n",
    "\n",
    "WANTED_COLS = [c.strip() for c in wanted_cols_text.splitlines() if c.strip()]\n",
    "\n",
    "# Quick duplicate check (just in case)\n",
    "dup = [c for c, k in Counter(WANTED_COLS).items() if k > 1]\n",
    "if dup:\n",
    "    print(\"Duplicate names in WANTED_COLS:\", dup)\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Optional aliases (common naming differences)\n",
    "# ----------------------------\n",
    "ALIASES = {\n",
    "    \"los\": [\"LOS\", \"icu_los\", \"unit_los\"],\n",
    "    \"hospital_expire_flag\": [\"hospital_expired_flag\", \"hospital_expired\", \"mortality\", \"unitdischargestatus\"],\n",
    "    \"Time_Zone\": [\"time_zone\", \"TimeZone\", \"timeZone\"],\n",
    "    \"race\": [\"ethnicity\"],\n",
    "}\n",
    "\n",
    "def subset_keep_columns(df, wanted_cols, df_name=\"df\", aliases=None):\n",
    "    aliases = aliases or {}\n",
    "    resolved = []\n",
    "    missing = []\n",
    "\n",
    "    df_cols = set(df.columns)\n",
    "\n",
    "    for col in wanted_cols:\n",
    "        if col in df_cols:\n",
    "            resolved.append(col)\n",
    "            continue\n",
    "\n",
    "        # try aliases\n",
    "        found = None\n",
    "        for alt in aliases.get(col, []):\n",
    "            if alt in df_cols:\n",
    "                found = alt\n",
    "                break\n",
    "\n",
    "        if found is not None:\n",
    "            resolved.append(found)\n",
    "        else:\n",
    "            missing.append(col)\n",
    "\n",
    "    out = df[resolved].copy()\n",
    "\n",
    "    print(f\"\\n[{df_name}] kept {out.shape[1]}/{len(wanted_cols)} columns | missing: {len(missing)}\")\n",
    "    if missing:\n",
    "        # show a manageable preview\n",
    "        preview = missing[:30]\n",
    "        print(\"Missing (first 30):\", preview)\n",
    "        if len(missing) > 30:\n",
    "            print(f\"... plus {len(missing)-30} more\")\n",
    "\n",
    "    return out, missing, resolved\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Apply to your dataframes\n",
    "# ----------------------------\n",
    "mimic_df_small, mimic_missing, mimic_resolved = subset_keep_columns(\n",
    "    mimic_df, WANTED_COLS, df_name=\"mimic_df\", aliases=ALIASES\n",
    ")\n",
    "\n",
    "eicu_df_small, eicu_missing, eicu_resolved = subset_keep_columns(\n",
    "    eicu_df, WANTED_COLS, df_name=\"eicu_df\", aliases=ALIASES\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Sanity checks\n",
    "# ----------------------------\n",
    "print(\"\\nShapes:\")\n",
    "print(\"mimic_df_small:\", mimic_df_small.shape)\n",
    "print(\"eicu_df_small :\", eicu_df_small.shape)\n",
    "\n",
    "print(\"\\nTargets check:\")\n",
    "for name, d in [(\"mimic\", mimic_df_small), (\"eicu\", eicu_df_small)]:\n",
    "    cols = d.columns\n",
    "    print(f\"{name}: has hospital_expire_flag? {'hospital_expire_flag' in cols} | has los? {'los' in cols or 'LOS' in cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c74a295e-d7be-4afc-a81a-44127f6536e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_count</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>Time_Zone</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>Alanine_Aminotransferase_(ALT)_(Max)</th>\n",
       "      <th>Alanine_Aminotransferase_(ALT)_(Mean)</th>\n",
       "      <th>Alanine_Aminotransferase_(ALT)_(Median)</th>\n",
       "      <th>...</th>\n",
       "      <th>White_Blood_Cells_(Max)</th>\n",
       "      <th>White_Blood_Cells_(Mean)</th>\n",
       "      <th>White_Blood_Cells_(Median)</th>\n",
       "      <th>White_Blood_Cells_(Min)</th>\n",
       "      <th>Glucose_(Max)</th>\n",
       "      <th>Glucose_(Mean)</th>\n",
       "      <th>Glucose_(Median)</th>\n",
       "      <th>Glucose_(Min)</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "      <th>los</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.357373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.357373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.357373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>94.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.357373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>94.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.357373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58139</th>\n",
       "      <td>58140</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>12</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.9</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.937847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58140</th>\n",
       "      <td>58141</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>13</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.9</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.937847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58141</th>\n",
       "      <td>58142</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>14</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.9</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.937847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58142</th>\n",
       "      <td>58143</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>15</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.9</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.937847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58143</th>\n",
       "      <td>58144</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.9</td>\n",
       "      <td>12.9</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.937847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51040 rows × 205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_count  subject_id   hadm_id  Time_Zone gender  age     race  \\\n",
       "0              1    10004733  27411876          1      M   51  UNKNOWN   \n",
       "1              2    10004733  27411876          2      M   51  UNKNOWN   \n",
       "2              3    10004733  27411876          3      M   51  UNKNOWN   \n",
       "3              4    10004733  27411876          4      M   51  UNKNOWN   \n",
       "4              5    10004733  27411876          5      M   51  UNKNOWN   \n",
       "...          ...         ...       ...        ...    ...  ...      ...   \n",
       "58139      58140    19999987  23865745         12      F   57  UNKNOWN   \n",
       "58140      58141    19999987  23865745         13      F   57  UNKNOWN   \n",
       "58141      58142    19999987  23865745         14      F   57  UNKNOWN   \n",
       "58142      58143    19999987  23865745         15      F   57  UNKNOWN   \n",
       "58143      58144    19999987  23865745         16      F   57  UNKNOWN   \n",
       "\n",
       "       Alanine_Aminotransferase_(ALT)_(Max)  \\\n",
       "0                                      46.0   \n",
       "1                                      46.0   \n",
       "2                                      46.0   \n",
       "3                                      46.0   \n",
       "4                                      46.0   \n",
       "...                                     ...   \n",
       "58139                                  63.0   \n",
       "58140                                  63.0   \n",
       "58141                                  63.0   \n",
       "58142                                  63.0   \n",
       "58143                                  63.0   \n",
       "\n",
       "       Alanine_Aminotransferase_(ALT)_(Mean)  \\\n",
       "0                                       46.0   \n",
       "1                                       46.0   \n",
       "2                                       46.0   \n",
       "3                                       46.0   \n",
       "4                                       46.0   \n",
       "...                                      ...   \n",
       "58139                                   63.0   \n",
       "58140                                   63.0   \n",
       "58141                                   63.0   \n",
       "58142                                   63.0   \n",
       "58143                                   63.0   \n",
       "\n",
       "       Alanine_Aminotransferase_(ALT)_(Median)  ...  White_Blood_Cells_(Max)  \\\n",
       "0                                         46.0  ...                      7.4   \n",
       "1                                         46.0  ...                      7.4   \n",
       "2                                         46.0  ...                      7.4   \n",
       "3                                         46.0  ...                      7.4   \n",
       "4                                         46.0  ...                      7.4   \n",
       "...                                        ...  ...                      ...   \n",
       "58139                                     63.0  ...                     12.9   \n",
       "58140                                     63.0  ...                     12.9   \n",
       "58141                                     63.0  ...                     12.9   \n",
       "58142                                     63.0  ...                     12.9   \n",
       "58143                                     63.0  ...                     12.9   \n",
       "\n",
       "       White_Blood_Cells_(Mean)  White_Blood_Cells_(Median)  \\\n",
       "0                           7.4                         7.4   \n",
       "1                           7.4                         7.4   \n",
       "2                           7.4                         7.4   \n",
       "3                           7.4                         7.4   \n",
       "4                           7.4                         7.4   \n",
       "...                         ...                         ...   \n",
       "58139                      12.9                        12.9   \n",
       "58140                      12.9                        12.9   \n",
       "58141                      12.9                        12.9   \n",
       "58142                      12.9                        12.9   \n",
       "58143                      12.9                        12.9   \n",
       "\n",
       "       White_Blood_Cells_(Min)  Glucose_(Max)  Glucose_(Mean)  \\\n",
       "0                          7.4           86.0            86.0   \n",
       "1                          7.4           86.0            86.0   \n",
       "2                          7.4           86.0            86.0   \n",
       "3                          7.4           94.0            90.0   \n",
       "4                          7.4           94.0            90.0   \n",
       "...                        ...            ...             ...   \n",
       "58139                     12.9          113.0           113.0   \n",
       "58140                     12.9          113.0           113.0   \n",
       "58141                     12.9          113.0           113.0   \n",
       "58142                     12.9          113.0           113.0   \n",
       "58143                     12.9          113.0           113.0   \n",
       "\n",
       "       Glucose_(Median)  Glucose_(Min)  hospital_expire_flag       los  \n",
       "0                  86.0           86.0                     0  8.357373  \n",
       "1                  86.0           86.0                     0  8.357373  \n",
       "2                  86.0           86.0                     0  8.357373  \n",
       "3                  90.0           86.0                     0  8.357373  \n",
       "4                  90.0           86.0                     0  8.357373  \n",
       "...                 ...            ...                   ...       ...  \n",
       "58139             113.0          113.0                     0  1.937847  \n",
       "58140             113.0          113.0                     0  1.937847  \n",
       "58141             113.0          113.0                     0  1.937847  \n",
       "58142             113.0          113.0                     0  1.937847  \n",
       "58143             113.0          113.0                     0  1.937847  \n",
       "\n",
       "[51040 rows x 205 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mimic_df_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb2f27c-9f42-4493-891f-1a0ac5321d16",
   "metadata": {},
   "source": [
    "# NLR, ANC & PLR Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb70dd2c-7d7f-4589-b981-a7b62d5b8a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>50%</th>\n",
       "      <th>90%</th>\n",
       "      <th>95%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Differential-Lymphs_(Median)</th>\n",
       "      <td>13648.0</td>\n",
       "      <td>14.277345</td>\n",
       "      <td>11.799012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>26.4</td>\n",
       "      <td>34.8</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Differential-Neuts_(Median)</th>\n",
       "      <td>13648.0</td>\n",
       "      <td>78.272018</td>\n",
       "      <td>14.111460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.9</td>\n",
       "      <td>90.4</td>\n",
       "      <td>92.3</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                count       mean        std  min   50%   90%  \\\n",
       "Differential-Lymphs_(Median)  13648.0  14.277345  11.799012  0.0  11.4  26.4   \n",
       "Differential-Neuts_(Median)   13648.0  78.272018  14.111460  0.0  81.9  90.4   \n",
       "\n",
       "                               95%    max  \n",
       "Differential-Lymphs_(Median)  34.8  100.0  \n",
       "Differential-Neuts_(Median)   92.3  100.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>50%</th>\n",
       "      <th>90%</th>\n",
       "      <th>95%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Differential-Lymphs_(Median)</th>\n",
       "      <td>47008.0</td>\n",
       "      <td>17.059932</td>\n",
       "      <td>10.707496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Differential-Neuts_(Median)</th>\n",
       "      <td>41136.0</td>\n",
       "      <td>72.690297</td>\n",
       "      <td>12.908184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>87.5</td>\n",
       "      <td>90.0</td>\n",
       "      <td>98.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                count       mean        std  min   50%   90%  \\\n",
       "Differential-Lymphs_(Median)  47008.0  17.059932  10.707496  0.0  15.0  31.0   \n",
       "Differential-Neuts_(Median)   41136.0  72.690297  12.908184  0.0  74.5  87.5   \n",
       "\n",
       "                               95%     max  \n",
       "Differential-Lymphs_(Median)  35.5  100.00  \n",
       "Differential-Neuts_(Median)   90.0   98.25  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols_check = [\n",
    "    \"Differential-Lymphs_(Median)\",\n",
    "    \"Differential-Neuts_(Median)\"\n",
    "]\n",
    "display(mimic_df_small[cols_check].describe(percentiles=[.5,.9,.95]).T)\n",
    "display(eicu_df_small[cols_check].describe(percentiles=[.5,.9,.95]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51f7b712-404a-4530-8d80-49d400dc65e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted to /μL (x1000): ['White_Blood_Cells_(Max)', 'Platelet_Count_(Max)', 'White_Blood_Cells_(Mean)', 'Platelet_Count_(Mean)', 'White_Blood_Cells_(Median)', 'Platelet_Count_(Median)', 'White_Blood_Cells_(Min)', 'Platelet_Count_(Min)']\n",
      "Converted to /μL (x1000): ['White_Blood_Cells_(Max)', 'Platelet_Count_(Max)', 'White_Blood_Cells_(Mean)', 'Platelet_Count_(Mean)', 'White_Blood_Cells_(Median)', 'Platelet_Count_(Median)', 'White_Blood_Cells_(Min)', 'Platelet_Count_(Min)']\n",
      "Dropped: ['Differential-Lymphs_(Max)', 'Differential-Neuts_(Max)', 'Differential-Lymphs_(Mean)', 'Differential-Neuts_(Mean)', 'Differential-Lymphs_(Median)', 'Differential-Neuts_(Median)', 'Differential-Lymphs_(Min)', 'Differential-Neuts_(Min)']\n",
      "Dropped: ['Differential-Lymphs_(Max)', 'Differential-Neuts_(Max)', 'Differential-Lymphs_(Mean)', 'Differential-Neuts_(Mean)', 'Differential-Lymphs_(Median)', 'Differential-Neuts_(Median)', 'Differential-Lymphs_(Min)', 'Differential-Neuts_(Min)']\n"
     ]
    }
   ],
   "source": [
    "def convert_wbc_and_platelets_to_per_uL(df: pd.DataFrame, verbose: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert WBC and Platelet counts from (x10^3/μL) to (/μL) by multiplying by 1000.\n",
    "    This makes values align with clinician intuition (e.g., WBC 10 -> 10,000 /μL).\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "    aggs = [\"Max\", \"Mean\", \"Median\", \"Min\"]\n",
    "    bases = [\"White_Blood_Cells\", \"Platelet_Count\"]\n",
    "\n",
    "    converted = []\n",
    "    for agg in aggs:\n",
    "        for base in bases:\n",
    "            col = f\"{base}_({agg})\"\n",
    "            if col in out.columns:\n",
    "                out[col] = pd.to_numeric(out[col], errors=\"coerce\") * 1000.0\n",
    "                converted.append(col)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Converted to /μL (x1000):\", converted)\n",
    "    return out\n",
    "\n",
    "\n",
    "def add_anc_nlr_plr_then_drop_differentials(df: pd.DataFrame, verbose: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Assumes after conversion:\n",
    "      - WBC is now in /μL\n",
    "      - Platelet_Count is now in /μL\n",
    "      - Differential-* are still percentages (0–100)\n",
    "\n",
    "    For each agg in {Max, Mean, Median, Min}:\n",
    "      - ANC_(agg) = WBC_(agg) * (Neuts%_(agg)/100)         -> /μL\n",
    "      - ALC_(agg) = WBC_(agg) * (Lymphs%_(agg)/100)        -> /μL (internal)\n",
    "      - NLR_(agg) = ANC_(agg) / ALC_(agg)                  -> unitless\n",
    "      - PLR_(agg) = Platelet_Count_(agg) / ALC_(agg)       -> unitless\n",
    "\n",
    "    Finally drops Differential-Lymphs_* and Differential-Neuts_* columns.\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "    aggs = [\"Max\", \"Mean\", \"Median\", \"Min\"]\n",
    "\n",
    "    for agg in aggs:\n",
    "        wbc_col   = f\"White_Blood_Cells_({agg})\"\n",
    "        neut_col  = f\"Differential-Neuts_({agg})\"\n",
    "        lymph_col = f\"Differential-Lymphs_({agg})\"\n",
    "        plt_col   = f\"Platelet_Count_({agg})\"\n",
    "\n",
    "        anc_out = f\"ANC_({agg})\"\n",
    "        nlr_out = f\"NLR_({agg})\"\n",
    "        plr_out = f\"PLR_({agg})\"\n",
    "\n",
    "        if wbc_col not in out.columns or lymph_col not in out.columns:\n",
    "            if verbose:\n",
    "                miss = [c for c in (wbc_col, lymph_col) if c not in out.columns]\n",
    "                print(f\"[skip {agg}] missing for ALC: {miss}\")\n",
    "            continue\n",
    "\n",
    "        wbc    = pd.to_numeric(out[wbc_col], errors=\"coerce\")      # /μL\n",
    "        lymphp = pd.to_numeric(out[lymph_col], errors=\"coerce\")    # %\n",
    "        alc = wbc * (lymphp / 100.0)                               # /μL\n",
    "\n",
    "        # ---------- ANC ----------\n",
    "        if neut_col in out.columns:\n",
    "            neutp = pd.to_numeric(out[neut_col], errors=\"coerce\")  # %\n",
    "            anc = wbc * (neutp / 100.0)                             # /μL\n",
    "            out[anc_out] = anc\n",
    "        else:\n",
    "            anc = pd.Series(np.nan, index=out.index)\n",
    "            if verbose:\n",
    "                print(f\"[{agg}] missing {neut_col} -> ANC/NLR not created\")\n",
    "\n",
    "        # ---------- NLR ----------\n",
    "        if neut_col in out.columns:\n",
    "            out[nlr_out] = anc / alc.replace(0, np.nan)\n",
    "\n",
    "        # ---------- PLR ----------\n",
    "        if plt_col in out.columns:\n",
    "            platelets = pd.to_numeric(out[plt_col], errors=\"coerce\")  # /μL\n",
    "            out[plr_out] = platelets / alc.replace(0, np.nan)\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"[{agg}] missing {plt_col} -> PLR not created\")\n",
    "\n",
    "    # Drop differential percentage columns AFTER computing ratios/counts\n",
    "    drop_cols = []\n",
    "    for agg in aggs:\n",
    "        for base in [\"Differential-Lymphs\", \"Differential-Neuts\"]:\n",
    "            c = f\"{base}_({agg})\"\n",
    "            if c in out.columns:\n",
    "                drop_cols.append(c)\n",
    "\n",
    "    out = out.drop(columns=drop_cols)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Dropped:\", drop_cols)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# USAGE (2 steps)\n",
    "# -------------------------\n",
    "mimic_df_small = convert_wbc_and_platelets_to_per_uL(mimic_df_small, verbose=True)\n",
    "eicu_df_small  = convert_wbc_and_platelets_to_per_uL(eicu_df_small,  verbose=True)\n",
    "\n",
    "mimic_df_small = add_anc_nlr_plr_then_drop_differentials(mimic_df_small, verbose=True)\n",
    "eicu_df_small  = add_anc_nlr_plr_then_drop_differentials(eicu_df_small,  verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a1ee3d-1f45-4c2f-971c-ae54f4db74af",
   "metadata": {},
   "source": [
    "# Calculate RAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "747a9f20-8c1a-4055-8fc4-20aec1ce75a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rar_columns_only(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for suf in [\"Max\", \"Min\", \"Mean\", \"Median\"]:\n",
    "        rdw_col = f\"RDW_({suf})\"\n",
    "        alb_col = f\"Albumin_({suf})\"\n",
    "        rar_col = f\"RAR_({suf})\"\n",
    "\n",
    "        rdw = pd.to_numeric(df[rdw_col], errors=\"coerce\")\n",
    "        alb = pd.to_numeric(df[alb_col], errors=\"coerce\").replace(0, np.nan)\n",
    "\n",
    "        df[rar_col] = rdw / alb\n",
    "\n",
    "    return df\n",
    "\n",
    "# apply\n",
    "mimic_df_small = add_rar_columns_only(mimic_df_small)\n",
    "eicu_df_small  = add_rar_columns_only(eicu_df_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5e95c7-4da4-4fbc-a7d8-f48e9fa0d347",
   "metadata": {},
   "source": [
    "# eICU BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1012644b-c8f6-4527-9d0e-797c1f10818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_file_path = r\"..\\00_Datasets\\eicu-2_0\\patient.csv.gz\"\n",
    "\n",
    "patients_df = pd.read_csv(compressed_file_path, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e96bf59-d07e-4229-9cca-fa746a9a1965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns related to ICU\n",
    "icu_columns = [\n",
    "    'uniquepid', # ID for a unique patient\n",
    "    'unitvisitnumber', # identifies the visit number of the patient\n",
    "    'patienthealthsystemstayid', # surrogate key for hospital Stay\n",
    "    'patientunitstayid', # surrogate key for ICU Stay\n",
    "    'gender', # gender of the patient\n",
    "    'age', # age of the patient in full years\n",
    "    'ethnicity', # ethnicity of the patient\n",
    "    'admissionheight', # admission height of the patient in cm\n",
    "    'admissionweight', #admission weight of the patient in kilograms\n",
    "]\n",
    "\n",
    "# Create a new DataFrame with only the ICU-related columns\n",
    "temp_df = patients_df[icu_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8490e48-fbc0-4c7a-851f-b71f7bf1fbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN counts:\n",
      " admissionheight    1312\n",
      "admissionweight    2032\n",
      "BMI                2928\n",
      "dtype: int64\n",
      "\n",
      "NaN rates (%):\n",
      " admissionheight    1.68\n",
      "admissionweight    2.60\n",
      "BMI                3.74\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def add_bmi_from_temp_using_patientunitstayid(\n",
    "    eicu_df_small: pd.DataFrame,\n",
    "    temp_df: pd.DataFrame,\n",
    "    verbose: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    out = eicu_df_small.copy()\n",
    "\n",
    "    # mapping table from temp_df\n",
    "    tmp = temp_df[[\"patientunitstayid\", \"admissionheight\", \"admissionweight\"]].copy()\n",
    "\n",
    "    # align dtypes for merge\n",
    "    out[\"hadm_id\"] = pd.to_numeric(out[\"hadm_id\"], errors=\"coerce\")\n",
    "    tmp[\"patientunitstayid\"] = pd.to_numeric(tmp[\"patientunitstayid\"], errors=\"coerce\")\n",
    "\n",
    "    # one row per ICU stay\n",
    "    tmp = tmp.drop_duplicates(subset=[\"patientunitstayid\"])\n",
    "\n",
    "    # merge: hadm_id (left) ↔ patientunitstayid (right)\n",
    "    out = out.merge(\n",
    "        tmp,\n",
    "        left_on=\"hadm_id\",\n",
    "        right_on=\"patientunitstayid\",\n",
    "        how=\"left\"\n",
    "    ).drop(columns=[\"patientunitstayid\"])  # drop duplicate key column\n",
    "\n",
    "    # BMI\n",
    "    h_cm = pd.to_numeric(out[\"admissionheight\"], errors=\"coerce\")\n",
    "    w_kg = pd.to_numeric(out[\"admissionweight\"], errors=\"coerce\")\n",
    "\n",
    "    h_m = (h_cm / 100.0).replace(0, np.nan)\n",
    "    w_kg = w_kg.replace(0, np.nan)\n",
    "\n",
    "    out[\"BMI\"] = w_kg / (h_m ** 2)\n",
    "\n",
    "    if verbose:\n",
    "        cols = [\"admissionheight\", \"admissionweight\", \"BMI\"]\n",
    "        print(\"NaN counts:\\n\", out[cols].isna().sum())\n",
    "        print(\"\\nNaN rates (%):\\n\", (out[cols].isna().mean() * 100).round(2))\n",
    "\n",
    "    return out\n",
    "\n",
    "# usage:\n",
    "eicu_df_small = add_bmi_from_temp_using_patientunitstayid(eicu_df_small, temp_df, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5817b863-fdc7-4ff2-bb66-10503b6a546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Αφαίρεση στηλών ύψους και βάρους από την eicu\n",
    "eicu_df_small = eicu_df_small.drop(columns=[\"admissionheight\", \"admissionweight\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f420f36-cc66-4143-9977-b02845d73051",
   "metadata": {},
   "source": [
    "# MIMIC BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95345efb-f4d0-483b-a3e3-36f56cabb621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_count</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>Time_Zone</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>Alanine_Aminotransferase_(ALT)_(Max)</th>\n",
       "      <th>Alanine_Aminotransferase_(ALT)_(Mean)</th>\n",
       "      <th>Alanine_Aminotransferase_(ALT)_(Median)</th>\n",
       "      <th>...</th>\n",
       "      <th>NLR_(Median)</th>\n",
       "      <th>PLR_(Median)</th>\n",
       "      <th>ANC_(Min)</th>\n",
       "      <th>NLR_(Min)</th>\n",
       "      <th>PLR_(Min)</th>\n",
       "      <th>RAR_(Max)</th>\n",
       "      <th>RAR_(Min)</th>\n",
       "      <th>RAR_(Mean)</th>\n",
       "      <th>RAR_(Median)</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>233029</td>\n",
       "      <td>142974</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>54</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>192.192192</td>\n",
       "      <td>9546.0</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>192.192192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.528345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>233029</td>\n",
       "      <td>142974</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>54</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>192.192192</td>\n",
       "      <td>9546.0</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>192.192192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.528345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>233029</td>\n",
       "      <td>142974</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>54</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>192.192192</td>\n",
       "      <td>9546.0</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>192.192192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.528345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>233029</td>\n",
       "      <td>142974</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>54</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>192.192192</td>\n",
       "      <td>9546.0</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>192.192192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.528345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>233029</td>\n",
       "      <td>142974</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>54</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>192.192192</td>\n",
       "      <td>9546.0</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>192.192192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.528345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78251</th>\n",
       "      <td>86652</td>\n",
       "      <td>3520548</td>\n",
       "      <td>3353094</td>\n",
       "      <td>12</td>\n",
       "      <td>F</td>\n",
       "      <td>78</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.922078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.018692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.824641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78252</th>\n",
       "      <td>86653</td>\n",
       "      <td>3520548</td>\n",
       "      <td>3353094</td>\n",
       "      <td>13</td>\n",
       "      <td>F</td>\n",
       "      <td>78</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.592593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.018692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.824641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78253</th>\n",
       "      <td>86654</td>\n",
       "      <td>3520548</td>\n",
       "      <td>3353094</td>\n",
       "      <td>14</td>\n",
       "      <td>F</td>\n",
       "      <td>78</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.922078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.018692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.824641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78254</th>\n",
       "      <td>86655</td>\n",
       "      <td>3520548</td>\n",
       "      <td>3353094</td>\n",
       "      <td>15</td>\n",
       "      <td>F</td>\n",
       "      <td>78</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.870968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.870968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.824641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78255</th>\n",
       "      <td>86656</td>\n",
       "      <td>3520548</td>\n",
       "      <td>3353094</td>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>78</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.922078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.018692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.824641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78256 rows × 214 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_count  subject_id  hadm_id  Time_Zone gender  age  \\\n",
       "0              1      233029   142974          1      F   54   \n",
       "1              2      233029   142974          2      F   54   \n",
       "2              3      233029   142974          3      F   54   \n",
       "3              4      233029   142974          4      F   54   \n",
       "4              5      233029   142974          5      F   54   \n",
       "...          ...         ...      ...        ...    ...  ...   \n",
       "78251      86652     3520548  3353094         12      F   78   \n",
       "78252      86653     3520548  3353094         13      F   78   \n",
       "78253      86654     3520548  3353094         14      F   78   \n",
       "78254      86655     3520548  3353094         15      F   78   \n",
       "78255      86656     3520548  3353094         16      F   78   \n",
       "\n",
       "                         race  Alanine_Aminotransferase_(ALT)_(Max)  \\\n",
       "0      BLACK/AFRICAN AMERICAN                                   NaN   \n",
       "1      BLACK/AFRICAN AMERICAN                                   NaN   \n",
       "2      BLACK/AFRICAN AMERICAN                                   NaN   \n",
       "3      BLACK/AFRICAN AMERICAN                                   NaN   \n",
       "4      BLACK/AFRICAN AMERICAN                                   NaN   \n",
       "...                       ...                                   ...   \n",
       "78251  BLACK/AFRICAN AMERICAN                                   NaN   \n",
       "78252  BLACK/AFRICAN AMERICAN                                   NaN   \n",
       "78253  BLACK/AFRICAN AMERICAN                                   NaN   \n",
       "78254  BLACK/AFRICAN AMERICAN                                   NaN   \n",
       "78255  BLACK/AFRICAN AMERICAN                                   NaN   \n",
       "\n",
       "       Alanine_Aminotransferase_(ALT)_(Mean)  \\\n",
       "0                                        NaN   \n",
       "1                                        NaN   \n",
       "2                                        NaN   \n",
       "3                                        NaN   \n",
       "4                                        NaN   \n",
       "...                                      ...   \n",
       "78251                                    NaN   \n",
       "78252                                    NaN   \n",
       "78253                                    NaN   \n",
       "78254                                    NaN   \n",
       "78255                                    NaN   \n",
       "\n",
       "       Alanine_Aminotransferase_(ALT)_(Median)  ...  NLR_(Median)  \\\n",
       "0                                          NaN  ...      7.166667   \n",
       "1                                          NaN  ...      7.166667   \n",
       "2                                          NaN  ...      7.166667   \n",
       "3                                          NaN  ...      7.166667   \n",
       "4                                          NaN  ...      7.166667   \n",
       "...                                        ...  ...           ...   \n",
       "78251                                      NaN  ...           NaN   \n",
       "78252                                      NaN  ...           NaN   \n",
       "78253                                      NaN  ...           NaN   \n",
       "78254                                      NaN  ...           NaN   \n",
       "78255                                      NaN  ...           NaN   \n",
       "\n",
       "       PLR_(Median)  ANC_(Min)  NLR_(Min)   PLR_(Min)  RAR_(Max)  RAR_(Min)  \\\n",
       "0        192.192192     9546.0   7.166667  192.192192        NaN        NaN   \n",
       "1        192.192192     9546.0   7.166667  192.192192        NaN        NaN   \n",
       "2        192.192192     9546.0   7.166667  192.192192        NaN        NaN   \n",
       "3        192.192192     9546.0   7.166667  192.192192        NaN        NaN   \n",
       "4        192.192192     9546.0   7.166667  192.192192        NaN        NaN   \n",
       "...             ...        ...        ...         ...        ...        ...   \n",
       "78251     77.922078        NaN        NaN   74.018692        NaN        NaN   \n",
       "78252     82.592593        NaN        NaN   74.018692        NaN        NaN   \n",
       "78253     77.922078        NaN        NaN   74.018692        NaN        NaN   \n",
       "78254     63.870968        NaN        NaN   63.870968        NaN        NaN   \n",
       "78255     77.922078        NaN        NaN   74.018692        NaN        NaN   \n",
       "\n",
       "       RAR_(Mean)  RAR_(Median)        BMI  \n",
       "0             NaN           NaN  47.528345  \n",
       "1             NaN           NaN  47.528345  \n",
       "2             NaN           NaN  47.528345  \n",
       "3             NaN           NaN  47.528345  \n",
       "4             NaN           NaN  47.528345  \n",
       "...           ...           ...        ...  \n",
       "78251         NaN           NaN  23.824641  \n",
       "78252         NaN           NaN  23.824641  \n",
       "78253         NaN           NaN  23.824641  \n",
       "78254         NaN           NaN  23.824641  \n",
       "78255         NaN           NaN  23.824641  \n",
       "\n",
       "[78256 rows x 214 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(eicu_df_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77086e3d-42ed-4fa0-ab7f-ca04cfcdb5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_stay_path = r\"CSV/Exports/o03_icu_first_stay.csv\"\n",
    "\n",
    "first_stay_df = pd.read_csv(first_stay_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "154b88dc-3b46-4bda-9fab-9683d1509b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found itemids -> height: 2, weight: 8, total: 10\n",
      "temp_chart_df shape: (3621, 4)\n",
      "   subject_id   hadm_id  admissionheight_cm  admissionweight_kg\n",
      "0    10004733  27411876              180.17              112.50\n",
      "1    10027602  28166872              162.53               65.75\n",
      "2    10029224  25729446              167.82               69.50\n",
      "3    10032725  20611640              182.94               84.50\n",
      "4    10044916  21484626              175.13              155.20\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Paths\n",
    "# -------------------------\n",
    "CHARTEVENTS_PATH = r\"../00_Datasets/mimic-iv-3_1/icu/chartevents.csv.gz\"\n",
    "DITEMS_PATH      = r\"../00_Datasets/mimic-iv-3_1/icu/d_items.csv.gz\"\n",
    "\n",
    "# -------------------------\n",
    "# 1) Load d_items and find itemids for height/weight\n",
    "# -------------------------\n",
    "d_items = pd.read_csv(DITEMS_PATH, compression=\"gzip\")\n",
    "d_items[\"label\"] = d_items[\"label\"].astype(str)\n",
    "d_items[\"unitname\"] = d_items.get(\"unitname\", pd.Series([np.nan]*len(d_items))).astype(str)\n",
    "\n",
    "# Height itemids\n",
    "height_mask = (\n",
    "    d_items[\"label\"].str.contains(r\"\\bheight\\b\", case=False, na=False)\n",
    "    & ~d_items[\"label\"].str.contains(r\"estimated|source|stated\", case=False, na=False)\n",
    ")\n",
    "\n",
    "# Weight itemids\n",
    "weight_mask = (\n",
    "    d_items[\"label\"].str.contains(r\"\\bweight\\b\", case=False, na=False)\n",
    "    & ~d_items[\"label\"].str.contains(r\"change|gain|loss|dry\", case=False, na=False)\n",
    ")\n",
    "\n",
    "height_itemids = set(d_items.loc[height_mask, \"itemid\"].unique())\n",
    "weight_itemids = set(d_items.loc[weight_mask, \"itemid\"].unique())\n",
    "need_itemids   = height_itemids | weight_itemids\n",
    "\n",
    "print(f\"Found itemids -> height: {len(height_itemids)}, weight: {len(weight_itemids)}, total: {len(need_itemids)}\")\n",
    "\n",
    "# Meta for merge (helps with units)\n",
    "meta = d_items.loc[d_items[\"itemid\"].isin(need_itemids), [\"itemid\", \"label\", \"unitname\"]].copy()\n",
    "\n",
    "# -------------------------\n",
    "# 2) Helpers for unit conversion\n",
    "# -------------------------\n",
    "def to_height_cm(val, uom):\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "    u = (\"\" if pd.isna(uom) else str(uom)).strip().lower()\n",
    "    if u in [\"cm\", \"centimeters\", \"centimetres\"]:\n",
    "        return val\n",
    "    if u in [\"in\", \"inch\", \"inches\"]:\n",
    "        return val * 2.54\n",
    "    if u in [\"m\", \"meter\", \"meters\"]:\n",
    "        return val * 100.0\n",
    "    # fallback (αν δεν ξέρουμε μονάδα, κρατάμε όπως είναι)\n",
    "    return val\n",
    "\n",
    "def to_weight_kg(val, uom):\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "    u = (\"\" if pd.isna(uom) else str(uom)).strip().lower()\n",
    "    if u in [\"kg\", \"kilogram\", \"kilograms\"]:\n",
    "        return val\n",
    "    if u in [\"lb\", \"lbs\", \"pound\", \"pounds\"]:\n",
    "        return val * 0.45359237\n",
    "    if u in [\"g\", \"gram\", \"grams\"]:\n",
    "        return val / 1000.0\n",
    "    return val\n",
    "\n",
    "# -------------------------\n",
    "# 3) Stream read chartevents, keep only height/weight, map to subject_id/hadm_id\n",
    "# -------------------------\n",
    "chunksize = 200_000\n",
    "reader = pd.read_csv(CHARTEVENTS_PATH, compression=\"gzip\", chunksize=chunksize)\n",
    "\n",
    "# keep only minimal mapping from first_stay_df\n",
    "stay_map = first_stay_df[[\"stay_id\", \"subject_id\", \"hadm_id\"]].drop_duplicates()\n",
    "\n",
    "kept = []\n",
    "\n",
    "for chunk in reader:\n",
    "    # keep only itemids we care about + numeric values\n",
    "    chunk = chunk[chunk[\"itemid\"].isin(need_itemids) & chunk[\"valuenum\"].notna()]\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "\n",
    "    # reduce cols early\n",
    "    use_cols = [\"stay_id\", \"itemid\", \"valuenum\"]\n",
    "    if \"valueuom\" in chunk.columns:\n",
    "        use_cols.append(\"valueuom\")\n",
    "    if \"charttime\" in chunk.columns:\n",
    "        use_cols.append(\"charttime\")\n",
    "\n",
    "    chunk = chunk[use_cols].copy()\n",
    "\n",
    "    # attach metadata (label/unitname) to help conversion if valueuom missing\n",
    "    chunk = chunk.merge(meta, on=\"itemid\", how=\"left\")\n",
    "\n",
    "    # choose unit source: prefer valueuom, else unitname\n",
    "    if \"valueuom\" in chunk.columns:\n",
    "        chunk[\"uom\"] = chunk[\"valueuom\"].where(chunk[\"valueuom\"].notna(), chunk[\"unitname\"])\n",
    "    else:\n",
    "        chunk[\"uom\"] = chunk[\"unitname\"]\n",
    "\n",
    "    # merge to get subject_id/hadm_id\n",
    "    chunk = chunk.merge(stay_map, on=\"stay_id\", how=\"inner\")\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "\n",
    "    # mark measure\n",
    "    chunk[\"measure\"] = np.where(chunk[\"itemid\"].isin(height_itemids), \"height\", \"weight\")\n",
    "\n",
    "    # convert to metric\n",
    "    chunk[\"value_metric\"] = np.where(\n",
    "        chunk[\"measure\"] == \"height\",\n",
    "        chunk.apply(lambda r: to_height_cm(r[\"valuenum\"], r[\"uom\"]), axis=1),\n",
    "        chunk.apply(lambda r: to_weight_kg(r[\"valuenum\"], r[\"uom\"]), axis=1),\n",
    "    )\n",
    "\n",
    "    kept.append(chunk[[\"subject_id\", \"hadm_id\", \"measure\", \"value_metric\"]])\n",
    "\n",
    "# combine\n",
    "if kept:\n",
    "    long_df = pd.concat(kept, ignore_index=True)\n",
    "else:\n",
    "    long_df = pd.DataFrame(columns=[\"subject_id\", \"hadm_id\", \"measure\", \"value_metric\"])\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# -------------------------\n",
    "# 4) Clean unrealistic values + aggregate to one height/weight per (subject_id, hadm_id)\n",
    "# -------------------------\n",
    "# broad plausibility filters\n",
    "h = long_df[long_df[\"measure\"] == \"height\"].copy()\n",
    "w = long_df[long_df[\"measure\"] == \"weight\"].copy()\n",
    "\n",
    "h = h[(h[\"value_metric\"] >= 100) & (h[\"value_metric\"] <= 250)]\n",
    "w = w[(w[\"value_metric\"] >= 30) & (w[\"value_metric\"] <= 350)]\n",
    "\n",
    "height_by = h.groupby([\"subject_id\", \"hadm_id\"])[\"value_metric\"].median().rename(\"admissionheight_cm\")\n",
    "weight_by = w.groupby([\"subject_id\", \"hadm_id\"])[\"value_metric\"].median().rename(\"admissionweight_kg\")\n",
    "\n",
    "temp_chart_df = pd.concat([height_by, weight_by], axis=1).reset_index()\n",
    "\n",
    "print(\"temp_chart_df shape:\", temp_chart_df.shape)\n",
    "print(temp_chart_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aa291f4-ccfe-4c54-a334-457f25002304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>admissionheight_cm</th>\n",
       "      <th>admissionweight_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>180.17</td>\n",
       "      <td>112.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10027602</td>\n",
       "      <td>28166872</td>\n",
       "      <td>162.53</td>\n",
       "      <td>65.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10029224</td>\n",
       "      <td>25729446</td>\n",
       "      <td>167.82</td>\n",
       "      <td>69.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10032725</td>\n",
       "      <td>20611640</td>\n",
       "      <td>182.94</td>\n",
       "      <td>84.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10044916</td>\n",
       "      <td>21484626</td>\n",
       "      <td>175.13</td>\n",
       "      <td>155.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3616</th>\n",
       "      <td>19978774</td>\n",
       "      <td>22382691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>216.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3617</th>\n",
       "      <td>19992365</td>\n",
       "      <td>20220175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3618</th>\n",
       "      <td>19994233</td>\n",
       "      <td>29338696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3619</th>\n",
       "      <td>19997293</td>\n",
       "      <td>26366652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>173.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3620</th>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3621 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject_id   hadm_id  admissionheight_cm  admissionweight_kg\n",
       "0       10004733  27411876              180.17              112.50\n",
       "1       10027602  28166872              162.53               65.75\n",
       "2       10029224  25729446              167.82               69.50\n",
       "3       10032725  20611640              182.94               84.50\n",
       "4       10044916  21484626              175.13              155.20\n",
       "...          ...       ...                 ...                 ...\n",
       "3616    19978774  22382691                 NaN              216.00\n",
       "3617    19992365  20220175                 NaN              102.85\n",
       "3618    19994233  29338696                 NaN              112.20\n",
       "3619    19997293  26366652                 NaN              173.00\n",
       "3620    19999987  23865745                 NaN              113.10\n",
       "\n",
       "[3621 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(temp_chart_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95c0054d-34b2-43a0-bfc1-4148ecee322c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN counts:\n",
      " admissionheight_cm    29376\n",
      "admissionweight_kg      208\n",
      "dtype: int64\n",
      "\n",
      "NaN rates (%):\n",
      " admissionheight_cm    57.55\n",
      "admissionweight_kg     0.41\n",
      "dtype: float64\n",
      "\n",
      "Example rows with height/weight:\n",
      "   subject_id   hadm_id  admissionheight_cm  admissionweight_kg\n",
      "0    10004733  27411876              180.17               112.5\n",
      "1    10004733  27411876              180.17               112.5\n",
      "2    10004733  27411876              180.17               112.5\n",
      "3    10004733  27411876              180.17               112.5\n",
      "4    10004733  27411876              180.17               112.5\n",
      "5    10004733  27411876              180.17               112.5\n",
      "6    10004733  27411876              180.17               112.5\n",
      "7    10004733  27411876              180.17               112.5\n",
      "8    10004733  27411876              180.17               112.5\n",
      "9    10004733  27411876              180.17               112.5\n"
     ]
    }
   ],
   "source": [
    "# 0) (προαιρετικά αλλά καλό) ensure σωστά dtypes για keys\n",
    "mimic_df_small = mimic_df_small.copy()\n",
    "temp_chart_df  = temp_chart_df.copy()\n",
    "\n",
    "mimic_df_small[\"subject_id\"] = pd.to_numeric(mimic_df_small[\"subject_id\"], errors=\"coerce\")\n",
    "mimic_df_small[\"hadm_id\"]    = pd.to_numeric(mimic_df_small[\"hadm_id\"], errors=\"coerce\")\n",
    "\n",
    "temp_chart_df[\"subject_id\"]  = pd.to_numeric(temp_chart_df[\"subject_id\"], errors=\"coerce\")\n",
    "temp_chart_df[\"hadm_id\"]     = pd.to_numeric(temp_chart_df[\"hadm_id\"], errors=\"coerce\")\n",
    "\n",
    "# 1) κρατάμε μόνο τα columns που θέλουμε να φέρουμε (και αφαιρούμε τυχόν duplicates)\n",
    "temp_hw = temp_chart_df[[\"subject_id\",\"hadm_id\",\"admissionheight_cm\",\"admissionweight_kg\"]].drop_duplicates(\n",
    "    subset=[\"subject_id\",\"hadm_id\"]\n",
    ")\n",
    "\n",
    "# 2) merge\n",
    "mimic_df_small = mimic_df_small.merge(\n",
    "    temp_hw,\n",
    "    on=[\"subject_id\",\"hadm_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 3) quick checks\n",
    "cols = [\"admissionheight_cm\", \"admissionweight_kg\"]\n",
    "print(\"NaN counts:\\n\", mimic_df_small[cols].isna().sum())\n",
    "print(\"\\nNaN rates (%):\\n\", (mimic_df_small[cols].isna().mean() * 100).round(2))\n",
    "print(\"\\nExample rows with height/weight:\")\n",
    "print(mimic_df_small.loc[mimic_df_small[\"admissionheight_cm\"].notna(), [\"subject_id\",\"hadm_id\"] + cols].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31687272-6797-44fc-b8b2-e3254e40db5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_m = (pd.to_numeric(mimic_df_small[\"admissionheight_cm\"], errors=\"coerce\") / 100.0).replace(0, np.nan)\n",
    "w_kg = pd.to_numeric(mimic_df_small[\"admissionweight_kg\"], errors=\"coerce\").replace(0, np.nan)\n",
    "mimic_df_small[\"BMI\"] = w_kg / (h_m ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "211e4114-c21f-41ac-a4e5-38b733cf8834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Αφαίρεση στηλών ύψους και βάρους από την eicu\n",
    "mimic_df_small = mimic_df_small.drop(columns=[\"admissionheight_cm\", \"admissionweight_kg\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7c8b5a-34e8-4181-bba0-e1634374ba30",
   "metadata": {},
   "source": [
    "# SOFA eICU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2adda8f8-f235-4b41-9eb9-323b8e1b09f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "APACHE_PRED_PATH = r\"..\\00_Datasets\\eicu-2_0\\apachePredVar.csv.gz\"\n",
    "APACHE_APS_PATH  = r\"..\\00_Datasets\\eicu-2_0\\apacheApsVar.csv.gz\"\n",
    "RESPCARE_PATH    = r\"..\\00_Datasets\\eicu-2_0\\respiratoryCare.csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f907fc91-bb24-4e88-93d2-6c908a7f238c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dimopoulos\\AppData\\Local\\Temp\\ipykernel_3024\\680375349.py:3: DtypeWarning: Columns (4,5,6,12,26,27,28,30,31,32,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  respcare = pd.read_csv(RESPCARE_PATH, compression=\"gzip\")\n"
     ]
    }
   ],
   "source": [
    "apache_pred = pd.read_csv(APACHE_PRED_PATH, compression=\"gzip\")\n",
    "apache_aps = pd.read_csv(APACHE_APS_PATH, compression=\"gzip\")\n",
    "respcare = pd.read_csv(RESPCARE_PATH, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a48a4b6-f218-4fe7-b52d-459c141c7cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Saved: CSV\\Exports\\Temp\\Doctors_Dataset\\headers\\apache_pred_headers.csv\n",
      "[OK] Saved: CSV\\Exports\\Temp\\Doctors_Dataset\\headers\\apache_aps_headers.csv\n",
      "[OK] Saved: CSV\\Exports\\Temp\\Doctors_Dataset\\headers\\respcare_headers.csv\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Output folder\n",
    "# -------------------------\n",
    "OUT_DIR = Path(\"CSV/Exports/Temp/Doctors_Dataset/headers\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def export_headers(df: pd.DataFrame, name: str):\n",
    "    \"\"\"\n",
    "    Saves:\n",
    "      1) all headers to CSV\n",
    "      2) candidate headers for RDW/Albumin to a separate CSV (optional but useful)\n",
    "    \"\"\"\n",
    "    # 1) All headers\n",
    "    headers_df = pd.DataFrame({\"column\": df.columns.astype(str)})\n",
    "    all_path = OUT_DIR / f\"{name}_headers.csv\"\n",
    "    headers_df.to_csv(all_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f\"[OK] Saved: {all_path}\")\n",
    "\n",
    "# -------------------------\n",
    "# Run exports\n",
    "# -------------------------\n",
    "export_headers(apache_pred, \"apache_pred\")\n",
    "export_headers(apache_aps, \"apache_aps\")\n",
    "export_headers(respcare, \"respcare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56b2692f-ea0f-4541-aa3e-efe39d985150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_fio2_frac(x):\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    # αν είναι 21–100, το κάνουμε 0.21–1.0\n",
    "    return x.where(x <= 1.0, x / 100.0).replace(0, np.nan)\n",
    "\n",
    "def sofa_resp(pao2, fio2, support):\n",
    "    pf = pd.to_numeric(pao2, errors=\"coerce\") / _to_fio2_frac(fio2)\n",
    "    s  = pd.to_numeric(support, errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "    out = pd.Series(np.nan, index=pf.index, dtype=\"float\")\n",
    "    out = np.where(pf >= 400, 0, out)\n",
    "    out = np.where((pf < 400) & (pf >= 300), 1, out)\n",
    "    out = np.where((pf < 300) & (pf >= 200), 2, out)\n",
    "    out = np.where((pf < 200) & (pf >= 100) & (s == 1), 3, out)\n",
    "    out = np.where((pf < 100) & (s == 1), 4, out)\n",
    "    return pd.Series(out, index=pf.index)\n",
    "\n",
    "def sofa_cns(gcs):\n",
    "    g = pd.to_numeric(gcs, errors=\"coerce\")\n",
    "    out = pd.Series(np.nan, index=g.index, dtype=\"float\")\n",
    "    out = np.where(g == 15, 0, out)\n",
    "    out = np.where((g >= 13) & (g <= 14), 1, out)\n",
    "    out = np.where((g >= 10) & (g <= 12), 2, out)\n",
    "    out = np.where((g >= 6)  & (g <= 9), 3, out)\n",
    "    out = np.where(g < 6, 4, out)\n",
    "    return pd.Series(out, index=g.index)\n",
    "\n",
    "def sofa_liver(bili_mgdl):\n",
    "    b = pd.to_numeric(bili_mgdl, errors=\"coerce\")\n",
    "    out = pd.Series(np.nan, index=b.index, dtype=\"float\")\n",
    "    out = np.where(b < 1.2, 0, out)\n",
    "    out = np.where((b >= 1.2) & (b <= 1.9), 1, out)\n",
    "    out = np.where((b >= 2.0) & (b <= 5.9), 2, out)\n",
    "    out = np.where((b >= 6.0) & (b <= 11.9), 3, out)\n",
    "    out = np.where(b >= 12.0, 4, out)\n",
    "    return pd.Series(out, index=b.index)\n",
    "\n",
    "def sofa_renal(creat_mgdl, urine_ml_day=None, dialysis=None):\n",
    "    c = pd.to_numeric(creat_mgdl, errors=\"coerce\")\n",
    "    u = pd.to_numeric(urine_ml_day, errors=\"coerce\") if urine_ml_day is not None else None\n",
    "    d = pd.to_numeric(dialysis, errors=\"coerce\").fillna(0).astype(int) if dialysis is not None else pd.Series(0, index=c.index)\n",
    "\n",
    "    out = pd.Series(np.nan, index=c.index, dtype=\"float\")\n",
    "    out = np.where(c < 1.2, 0, out)\n",
    "    out = np.where((c >= 1.2) & (c <= 1.9), 1, out)\n",
    "    out = np.where((c >= 2.0) & (c <= 3.4), 2, out)\n",
    "    out = np.where((c >= 3.5) & (c <= 4.9), 3, out)\n",
    "    out = np.where(c >= 5.0, 4, out)\n",
    "\n",
    "    # urine criteria (αν το urine είναι 24h total)\n",
    "    if u is not None:\n",
    "        out = np.where(u < 500, np.maximum(out, 3), out)\n",
    "        out = np.where(u < 200, np.maximum(out, 4), out)\n",
    "\n",
    "    # dialysis -> πρακτικά πολύ severe (συχνά το αντιμετωπίζουν ως 4)\n",
    "    out = np.where(d == 1, 4, out)\n",
    "\n",
    "    return pd.Series(out, index=c.index)\n",
    "\n",
    "def sofa_coag(plt):\n",
    "    p = pd.to_numeric(plt, errors=\"coerce\")\n",
    "    out = pd.Series(np.nan, index=p.index, dtype=\"float\")\n",
    "    out = np.where(p >= 150, 0, out)\n",
    "    out = np.where((p < 150) & (p >= 100), 1, out)\n",
    "    out = np.where((p < 100) & (p >= 50), 2, out)\n",
    "    out = np.where((p < 50)  & (p >= 20), 3, out)\n",
    "    out = np.where(p < 20, 4, out)\n",
    "    return pd.Series(out, index=p.index)\n",
    "\n",
    "def sofa_cardio(map_mmHg, pressor_level=None):\n",
    "    # v1: μόνο MAP 0/1 (χωρίς pressor doses)\n",
    "    m = pd.to_numeric(map_mmHg, errors=\"coerce\")\n",
    "    out = pd.Series(np.nan, index=m.index, dtype=\"float\")\n",
    "    out = np.where(m >= 70, 0, out)\n",
    "    out = np.where(m < 70, 1, out)\n",
    "    return pd.Series(out, index=m.index)\n",
    "\n",
    "def build_sofa_eicu_day1(apache_aps, apache_pred, respcare, eicu_df_small):\n",
    "    # keys\n",
    "    aps  = apache_aps.copy()\n",
    "    pred = apache_pred.copy()\n",
    "    rc   = respcare.copy()\n",
    "\n",
    "    aps[\"patientunitstayid\"]  = pd.to_numeric(aps[\"patientunitstayid\"], errors=\"coerce\")\n",
    "    pred[\"patientunitstayid\"] = pd.to_numeric(pred[\"patientunitstayid\"], errors=\"coerce\")\n",
    "    rc[\"patientunitstayid\"]   = pd.to_numeric(rc[\"patientunitstayid\"], errors=\"coerce\")\n",
    "\n",
    "    # --- support flag (day1/baseline)\n",
    "    # pred: oobventday1 / oobintubday1 (doc: intubated day1 => mechanically ventilated) \n",
    "    support_pred = pred[[\"patientunitstayid\",\"oobventday1\",\"oobintubday1\"]].drop_duplicates(\"patientunitstayid\")\n",
    "    for c in [\"oobventday1\",\"oobintubday1\"]:\n",
    "        support_pred[c] = pd.to_numeric(support_pred[c], errors=\"coerce\").fillna(0).astype(int)\n",
    "    support_pred[\"support_pred\"] = ((support_pred[\"oobventday1\"]==1) | (support_pred[\"oobintubday1\"]==1)).astype(int)\n",
    "\n",
    "    # aps: vent/intubated\n",
    "    support_aps = aps[[\"patientunitstayid\",\"vent\",\"intubated\"]].drop_duplicates(\"patientunitstayid\").copy()\n",
    "    for c in [\"vent\",\"intubated\"]:\n",
    "        support_aps[c] = pd.to_numeric(support_aps[c], errors=\"coerce\").fillna(0).astype(int)\n",
    "    support_aps[\"support_aps\"] = ((support_aps[\"vent\"]==1) | (support_aps[\"intubated\"]==1)).astype(int)\n",
    "\n",
    "    # respcare: has ventstartoffset => ventilated episode exists\n",
    "    support_rc = rc.groupby(\"patientunitstayid\")[\"ventstartoffset\"].apply(lambda s: int(s.notna().any())).reset_index()\n",
    "    support_rc = support_rc.rename(columns={\"ventstartoffset\":\"support_rc\"})\n",
    "\n",
    "    support = support_pred[[\"patientunitstayid\",\"support_pred\"]].merge(\n",
    "        support_aps[[\"patientunitstayid\",\"support_aps\"]], on=\"patientunitstayid\", how=\"outer\"\n",
    "    ).merge(\n",
    "        support_rc, on=\"patientunitstayid\", how=\"outer\"\n",
    "    ).fillna(0)\n",
    "\n",
    "    support[\"support\"] = ((support[\"support_pred\"]==1) | (support[\"support_aps\"]==1) | (support[\"support_rc\"]==1)).astype(int)\n",
    "\n",
    "    # --- base sofa frame\n",
    "    base = aps[[\"patientunitstayid\",\"pao2\",\"fio2\",\"bilirubin\",\"creatinine\",\"urine\",\"dialysis\",\"meanbp\",\"eyes\",\"verbal\",\"motor\"]].drop_duplicates(\"patientunitstayid\")\n",
    "    base = base.merge(support[[\"patientunitstayid\",\"support\"]], on=\"patientunitstayid\", how=\"left\").fillna({\"support\":0})\n",
    "\n",
    "    # GCS from components\n",
    "    base[\"gcs\"] = (\n",
    "        pd.to_numeric(base[\"eyes\"], errors=\"coerce\")\n",
    "        + pd.to_numeric(base[\"verbal\"], errors=\"coerce\")\n",
    "        + pd.to_numeric(base[\"motor\"], errors=\"coerce\")\n",
    "    )\n",
    "\n",
    "    # platelets: από eicu_df_small (worst) -> πάρε το MIN ανά stay σε όλο το dataset σου (ή μόνο day1 αν θες)\n",
    "    tmp = eicu_df_small[[\"hadm_id\",\"Platelet_Count_(Min)\"]].copy()\n",
    "    tmp[\"hadm_id\"] = pd.to_numeric(tmp[\"hadm_id\"], errors=\"coerce\")\n",
    "    plt_by_stay = tmp.groupby(\"hadm_id\")[\"Platelet_Count_(Min)\"].min().reset_index().rename(columns={\"hadm_id\":\"patientunitstayid\", \"Platelet_Count_(Min)\":\"platelets_worst\"})\n",
    "\n",
    "    base = base.merge(plt_by_stay, on=\"patientunitstayid\", how=\"left\")\n",
    "\n",
    "    # subscores\n",
    "    base[\"SOFA_resp\"]  = sofa_resp(base[\"pao2\"], base[\"fio2\"], base[\"support\"])\n",
    "    base[\"SOFA_cns\"]   = sofa_cns(base[\"gcs\"])\n",
    "    base[\"SOFA_liver\"] = sofa_liver(base[\"bilirubin\"])\n",
    "    base[\"SOFA_renal\"] = sofa_renal(base[\"creatinine\"], base[\"urine\"], base[\"dialysis\"])\n",
    "    base[\"SOFA_coag\"]  = sofa_coag(base[\"platelets_worst\"])\n",
    "    base[\"SOFA_cardio\"]= sofa_cardio(base[\"meanbp\"])\n",
    "\n",
    "    base[\"SOFA_total_v1\"] = base[[\"SOFA_resp\",\"SOFA_cns\",\"SOFA_liver\",\"SOFA_renal\",\"SOFA_coag\",\"SOFA_cardio\"]].sum(axis=1, min_count=1)\n",
    "\n",
    "    return base[[\"patientunitstayid\",\"SOFA_resp\",\"SOFA_cns\",\"SOFA_liver\",\"SOFA_renal\",\"SOFA_coag\",\"SOFA_cardio\",\"SOFA_total_v1\",\"support\"]]\n",
    "\n",
    "# ---- usage ----\n",
    "sofa_day1 = build_sofa_eicu_day1(apache_aps, apache_pred, respcare, eicu_df_small)\n",
    "eicu_df_small = eicu_df_small.merge(sofa_day1, left_on=\"hadm_id\", right_on=\"patientunitstayid\", how=\"left\").drop(columns=[\"patientunitstayid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "401b296b-6913-4e50-a617-42881c5a86d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# κράτα ένα ενιαίο column\n",
    "eicu_df_small[\"SOFA\"] = eicu_df_small[\"SOFA_total_v1\"]\n",
    "\n",
    "# πέτα τα ενδιάμεσα\n",
    "drop_cols = [\"SOFA_resp\",\"SOFA_cns\",\"SOFA_liver\",\"SOFA_renal\",\"SOFA_coag\",\"SOFA_cardio\",\"SOFA_total_v1\",\"support\"]\n",
    "eicu_df_small = eicu_df_small.drop(columns=[c for c in drop_cols if c in eicu_df_small.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0996673-d202-4e56-9e13-39c9642d0c33",
   "metadata": {},
   "source": [
    "# MIMIC SOFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16e8ce15-d52b-4ec6-af1e-365182f86625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing stay_id rows: 0\n"
     ]
    }
   ],
   "source": [
    "# 1) Κράτα μόνο τα κλειδιά + stay_id από το stroke_first_stay\n",
    "map_stay = (\n",
    "    stroke_first_stay[[\"subject_id\", \"hadm_id\", \"stay_id\"]]\n",
    "    .dropna(subset=[\"subject_id\", \"hadm_id\", \"stay_id\"])\n",
    "    .drop_duplicates(subset=[\"subject_id\", \"hadm_id\"])  # αν υπάρχει 1 stay_id ανά (subject_id, hadm_id)\n",
    ")\n",
    "\n",
    "# 2) Φέρε το stay_id στο mimic_df\n",
    "mimic_df_small = mimic_df_small.merge(\n",
    "    map_stay,\n",
    "    on=[\"subject_id\", \"hadm_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# μετακίνηση της stay_id μετά την hadm_id\n",
    "cols = mimic_df_small.columns.tolist()\n",
    "cols.remove(\"stay_id\")\n",
    "\n",
    "hadm_pos = cols.index(\"hadm_id\")\n",
    "cols.insert(hadm_pos + 1, \"stay_id\")\n",
    "\n",
    "mimic_df_small =mimic_df_small[cols]\n",
    "\n",
    "# 3) (προαιρετικά) έλεγξε πόσα δεν βρέθηκαν\n",
    "missing = mimic_df_small[\"stay_id\"].isna().sum()\n",
    "print(\"Missing stay_id rows:\", missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c52f5ce3-4570-49b6-91ae-c885cdcaa32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Κρατάω από το stroke_first_day_sofa μόνο τις γραμμές που έχουν stay_id ίδιο με αυτό τον εισαγω΄γων εγκεφαλικού\n",
    "\n",
    "target_stay_ids = mimic_df_small[\"stay_id\"].dropna().unique()\n",
    "\n",
    "stroke_first_day_sofa_filtered = stroke_first_day_sofa[\n",
    "    stroke_first_day_sofa[\"stay_id\"].isin(target_stay_ids)\n",
    "].copy()\n",
    "\n",
    "stroke_first_day_sofa_filtered.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28305107-74ab-436a-8526-522cc3192a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = [\"subject_id\", \"hadm_id\", \"stay_id\"]\n",
    "\n",
    "# 1) Κράτα μόνο τα keys + sofa (και λύσε τυχόν διπλοεγγραφές)\n",
    "sofa_lookup = (\n",
    "    stroke_first_day_sofa_filtered[keys + [\"sofa\"]]\n",
    "    .groupby(keys, as_index=False)[\"sofa\"].max()   # αν υπάρχουν πολλαπλές εγγραφές, κράτα το max sofa\n",
    ")\n",
    "\n",
    "# 2) Merge (left, ώστε να μη χάσεις γραμμές από merged_df)\n",
    "mimic_df_small = mimic_df_small.merge(sofa_lookup, on=keys, how=\"left\", validate=\"m:1\")\n",
    "\n",
    "mimic_df_small[\"sofa\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b46ae668-056b-4cf6-9eaa-e55d90c3abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Αφαίρεση στηλών\n",
    "mimic_df_small = mimic_df_small.drop(columns=[\"stay_id\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ccea94bc-5835-48aa-bfd5-44bb74f50077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_count</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>Time_Zone</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>Alanine_Aminotransferase_(ALT)_(Max)</th>\n",
       "      <th>Alanine_Aminotransferase_(ALT)_(Mean)</th>\n",
       "      <th>Alanine_Aminotransferase_(ALT)_(Median)</th>\n",
       "      <th>...</th>\n",
       "      <th>PLR_(Median)</th>\n",
       "      <th>ANC_(Min)</th>\n",
       "      <th>NLR_(Min)</th>\n",
       "      <th>PLR_(Min)</th>\n",
       "      <th>RAR_(Max)</th>\n",
       "      <th>RAR_(Min)</th>\n",
       "      <th>RAR_(Mean)</th>\n",
       "      <th>RAR_(Median)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>sofa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>265.663391</td>\n",
       "      <td>6053.2</td>\n",
       "      <td>9.295455</td>\n",
       "      <td>265.663391</td>\n",
       "      <td>5.586207</td>\n",
       "      <td>5.586207</td>\n",
       "      <td>5.586207</td>\n",
       "      <td>5.586207</td>\n",
       "      <td>34.656729</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>265.663391</td>\n",
       "      <td>6053.2</td>\n",
       "      <td>9.295455</td>\n",
       "      <td>265.663391</td>\n",
       "      <td>5.586207</td>\n",
       "      <td>5.586207</td>\n",
       "      <td>5.586207</td>\n",
       "      <td>5.586207</td>\n",
       "      <td>34.656729</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>265.663391</td>\n",
       "      <td>6053.2</td>\n",
       "      <td>9.295455</td>\n",
       "      <td>265.663391</td>\n",
       "      <td>5.586207</td>\n",
       "      <td>5.586207</td>\n",
       "      <td>5.586207</td>\n",
       "      <td>5.586207</td>\n",
       "      <td>34.656729</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>265.663391</td>\n",
       "      <td>6053.2</td>\n",
       "      <td>9.295455</td>\n",
       "      <td>265.663391</td>\n",
       "      <td>5.586207</td>\n",
       "      <td>5.586207</td>\n",
       "      <td>5.586207</td>\n",
       "      <td>5.586207</td>\n",
       "      <td>34.656729</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>265.663391</td>\n",
       "      <td>6053.2</td>\n",
       "      <td>9.295455</td>\n",
       "      <td>265.663391</td>\n",
       "      <td>5.586207</td>\n",
       "      <td>5.586207</td>\n",
       "      <td>5.586207</td>\n",
       "      <td>5.586207</td>\n",
       "      <td>34.656729</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51035</th>\n",
       "      <td>58140</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>12</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.430366</td>\n",
       "      <td>8849.4</td>\n",
       "      <td>2.956897</td>\n",
       "      <td>40.430366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51036</th>\n",
       "      <td>58141</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>13</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.430366</td>\n",
       "      <td>8849.4</td>\n",
       "      <td>2.956897</td>\n",
       "      <td>40.430366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51037</th>\n",
       "      <td>58142</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>14</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.430366</td>\n",
       "      <td>8849.4</td>\n",
       "      <td>2.956897</td>\n",
       "      <td>40.430366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51038</th>\n",
       "      <td>58143</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>15</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.430366</td>\n",
       "      <td>8849.4</td>\n",
       "      <td>2.956897</td>\n",
       "      <td>40.430366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51039</th>\n",
       "      <td>58144</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.430366</td>\n",
       "      <td>8849.4</td>\n",
       "      <td>2.956897</td>\n",
       "      <td>40.430366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51040 rows × 215 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_count  subject_id   hadm_id  Time_Zone gender  age     race  \\\n",
       "0              1    10004733  27411876          1      M   51  UNKNOWN   \n",
       "1              2    10004733  27411876          2      M   51  UNKNOWN   \n",
       "2              3    10004733  27411876          3      M   51  UNKNOWN   \n",
       "3              4    10004733  27411876          4      M   51  UNKNOWN   \n",
       "4              5    10004733  27411876          5      M   51  UNKNOWN   \n",
       "...          ...         ...       ...        ...    ...  ...      ...   \n",
       "51035      58140    19999987  23865745         12      F   57  UNKNOWN   \n",
       "51036      58141    19999987  23865745         13      F   57  UNKNOWN   \n",
       "51037      58142    19999987  23865745         14      F   57  UNKNOWN   \n",
       "51038      58143    19999987  23865745         15      F   57  UNKNOWN   \n",
       "51039      58144    19999987  23865745         16      F   57  UNKNOWN   \n",
       "\n",
       "       Alanine_Aminotransferase_(ALT)_(Max)  \\\n",
       "0                                      46.0   \n",
       "1                                      46.0   \n",
       "2                                      46.0   \n",
       "3                                      46.0   \n",
       "4                                      46.0   \n",
       "...                                     ...   \n",
       "51035                                  63.0   \n",
       "51036                                  63.0   \n",
       "51037                                  63.0   \n",
       "51038                                  63.0   \n",
       "51039                                  63.0   \n",
       "\n",
       "       Alanine_Aminotransferase_(ALT)_(Mean)  \\\n",
       "0                                       46.0   \n",
       "1                                       46.0   \n",
       "2                                       46.0   \n",
       "3                                       46.0   \n",
       "4                                       46.0   \n",
       "...                                      ...   \n",
       "51035                                   63.0   \n",
       "51036                                   63.0   \n",
       "51037                                   63.0   \n",
       "51038                                   63.0   \n",
       "51039                                   63.0   \n",
       "\n",
       "       Alanine_Aminotransferase_(ALT)_(Median)  ...  PLR_(Median)  ANC_(Min)  \\\n",
       "0                                         46.0  ...    265.663391     6053.2   \n",
       "1                                         46.0  ...    265.663391     6053.2   \n",
       "2                                         46.0  ...    265.663391     6053.2   \n",
       "3                                         46.0  ...    265.663391     6053.2   \n",
       "4                                         46.0  ...    265.663391     6053.2   \n",
       "...                                        ...  ...           ...        ...   \n",
       "51035                                     63.0  ...     40.430366     8849.4   \n",
       "51036                                     63.0  ...     40.430366     8849.4   \n",
       "51037                                     63.0  ...     40.430366     8849.4   \n",
       "51038                                     63.0  ...     40.430366     8849.4   \n",
       "51039                                     63.0  ...     40.430366     8849.4   \n",
       "\n",
       "       NLR_(Min)   PLR_(Min)  RAR_(Max)  RAR_(Min)  RAR_(Mean)  RAR_(Median)  \\\n",
       "0       9.295455  265.663391   5.586207   5.586207    5.586207      5.586207   \n",
       "1       9.295455  265.663391   5.586207   5.586207    5.586207      5.586207   \n",
       "2       9.295455  265.663391   5.586207   5.586207    5.586207      5.586207   \n",
       "3       9.295455  265.663391   5.586207   5.586207    5.586207      5.586207   \n",
       "4       9.295455  265.663391   5.586207   5.586207    5.586207      5.586207   \n",
       "...          ...         ...        ...        ...         ...           ...   \n",
       "51035   2.956897   40.430366        NaN        NaN         NaN           NaN   \n",
       "51036   2.956897   40.430366        NaN        NaN         NaN           NaN   \n",
       "51037   2.956897   40.430366        NaN        NaN         NaN           NaN   \n",
       "51038   2.956897   40.430366        NaN        NaN         NaN           NaN   \n",
       "51039   2.956897   40.430366        NaN        NaN         NaN           NaN   \n",
       "\n",
       "             BMI  sofa  \n",
       "0      34.656729     3  \n",
       "1      34.656729     3  \n",
       "2      34.656729     3  \n",
       "3      34.656729     3  \n",
       "4      34.656729     3  \n",
       "...          ...   ...  \n",
       "51035        NaN     6  \n",
       "51036        NaN     6  \n",
       "51037        NaN     6  \n",
       "51038        NaN     6  \n",
       "51039        NaN     6  \n",
       "\n",
       "[51040 rows x 215 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mimic_df_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9683d5e4-bf7f-4251-b9e8-831b0b2af641",
   "metadata": {},
   "source": [
    "# Move los and hospital_expire_flag at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a11b221-989b-44b7-97d1-7d671922cc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIMIC last cols: ['RAR_(Median)', 'BMI', 'SOFA', 'los', 'hospital_expire_flag']\n",
      "eICU  last cols: ['RAR_(Median)', 'BMI', 'SOFA', 'los', 'hospital_expire_flag']\n"
     ]
    }
   ],
   "source": [
    "def move_targets_to_end(df, targets=(\"los\", \"hospital_expire_flag\")):\n",
    "    df = df.copy()\n",
    "    targets = [c for c in targets if c in df.columns]\n",
    "    other_cols = [c for c in df.columns if c not in targets]\n",
    "    return df[other_cols + targets]\n",
    "\n",
    "mimic_df_small = mimic_df_small.rename(columns={\"sofa\": \"SOFA\"})\n",
    "\n",
    "mimic_df_small = move_targets_to_end(mimic_df_small)\n",
    "eicu_df_small  = move_targets_to_end(eicu_df_small)\n",
    "\n",
    "# quick check\n",
    "print(\"MIMIC last cols:\", list(mimic_df_small.columns[-5:]))\n",
    "print(\"eICU  last cols:\", list(eicu_df_small.columns[-5:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b73a1d-bec7-4687-bcc7-9049213d9f9b",
   "metadata": {},
   "source": [
    "# Save Mimic - eICU Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db7029e5-a9a7-4cbc-b7da-7e6301b4657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"CSV/Exports/Temp/Doctors_Dataset\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "mimic_df_small.to_csv(os.path.join(out_dir, \"o01_mimic_for_ext_val.csv\"), index=False)\n",
    "eicu_df_small.to_csv(os.path.join(out_dir, \"o01_eicu_for_ext_val.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09990176-fe75-4e96-9a7b-372bab9bdcff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e0a192-d298-49d9-bedf-6d89e176f027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fe459c-b229-4086-b0a6-1b91c717a005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4666d537-9d3e-4d05-9789-c714e1124d4b",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d9ef521-a2da-4043-b65c-6e5efc8152d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- eicu_df_small: matches in subject_id ----\n",
      "rows: 0\n",
      "Empty DataFrame\n",
      "Columns: [subject_id, hadm_id, Time_Zone]\n",
      "Index: []\n",
      "\n",
      "---- temp_df: matches in uniquepid ----\n",
      "rows: 0\n",
      "Empty DataFrame\n",
      "Columns: [uniquepid, unitvisitnumber, patienthealthsystemstayid, patientunitstayid, gender, age, ethnicity, admissionheight, admissionweight]\n",
      "Index: []\n",
      "\n",
      "---- temp_df: matches in patienthealthsystemstayid ----\n",
      "rows: 0\n",
      "Empty DataFrame\n",
      "Columns: [uniquepid, patienthealthsystemstayid, patientunitstayid, admissionheight, admissionweight]\n",
      "Index: []\n",
      "\n",
      "---- temp_df: matches in patientunitstayid ----\n",
      "rows: 1\n",
      "        uniquepid  patienthealthsystemstayid  patientunitstayid  \\\n",
      "200838  035-20783                    2743005            3353144   \n",
      "\n",
      "        admissionheight  admissionweight  \n",
      "200838            180.3             39.2  \n"
     ]
    }
   ],
   "source": [
    "sid = 3353144\n",
    "sid_str = str(sid)\n",
    "\n",
    "print(\"---- eicu_df_small: matches in subject_id ----\")\n",
    "m_eicu = eicu_df_small[eicu_df_small[\"subject_id\"].astype(str) == sid_str]\n",
    "print(\"rows:\", len(m_eicu))\n",
    "print(m_eicu[[\"subject_id\",\"hadm_id\",\"Time_Zone\"]].head(10))\n",
    "\n",
    "print(\"\\n---- temp_df: matches in uniquepid ----\")\n",
    "m_u = temp_df[temp_df[\"uniquepid\"].astype(str) == sid_str]\n",
    "print(\"rows:\", len(m_u))\n",
    "print(m_u.head(5))\n",
    "\n",
    "print(\"\\n---- temp_df: matches in patienthealthsystemstayid ----\")\n",
    "m_h = temp_df[temp_df[\"patienthealthsystemstayid\"].astype(str) == sid_str]\n",
    "print(\"rows:\", len(m_h))\n",
    "print(m_h[[\"uniquepid\",\"patienthealthsystemstayid\",\"patientunitstayid\",\"admissionheight\",\"admissionweight\"]].head(10))\n",
    "\n",
    "print(\"\\n---- temp_df: matches in patientunitstayid ----\")\n",
    "m_pu = temp_df[temp_df[\"patientunitstayid\"].astype(str) == sid_str]\n",
    "print(\"rows:\", len(m_pu))\n",
    "print(m_pu[[\"uniquepid\",\"patienthealthsystemstayid\",\"patientunitstayid\",\"admissionheight\",\"admissionweight\"]].head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
