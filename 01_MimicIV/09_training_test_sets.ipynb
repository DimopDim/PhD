{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c4a47b6-bda1-464a-9038-3dc2e0a6cbc1",
   "metadata": {},
   "source": [
    "## Training - Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aa90ad6-3fce-4ab8-805f-e4867fafb173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "# Read the exported for header chartevent CSV file\n",
    "mean_df = pd.read_csv(r'CSV\\Exports\\datasets\\whole_set\\o01_final_mean_table.csv')\n",
    "median_df = pd.read_csv(r'CSV\\Exports\\datasets\\whole_set\\o02_final_median_table.csv')\n",
    "min_df = pd.read_csv(r'CSV\\Exports\\datasets\\whole_set\\o03_final_min_table.csv')\n",
    "max_df = pd.read_csv(r'CSV\\Exports\\datasets\\whole_set\\o04_final_max_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "996e88ad-5131-4c4a-a21d-5e76ea78b385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training percentage. The difference goes to test set\n",
    "training_percentage = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909f11e0-b2c2-460f-8395-89fc40eada26",
   "metadata": {},
   "source": [
    "# Split Mean to Training - Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d35f319-4ea6-4fd5-9b7b-570b767badef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The last row of the training set is -> 40688'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It's already sorted. Just for precaution. Sort by 'subject_id' and 'Time_Zone')\n",
    "mean_df = mean_df.sort_values(by=['subject_id', 'Time_Zone'])\n",
    "\n",
    "# Calculate the total number of unique subject IDs\n",
    "unique_subject_ids = mean_df['subject_id'].nunique()\n",
    "\n",
    "# Calculate the number of unique subject IDs to include in the training set\n",
    "train_subject_ids_count = int(training_percentage * unique_subject_ids)\n",
    "\n",
    "# Initialize variables to track the number of subject IDs included in the training set\n",
    "subject_ids_in_training = 0\n",
    "\n",
    "# Initialize empty DataFrames for the training and test sets with the same column structure and dtypes as mean_df\n",
    "train_df = mean_df.iloc[0:0].copy()\n",
    "test_df = mean_df.iloc[0:0].copy()\n",
    "\n",
    "# Iterate through the sorted DataFrame\n",
    "for subject_id, subject_data in mean_df.groupby('subject_id'):\n",
    "    if subject_ids_in_training < train_subject_ids_count:\n",
    "        # Add this subject's data to the training set\n",
    "        train_df = pd.concat([train_df, subject_data], ignore_index=True)\n",
    "        subject_ids_in_training += 1\n",
    "    else:\n",
    "        # Add this subject's data to the test set\n",
    "        test_df = pd.concat([test_df, subject_data], ignore_index=True)\n",
    "\n",
    "\n",
    "# Reset the index of the resulting DataFrames\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "# Export the merged DataFrame to a CSV file\n",
    "train_df.to_csv(r'CSV\\Exports\\datasets\\Train_test_sets\\o01_mean_train_.csv', index=False)\n",
    "test_df.to_csv(r'CSV\\Exports\\datasets\\Train_test_sets\\o01_mean_test_.csv', index=False)\n",
    "\n",
    "# Display the last row of the training set\n",
    "display(\"The last row of the training set is -> \" + str(train_df.tail(1)[\"row_count\"].values[0]))\n",
    "\n",
    "# Delete dataframes and variables to free memory\n",
    "del (unique_subject_ids, train_subject_ids_count, subject_ids_in_training, subject_data, train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c084004-91f2-497e-8b83-df47c16c4271",
   "metadata": {},
   "source": [
    "# Split Median to Training - Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dacd8ad-fef5-433c-93d7-6f3d69d64e33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The last row of the training set is -> 40688'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It's already sorted. Just for precaution. Sort by 'subject_id' and 'Time_Zone')\n",
    "median_df = median_df.sort_values(by=['subject_id', 'Time_Zone'])\n",
    "\n",
    "# Calculate the total number of unique subject IDs\n",
    "unique_subject_ids = median_df['subject_id'].nunique()\n",
    "\n",
    "# Calculate the number of unique subject IDs to include in the training set\n",
    "train_subject_ids_count = int(training_percentage * unique_subject_ids)\n",
    "\n",
    "# Initialize variables to track the number of subject IDs included in the training set\n",
    "subject_ids_in_training = 0\n",
    "\n",
    "# Initialize empty DataFrames for the training and test sets\n",
    "train_df = median_df.iloc[0:0].copy()\n",
    "test_df = median_df.iloc[0:0].copy()\n",
    "\n",
    "# Iterate through the sorted DataFrame\n",
    "for subject_id, subject_data in median_df.groupby('subject_id'):\n",
    "    if subject_ids_in_training < train_subject_ids_count:\n",
    "        # Add this subject's data to the training set\n",
    "        train_df = pd.concat([train_df, subject_data], ignore_index=True)\n",
    "        subject_ids_in_training += 1\n",
    "    else:\n",
    "        # Add this subject's data to the test set\n",
    "        test_df = pd.concat([test_df, subject_data], ignore_index=True)\n",
    "\n",
    "\n",
    "# Export the merged DataFrame to a CSV file\n",
    "train_df.to_csv(r'CSV\\Exports\\datasets\\Train_test_sets\\o02_median_train_.csv', index=False)\n",
    "test_df.to_csv(r'CSV\\Exports\\datasets\\Train_test_sets\\o02_median_test_.csv', index=False)\n",
    "\n",
    "# I'm going to use those numbers as the split point in rapidminer filter operator\n",
    "display(\"The last row of the training set is -> \" + str(train_df.tail(1)[\"row_count\"].values[0]))\n",
    "\n",
    "# Delete dataframes and variables to free memory.\n",
    "del (unique_subject_ids, train_subject_ids_count, subject_ids_in_training, subject_data, train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabcb621-cca1-4505-b59d-caa6bf612b19",
   "metadata": {},
   "source": [
    "# Split Min to Training - Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db779c6a-e65a-485e-bee0-4c0e5e420e6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The last row of the training set is -> 40688'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It's already sorted. Just for precaution. Sort by 'subject_id' and 'Time_Zone')\n",
    "min_df = min_df.sort_values(by=['subject_id', 'Time_Zone'])\n",
    "\n",
    "# Calculate the total number of unique subject IDs\n",
    "unique_subject_ids = min_df['subject_id'].nunique()\n",
    "\n",
    "# Calculate the number of unique subject IDs to include in the training set\n",
    "train_subject_ids_count = int(training_percentage * unique_subject_ids)\n",
    "\n",
    "# Initialize variables to track the number of subject IDs included in the training set\n",
    "subject_ids_in_training = 0\n",
    "\n",
    "# Initialize empty DataFrames for the training and test sets\n",
    "train_df = min_df.iloc[0:0].copy()\n",
    "test_df = min_df.iloc[0:0].copy()\n",
    "\n",
    "# Iterate through the sorted DataFrame\n",
    "for subject_id, subject_data in min_df.groupby('subject_id'):\n",
    "    if subject_ids_in_training < train_subject_ids_count:\n",
    "        # Add this subject's data to the training set\n",
    "        train_df = pd.concat([train_df, subject_data], ignore_index=True)\n",
    "        subject_ids_in_training += 1\n",
    "    else:\n",
    "        # Add this subject's data to the test set\n",
    "        test_df = pd.concat([test_df, subject_data], ignore_index=True)\n",
    "\n",
    "# Export the merged DataFrame to a CSV file\n",
    "train_df.to_csv(r'CSV\\Exports\\datasets\\Train_test_sets\\o03_min_train_.csv', index=False)\n",
    "test_df.to_csv(r'CSV\\Exports\\datasets\\Train_test_sets\\o03_min_test_.csv', index=False)\n",
    "\n",
    "# I'm going to use those numbers as the split point in rapidminer filter operator\n",
    "display(\"The last row of the training set is -> \" + str(train_df.tail(1)[\"row_count\"].values[0]))\n",
    "\n",
    "# Delete dataframes and variables to free memory.\n",
    "del (unique_subject_ids, train_subject_ids_count, subject_ids_in_training, subject_data, train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6713dea-29b8-4af5-a7b9-e9754af0c950",
   "metadata": {},
   "source": [
    "# Split Max to Training - Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a345c38-c675-434e-91e8-f7aec3a07739",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The last row of the training set is -> 40688'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It's already sorted. Just for precaution. Sort by 'subject_id' and 'Time_Zone')\n",
    "max_df = max_df.sort_values(by=['subject_id', 'Time_Zone'])\n",
    "\n",
    "# Calculate the total number of unique subject IDs\n",
    "unique_subject_ids = max_df['subject_id'].nunique()\n",
    "\n",
    "# Calculate the number of unique subject IDs to include in the training set\n",
    "train_subject_ids_count = int(training_percentage * unique_subject_ids)\n",
    "\n",
    "# Initialize variables to track the number of subject IDs included in the training set\n",
    "subject_ids_in_training = 0\n",
    "\n",
    "# Initialize empty DataFrames for the training and test sets\n",
    "train_df = max_df.iloc[0:0].copy()\n",
    "test_df = max_df.iloc[0:0].copy()\n",
    "\n",
    "# Iterate through the sorted DataFrame\n",
    "for subject_id, subject_data in max_df.groupby('subject_id'):\n",
    "    if subject_ids_in_training < train_subject_ids_count:\n",
    "        # Add this subject's data to the training set\n",
    "        train_df = pd.concat([train_df, subject_data], ignore_index=True)\n",
    "        subject_ids_in_training += 1\n",
    "    else:\n",
    "        # Add this subject's data to the test set\n",
    "        test_df = pd.concat([test_df, subject_data], ignore_index=True)\n",
    "\n",
    "# Export the merged DataFrame to a CSV file\n",
    "train_df.to_csv(r'CSV\\Exports\\datasets\\Train_test_sets\\o04_max_train_.csv', index=False)\n",
    "test_df.to_csv(r'CSV\\Exports\\datasets\\Train_test_sets\\o04_max_test_.csv', index=False)\n",
    "\n",
    "# I'm going to use those numbers as the split point in rapidminer filter operator\n",
    "display(\"The last row of the training set is -> \" + str(train_df.tail(1)[\"row_count\"].values[0]))\n",
    "\n",
    "# Delete dataframes and variables to free memory.\n",
    "del (unique_subject_ids, train_subject_ids_count, subject_ids_in_training, subject_data, train_df, test_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
