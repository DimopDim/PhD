{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0521ccf9-6e37-466e-af74-61d89d0fdae4",
   "metadata": {},
   "source": [
    "## ICU Labevents\n",
    "\n",
    "The code below keeps only the labevents rows from patients with disease we have declare to the csv file\n",
    "\n",
    "Export file -> CSV\\Exports\\o04_icu_chartevent.csv\n",
    "\n",
    "------------------\n",
    "\n",
    "I apply the chunk command because the file contains 59,327,830 lines which causes the computer to run out of memory.\n",
    "\n",
    "I have set the size of the chunksize variable it will read to 100,000 rows. I set it according to the available computer memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031b17ae-5882-47af-b361-3e584bcaa1ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Read the first_rows_df CSV file\n",
    "first_stay_df = pd.read_csv('CSV\\Exports\\o03_icu_first_stay.csv')\n",
    "\n",
    "# Read the chartevents CSV file in chunks\n",
    "chunksize = 100000  # Number of rows to read in each chunk\n",
    "labevents_df = pd.read_csv(r\"..\\Datasets\\mimic-iv-2_2\\hosp\\labevents.csv.gz\", low_memory=False, chunksize=chunksize)\n",
    "\n",
    "# Create a list to store the processed chunks\n",
    "processed_chunks = []\n",
    "\n",
    "# Iterate over the chunks and process them\n",
    "for chunk in labevents_df:\n",
    "    # Merge the first_stay_df and chartevents_df DataFrames on the stay_id column\n",
    "    merged_df = pd.merge(first_stay_df, chunk, on='hadm_id')\n",
    "\n",
    "    # Add the processed chunk to the list\n",
    "    processed_chunks.append(merged_df)\n",
    "\n",
    "# Combine the processed chunks into a single DataFrame\n",
    "labevents_df = pd.concat(processed_chunks)\n",
    "\n",
    "# Drop the columns subject_id_y, hadm_id_y\n",
    "labevents_df = labevents_df.drop(columns=['subject_id_y'])\n",
    "\n",
    "# Rename the columns subject_id_x to subject_id and hamd_id_x to hadm_id\n",
    "labevents_df = labevents_df.rename(columns={'subject_id_x': 'subject_id'})\n",
    "\n",
    "# Keeping the rows that contain values in the valuenum\n",
    "labevents_df = labevents_df[labevents_df['valuenum'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb00ca4-762e-48c0-90a2-4f06700375b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Keeping the lab measurements\n",
    "that have been requested during\n",
    "the period stay in the ICU.\n",
    "\"\"\"\n",
    "# Convert 'charttime', 'intime', and 'outtime' columns to datetime objects\n",
    "labevents_df['charttime'] = pd.to_datetime(labevents_df['charttime'])\n",
    "labevents_df['intime'] = pd.to_datetime(labevents_df['intime'])\n",
    "labevents_df['outtime'] = pd.to_datetime(labevents_df['outtime'])\n",
    "\n",
    "# Now 'filtered_df' contains only the rows where 'charttime' is between 'intime' and 'outtime'\n",
    "filtered_df = labevents_df[(labevents_df['charttime'] >= labevents_df['intime']) & (labevents_df['charttime'] <= labevents_df['outtime'])]\n",
    "\n",
    "# Save chartevent dataset to a CSV file\n",
    "filtered_df.to_csv('CSV\\Exports\\o04_icu_labevents.csv', index=False)\n",
    "\n",
    "# Free RAM\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
