{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295ccc90-0aa4-4e1d-8805-16a4ad5e82b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767b7963-a1c8-41e8-bd49-0103625ca6a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create and fill \"Mean\" table (rows and columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7891d938-fd18-4386-8572-87b0215c4d3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the exported for header chartevent CSV file\n",
    "head_df = pd.read_csv('CSV\\Exports\\groupby\\chartevent\\o01_icu_chartevent_grouped_mean.csv')\n",
    "\n",
    "# Read the exported for rows chartevent CSV file\n",
    "row_df = pd.read_csv('CSV\\Exports\\o07_chartevent_rows.csv')\n",
    "\n",
    "# Read the files `d_items.csv`\n",
    "compressed_chart_items_df = r\"..\\Datasets\\mimic-iv-2_2\\icu\\d_items.csv.gz\"\n",
    "compressed_lab_items_df = r\"..\\Datasets\\mimic-iv-2_2\\hosp\\d_labitems.csv.gz\"\n",
    "\n",
    "# Read and pass the compressed CSV file into a DataFrame\n",
    "chart_items_df = pd.read_csv(compressed_chart_items_df, compression='gzip')\n",
    "lab_items_df = pd.read_csv(compressed_lab_items_df, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d86e3a-024d-4baf-9f72-9bb8fb175689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating the concat column as an index\n",
    "from the combination of subject_id,\n",
    "hadm_id and Time_Zone.\n",
    "\"\"\"\n",
    "row_df[\"concat\"] = (row_df[\"subject_id\"].astype(str)\n",
    "                          + row_df[\"hadm_id\"].astype(str)\n",
    "                          + row_df[\"Time_Zone\"].astype(str))\n",
    "    \n",
    "# I define the concat column as the index of the rows\n",
    "row_df = row_df.set_index('concat')\n",
    "\n",
    "\"\"\"\n",
    "Creating the concat column in the table as\n",
    "well which includes the measurements to be\n",
    "the common point between the two tables.\n",
    "\"\"\"\n",
    "head_df[\"concat\"] = (head_df[\"subject_id\"].astype(str)\n",
    "                     + head_df[\"hadm_id\"].astype(str)\n",
    "                     + head_df[\"Time_Zone\"].astype(str))\n",
    "\n",
    "# I define the concat column as the index of the rows\n",
    "head_df = head_df.set_index('concat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc261cd-11d4-449f-93d9-5318c89e8d30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Keeping the row_df unaffected by changes.\n",
    "new_df = row_df\n",
    "\n",
    "# Suppress the specific warning.\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# Filling the table\n",
    "for row in head_df.itertuples():\n",
    "    con = row.Index\n",
    "    item = row.itemid\n",
    "    value = row.Mean_Chart\n",
    "    new_df.at['{}'.format(con), '{}'.format(item)] = value\n",
    "    \n",
    "# Removing rows that contains no values\n",
    "new_df = new_df.dropna(subset=row_df.columns[3:], how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6bb8f4-6ce7-4f55-a3f9-4fe83b220dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combining the elements from charts and labs to update my table header\n",
    "\n",
    "# Merge values in chart data for header\n",
    "chart_items_df[\"header\"] = (chart_items_df[\"label\"].astype(str)\n",
    "                           + \" (\"\n",
    "                           + chart_items_df[\"unitname\"].astype(str)\n",
    "                           + \")\"\n",
    "                           + \" - Mean\")\n",
    "\n",
    "# Merge values in lab data for header\n",
    "lab_items_df[\"header\"] = (lab_items_df[\"label\"].astype(str)\n",
    "                          + \" - Mean\")\n",
    "\n",
    "# Keeping only the two specific columns\n",
    "chart_items_df = chart_items_df[[\"itemid\", \"header\"]]\n",
    "lab_items_df = lab_items_df[[\"itemid\", \"header\"]]\n",
    "\n",
    "# Combine them.\n",
    "combined_df = pd.concat([lab_items_df, chart_items_df], ignore_index=True)\n",
    "\n",
    "# Remove the \"(nan)\" substring from the \"header\" column\n",
    "combined_df['header'] = combined_df['header'].str.replace('(nan)', '').str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11bcce9-182f-42bb-910e-e7ca5ef18974",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change header numbers with observation names\n",
    "\n",
    "# Keeping the row_df unaffected by changes.\n",
    "temp_df = new_df\n",
    "\n",
    "# Create a dictionary mapping item IDs to headers from combined_df\n",
    "header_mapping = dict(zip(combined_df['itemid'].astype(str), combined_df['header']))\n",
    "\n",
    "# Replace the numeric headers in test_df with the corresponding headers\n",
    "temp_df.columns = temp_df.columns.map(header_mapping)\n",
    "\n",
    "# Rename the first three columns directly\n",
    "temp_df.columns.values[0:3] = [\"subject_id\", \"hadm_id\", \"Time_Zone\"]\n",
    "\n",
    "# Export the merged DataFrame to a CSV file\n",
    "temp_df.to_csv('CSV\\Exports\\datasets\\Temp\\o01_mean_table.csv', index=False)\n",
    "\n",
    "# Free RAM\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfd994f-d1c3-423a-92d6-00d89c6eb798",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create and fill \"Median\" table (rows and columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c4fe5d-1522-4e04-9b7b-3d09dd176f86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the exported for header chartevent CSV file\n",
    "head_df = pd.read_csv('CSV\\Exports\\groupby\\chartevent\\o02_icu_chartevent_grouped_median.csv')\n",
    "\n",
    "# Read the exported for rows chartevent CSV file\n",
    "row_df = pd.read_csv('CSV\\Exports\\o07_chartevent_rows.csv')\n",
    "\n",
    "# Read the files `d_items.csv`\n",
    "compressed_chart_items_df = r\"..\\Datasets\\mimic-iv-2_2\\icu\\d_items.csv.gz\"\n",
    "compressed_lab_items_df = r\"..\\Datasets\\mimic-iv-2_2\\hosp\\d_labitems.csv.gz\"\n",
    "\n",
    "# Read and pass the compressed CSV file into a DataFrame\n",
    "chart_items_df = pd.read_csv(compressed_chart_items_df, compression='gzip')\n",
    "lab_items_df = pd.read_csv(compressed_lab_items_df, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1c4c35-18e3-4b82-b8e2-73d3c2dfd861",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating the concat column as an index\n",
    "from the combination of subject_id,\n",
    "hadm_id and Time_Zone.\n",
    "\"\"\"\n",
    "row_df[\"concat\"] = (row_df[\"subject_id\"].astype(str)\n",
    "                          + row_df[\"hadm_id\"].astype(str)\n",
    "                          + row_df[\"Time_Zone\"].astype(str))\n",
    "    \n",
    "# Define the concat column as the index of the rows\n",
    "row_df = row_df.set_index('concat')\n",
    "\n",
    "\"\"\"\n",
    "Creating the concat column in the table as\n",
    "well which includes the measurements to be\n",
    "the common point between the two tables.\n",
    "\"\"\"\n",
    "head_df[\"concat\"] = (head_df[\"subject_id\"].astype(str)\n",
    "                     + head_df[\"hadm_id\"].astype(str)\n",
    "                     + head_df[\"Time_Zone\"].astype(str))\n",
    "\n",
    "# Define the concat column as the index of the rows\n",
    "head_df = head_df.set_index('concat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9117ac0a-7c0c-4f4a-afe4-89e3f1b9e4bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Keeping the row_df unaffected by changes.\n",
    "new_df = row_df\n",
    "\n",
    "# Suppress the specific warning.\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# Filling the table\n",
    "for row in head_df.itertuples():\n",
    "    con = row.Index\n",
    "    item = row.itemid\n",
    "    value = row.Median_Chart\n",
    "    new_df.at['{}'.format(con), '{}'.format(item)] = value\n",
    "    \n",
    "# Removing rows that contains no values\n",
    "new_df = new_df.dropna(subset=row_df.columns[3:], how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62653fd4-488e-42bd-a697-6e2b48d763fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combining the elements from charts and labs to update my table header\n",
    "\n",
    "# Merge values in chart data for header\n",
    "chart_items_df[\"header\"] = (chart_items_df[\"label\"].astype(str)\n",
    "                           + \" (\"\n",
    "                           + chart_items_df[\"unitname\"].astype(str)\n",
    "                           + \")\"\n",
    "                           + \" - Median\")\n",
    "\n",
    "# Merge values in lab data for header\n",
    "lab_items_df[\"header\"] = (lab_items_df[\"label\"].astype(str)\n",
    "                          + \" - Median\")\n",
    "\n",
    "# Keeping only the two specific columns\n",
    "chart_items_df = chart_items_df[[\"itemid\", \"header\"]]\n",
    "lab_items_df = lab_items_df[[\"itemid\", \"header\"]]\n",
    "\n",
    "# Combine them.\n",
    "combined_df = pd.concat([lab_items_df, chart_items_df], ignore_index=True)\n",
    "\n",
    "# Remove the \"(nan)\" substring from the \"header\" column\n",
    "combined_df['header'] = combined_df['header'].str.replace('(nan)', '').str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d83a8d2-561a-4eed-9c71-fae0aa16d5f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change header numbers with observation names\n",
    "\n",
    "# Keeping the row_df unaffected by changes.\n",
    "temp_df = new_df\n",
    "\n",
    "# Create a dictionary mapping item IDs to headers from combined_df\n",
    "header_mapping = dict(zip(combined_df['itemid'].astype(str), combined_df['header']))\n",
    "\n",
    "# Replace the numeric headers in test_df with the corresponding headers\n",
    "temp_df.columns = temp_df.columns.map(header_mapping)\n",
    "\n",
    "# Rename the first three columns directly\n",
    "temp_df.columns.values[0:3] = [\"subject_id\", \"hadm_id\", \"Time_Zone\"]\n",
    "\n",
    "# Export the merged DataFrame to a CSV file\n",
    "temp_df.to_csv('CSV\\Exports\\datasets\\Temp\\o02_median_table.csv', index=False)\n",
    "\n",
    "# Free RAM\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd98c51d-bd46-4338-bf7b-ff36bebeb998",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create and fill \"Min\" table (rows and columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401a8498-264b-4bcd-a4d7-500bb3768862",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the exported for header chartevent CSV file\n",
    "head_df = pd.read_csv('CSV\\Exports\\groupby\\chartevent\\o03_icu_chartevent_grouped_min.csv')\n",
    "\n",
    "# Read the exported for rows chartevent CSV file\n",
    "row_df = pd.read_csv('CSV\\Exports\\o07_chartevent_rows.csv')\n",
    "\n",
    "# Read the files `d_items.csv`\n",
    "compressed_chart_items_df = r\"..\\Datasets\\mimic-iv-2_2\\icu\\d_items.csv.gz\"\n",
    "compressed_lab_items_df = r\"..\\Datasets\\mimic-iv-2_2\\hosp\\d_labitems.csv.gz\"\n",
    "\n",
    "# Read and pass the compressed CSV file into a DataFrame\n",
    "chart_items_df = pd.read_csv(compressed_chart_items_df, compression='gzip')\n",
    "lab_items_df = pd.read_csv(compressed_lab_items_df, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e19faac-bdc2-4201-9147-28bd60571916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating the concat column as an index\n",
    "from the combination of subject_id,\n",
    "hadm_id and Time_Zone.\n",
    "\"\"\"\n",
    "row_df[\"concat\"] = (row_df[\"subject_id\"].astype(str)\n",
    "                          + row_df[\"hadm_id\"].astype(str)\n",
    "                          + row_df[\"Time_Zone\"].astype(str))\n",
    "    \n",
    "# DSefine the concat column as the index of the rows\n",
    "row_df = row_df.set_index('concat')\n",
    "\n",
    "\"\"\"\n",
    "Creating the concat column in the table as\n",
    "well which includes the measurements to be\n",
    "the common point between the two tables.\n",
    "\"\"\"\n",
    "head_df[\"concat\"] = (head_df[\"subject_id\"].astype(str)\n",
    "                     + head_df[\"hadm_id\"].astype(str)\n",
    "                     + head_df[\"Time_Zone\"].astype(str))\n",
    "\n",
    "# Define the concat column as the index of the rows\n",
    "head_df = head_df.set_index('concat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54602fce-db66-470f-bb95-61a42c077f87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Keeping the row_df unaffected by changes.\n",
    "new_df = row_df\n",
    "\n",
    "# Suppress the specific warning.\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# Filling the table\n",
    "for row in head_df.itertuples():\n",
    "    con = row.Index\n",
    "    item = row.itemid\n",
    "    value = row.Min_Chart\n",
    "    new_df.at['{}'.format(con), '{}'.format(item)] = value\n",
    "    \n",
    "# Removing rows that contains no values\n",
    "new_df = new_df.dropna(subset=row_df.columns[3:], how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa529031-67be-46a4-a745-8d4c5a9ca18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the elements from charts and labs to update my table header\n",
    "\n",
    "# Merge values in chart data for header\n",
    "chart_items_df[\"header\"] = (chart_items_df[\"label\"].astype(str)\n",
    "                           + \" (\"\n",
    "                           + chart_items_df[\"unitname\"].astype(str)\n",
    "                           + \")\"\n",
    "                           + \" - Min\")\n",
    "\n",
    "# Merge values in lab data for header\n",
    "lab_items_df[\"header\"] = (lab_items_df[\"label\"].astype(str)\n",
    "                          + \" - Min\")\n",
    "\n",
    "# Keeping only the two specific columns\n",
    "chart_items_df = chart_items_df[[\"itemid\", \"header\"]]\n",
    "lab_items_df = lab_items_df[[\"itemid\", \"header\"]]\n",
    "\n",
    "# Combine them.\n",
    "combined_df = pd.concat([lab_items_df, chart_items_df], ignore_index=True)\n",
    "\n",
    "# Remove the \"(nan)\" substring from the \"header\" column\n",
    "combined_df['header'] = combined_df['header'].str.replace('(nan)', '').str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d11455-22f2-44e8-a91f-aff274b78e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change header numbers with observation names\n",
    "\n",
    "# Keeping the row_df unaffected by changes.\n",
    "temp_df = new_df\n",
    "\n",
    "# Create a dictionary mapping item IDs to headers from combined_df\n",
    "header_mapping = dict(zip(combined_df['itemid'].astype(str), combined_df['header']))\n",
    "\n",
    "# Replace the numeric headers in test_df with the corresponding headers\n",
    "temp_df.columns = temp_df.columns.map(header_mapping)\n",
    "\n",
    "# Rename the first three columns directly\n",
    "temp_df.columns.values[0:3] = [\"subject_id\", \"hadm_id\", \"Time_Zone\"]\n",
    "\n",
    "# Export the merged DataFrame to a CSV file\n",
    "temp_df.to_csv('CSV\\Exports\\datasets\\Temp\\o03_min_table.csv', index=False)\n",
    "\n",
    "# Free RAM\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e8060f-7fbf-418c-9dfd-e1f95443fc32",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create and fill \"Max\" table (rows and columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0e24f4-2965-45c4-86f3-85b67a8d8b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the exported for header chartevent CSV file\n",
    "head_df = pd.read_csv('CSV\\Exports\\groupby\\chartevent\\o04_icu_chartevent_grouped_max.csv')\n",
    "\n",
    "# Read the exported for rows chartevent CSV file\n",
    "row_df = pd.read_csv('CSV\\Exports\\o07_chartevent_rows.csv')\n",
    "\n",
    "# Read the files `d_items.csv`\n",
    "compressed_chart_items_df = r\"..\\Datasets\\mimic-iv-2_2\\icu\\d_items.csv.gz\"\n",
    "compressed_lab_items_df = r\"..\\Datasets\\mimic-iv-2_2\\hosp\\d_labitems.csv.gz\"\n",
    "\n",
    "# Read and pass the compressed CSV file into a DataFrame\n",
    "chart_items_df = pd.read_csv(compressed_chart_items_df, compression='gzip')\n",
    "lab_items_df = pd.read_csv(compressed_lab_items_df, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f924ae-326f-449b-9a09-88f69bbb9b84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating the concat column as an index\n",
    "from the combination of subject_id,\n",
    "hadm_id and Time_Zone.\n",
    "\"\"\"\n",
    "row_df[\"concat\"] = (row_df[\"subject_id\"].astype(str)\n",
    "                          + row_df[\"hadm_id\"].astype(str)\n",
    "                          + row_df[\"Time_Zone\"].astype(str))\n",
    "    \n",
    "# Define the concat column as the index of the rows\n",
    "row_df = row_df.set_index('concat')\n",
    "\n",
    "\"\"\"\n",
    "Creating the concat column in the table as\n",
    "well which includes the measurements to be\n",
    "the common point between the two tables.\n",
    "\"\"\"\n",
    "head_df[\"concat\"] = (head_df[\"subject_id\"].astype(str)\n",
    "                     + head_df[\"hadm_id\"].astype(str)\n",
    "                     + head_df[\"Time_Zone\"].astype(str))\n",
    "\n",
    "# Define the concat column as the index of the rows\n",
    "head_df = head_df.set_index('concat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6123bdf3-7897-4d1c-a83f-2400b3beca2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Keeping to keep the row_df unaffected by changes.\n",
    "new_df = row_df\n",
    "\n",
    "# Suppress the specific warning.\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# Filling in the table\n",
    "for row in head_df.itertuples():\n",
    "    con = row.Index\n",
    "    item = row.itemid\n",
    "    value = row.Max_Chart\n",
    "    new_df.at['{}'.format(con), '{}'.format(item)] = value\n",
    "    \n",
    "# Removing rows that contains no values\n",
    "new_df = new_df.dropna(subset=row_df.columns[3:], how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9246008a-a27b-474a-aa63-9a3794cdd34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the elements from charts and labs to update my table header\n",
    "\n",
    "# Merge values in chart data for header\n",
    "chart_items_df[\"header\"] = (chart_items_df[\"label\"].astype(str)\n",
    "                           + \" (\"\n",
    "                           + chart_items_df[\"unitname\"].astype(str)\n",
    "                           + \")\"\n",
    "                           + \" - Max\")\n",
    "\n",
    "# Merge values in lab data for header\n",
    "lab_items_df[\"header\"] = (lab_items_df[\"label\"].astype(str)\n",
    "                          + \" - Max\")\n",
    "\n",
    "# Keeping only the two specific columns\n",
    "chart_items_df = chart_items_df[[\"itemid\", \"header\"]]\n",
    "lab_items_df = lab_items_df[[\"itemid\", \"header\"]]\n",
    "\n",
    "# Combine them.\n",
    "combined_df = pd.concat([lab_items_df, chart_items_df], ignore_index=True)\n",
    "\n",
    "# Remove the \"(nan)\" substring from the \"header\" column\n",
    "combined_df['header'] = combined_df['header'].str.replace('(nan)', '').str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8fe1eb-aa90-41a4-92a4-eb9a8e0dc458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change header numbers with observation names\n",
    "\n",
    "# Keeping the row_df unaffected by changes.\n",
    "temp_df = new_df\n",
    "\n",
    "# Create a dictionary mapping item IDs to headers from combined_df\n",
    "header_mapping = dict(zip(combined_df['itemid'].astype(str), combined_df['header']))\n",
    "\n",
    "# Replace the numeric headers in test_df with the corresponding headers\n",
    "temp_df.columns = temp_df.columns.map(header_mapping)\n",
    "\n",
    "# Rename the first three columns directly\n",
    "temp_df.columns.values[0:3] = [\"subject_id\", \"hadm_id\", \"Time_Zone\"]\n",
    "\n",
    "# Export the merged DataFrame to a CSV file\n",
    "temp_df.to_csv('CSV\\Exports\\datasets\\Temp\\o04_max_table.csv', index=False)\n",
    "\n",
    "# Free RAM\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
