{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf33bd9a-f0f9-4c58-8081-c5022f031ad4",
   "metadata": {},
   "source": [
    "## ICU Chartevents\n",
    "\n",
    "The code below keeps only the chartevents rows from patients with disease we have declare to the csv file and merge them with the file o03_icu_first_stay.csv\n",
    "\n",
    "Export file -> CSV\\Exports\\o04_icu_chartevent.csv\n",
    "\n",
    "------------------\n",
    "\n",
    "I apply the chunk command because the file contains 313,645,063 lines which causes the computer to run out of memory.\n",
    "\n",
    "I have set the size of the chunksize variable it will read to 100,000 rows. I set it according to the available computer memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ef3549-50d8-463c-a107-b18b8b95d638",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "#Read the first_rows_df CSV file\n",
    "first_stay_df = pd.read_csv('CSV\\Exports\\o03_icu_first_stay.csv')\n",
    "\n",
    "# Read the chartevents CSV file in chunks\n",
    "chunksize = 100000  # Number of rows to read in each chunk\n",
    "chartevents_df = pd.read_csv(r\"..\\Datasets\\mimic-iv-2_2\\icu\\chartevents.csv.gz\", chunksize=chunksize)\n",
    "\n",
    "# Create a list to store the processed chunks\n",
    "processed_chunks = []\n",
    "\n",
    "# Iterate over the chunks and process them\n",
    "for chunk in chartevents_df:\n",
    "    # Merge the first_stay_df and chartevents_df DataFrames on the stay_id column\n",
    "    merged_df = pd.merge(first_stay_df, chunk, on='stay_id')\n",
    "\n",
    "    # Add the processed chunk to the list\n",
    "    processed_chunks.append(merged_df)\n",
    "\n",
    "# Combine the processed chunks into a single DataFrame\n",
    "chartevent_df = pd.concat(processed_chunks)\n",
    "\n",
    "# Drop the columns subject_id_y, hadm_id_y\n",
    "chartevent_df = chartevent_df.drop(columns=['subject_id_y', 'hadm_id_y'])\n",
    "\n",
    "# Rename the columns subject_id_x to subject_id and hamd_id_x to hadm_id\n",
    "chartevent_df = chartevent_df.rename(columns={'subject_id_x': 'subject_id', 'hadm_id_x': 'hadm_id'})\n",
    "\n",
    "# Keeping the rows that contain values in the valuenum\n",
    "chartevent_df = chartevent_df[chartevent_df['valuenum'].notna()]\n",
    "\n",
    "# Save chartevent dataset to a CSV file\n",
    "chartevent_df.to_csv('CSV\\Exports\\o04_icu_chartevent.csv', index=False)\n",
    "\n",
    "# Free RAM\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
