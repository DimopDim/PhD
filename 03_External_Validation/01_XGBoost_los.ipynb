{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6243b02-165d-496a-a198-f00704a71eb6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Imports | Reads | Filter Patients (Phase 01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6671463d-f9c0-4542-b28c-eec0dfb36e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, ParameterGrid, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error, mean_squared_log_error, r2_score\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor # Regression Impute\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Input\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a182eba9-001e-43e2-b928-7bdd96cf667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read MIMICs CSV file\n",
    "mimic_df = pd.read_csv(\"CSV\\\\exports\\\\final\\\\mimic_mean_median_min_max_final.csv\")\n",
    "\n",
    "# Read eICUs CSV file\n",
    "eicu_df = pd.read_csv(\"CSV\\\\exports\\\\final\\\\eicu_mean_median_min_max_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abae581b-694b-43c7-9805-90856381db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "day = 10\n",
    "\n",
    "# Filter icu stay less than 10 days\n",
    "mimic_df = mimic_df[mimic_df['los'] < day]\n",
    "\n",
    "# Filter icu stay less than 10 days\n",
    "eicu_df = eicu_df[eicu_df['los'] < day]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bc6cae-2821-43c1-a6b1-04c79b38273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Time Zone\n",
    "\n",
    "#time_zone = 16\n",
    "#mimic_df = mimic_df[mimic_df['Time_Zone'] == time_zone]\n",
    "#eicu_df = eicu_df[eicu_df['Time_Zone'] == time_zone]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894f6245-e142-45de-971e-fb52f9a1ffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I'm gonna concat and split the mimic and icu\n",
    "at this point. I must create the same columns\n",
    "from the tranformation of categorical data.\n",
    "\"\"\"\n",
    "row_count = mimic_df.shape[0]\n",
    "print(f\"Row count: {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9462d7a8-d964-43b5-9e61-6064e02f0ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat dataframes\n",
    "df_combined = pd.concat([mimic_df, eicu_df], ignore_index=True)\n",
    "\n",
    "# Find all categorical columns in mimic\n",
    "categorical_columns = df_combined.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Apply one-hot encoding to all categorical columns\n",
    "df_encoded = pd.get_dummies(df_combined, columns=categorical_columns)\n",
    "\n",
    "# Split the concatenate dataframe\n",
    "mimic_df = df_encoded.iloc[:row_count, :]\n",
    "eicu_df = df_encoded.iloc[row_count:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1786ba0-60a9-4593-87be-689ee23fffe2",
   "metadata": {},
   "source": [
    "# Split Training - Validation - Test Set (Phase 02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c308615a-2615-468c-a99f-a0b2bf265697",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_test_val_perc = 0.2\n",
    "split_between_test_val_perc = 0.5\n",
    "\n",
    "# Group data by subject_id and hadm_id\n",
    "grouped_df = mimic_df.groupby(['subject_id', 'hadm_id'])\n",
    "\n",
    "# Get a new dataframe with one row per patient (subject_id, hadm_id) pair\n",
    "patient_df = grouped_df['hospital_expire_flag'].first().reset_index()\n",
    "\n",
    "# Split the patient_df into training (80%), validation (10%), and test (10%) while keeping the ratio of hospital_expired_flag\n",
    "train, temp = train_test_split(patient_df, test_size=total_test_val_perc, stratify=patient_df['hospital_expire_flag'], random_state=42)\n",
    "val, test = train_test_split(temp, test_size=split_between_test_val_perc, stratify=temp['hospital_expire_flag'], random_state=42)\n",
    "\n",
    "# Step 4: Merge back with the original df to get the rows for each patient in the splits\n",
    "train_df = mimic_df.merge(train[['subject_id', 'hadm_id']], on=['subject_id', 'hadm_id'], how='inner')\n",
    "val_df = mimic_df.merge(val[['subject_id', 'hadm_id']], on=['subject_id', 'hadm_id'], how='inner')\n",
    "test_df = mimic_df.merge(test[['subject_id', 'hadm_id']], on=['subject_id', 'hadm_id'], how='inner')\n",
    "\n",
    "# Check the sizes of the splits\n",
    "print(f'Training set size: {train_df.shape[0]}')\n",
    "print(f'Validation set size: {val_df.shape[0]}')\n",
    "print(f'Test set size: {test_df.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47462f19-6295-4cb1-a8f7-64b8bd104609",
   "metadata": {},
   "source": [
    "# Check ratio and unique patients between sets (Phase 03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729ed3bc-b7ae-48fe-892f-66b6f814c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count on Training set survive and non-survive\n",
    "survival_counts = train_df['hospital_expire_flag'].value_counts()\n",
    "temp_survive = survival_counts.get(0, 0)/16\n",
    "temp_non_survive = survival_counts.get(1, 0)/16\n",
    "\n",
    "# Display the results\n",
    "print(f'Train Set')\n",
    "print(f'Survive: {temp_survive}')\n",
    "print(f'Non-survive: {temp_non_survive}')\n",
    "\n",
    "# Check if temp_non_survive is not zero to avoid division by zero\n",
    "if temp_non_survive != 0:\n",
    "    ratio = temp_survive / temp_non_survive\n",
    "else:\n",
    "    ratio = float('inf')  # Set ratio to infinity if there are no non-survivors\n",
    "\n",
    "# Display the ratio\n",
    "print(f'Ratio Train Set: {ratio:.2f}:1')\n",
    "\n",
    "\"\"\"----------------------------\"\"\"\n",
    "\n",
    "# Count on validation set survive and non-survive\n",
    "survival_counts = val_df['hospital_expire_flag'].value_counts()\n",
    "temp_survive = survival_counts.get(0, 0)/16\n",
    "temp_non_survive = survival_counts.get(1, 0)/16\n",
    "\n",
    "# Display the results\n",
    "print(f'\\nValidation Set')\n",
    "print(f'Survive: {temp_survive}')\n",
    "print(f'Non-survive: {temp_non_survive}')\n",
    "\n",
    "# Check if temp_non_survive is not zero to avoid division by zero\n",
    "if temp_non_survive != 0:\n",
    "    ratio = temp_survive / temp_non_survive\n",
    "else:\n",
    "    ratio = float('inf')  # Set ratio to infinity if there are no non-survivors\n",
    "\n",
    "# Display the ratio\n",
    "print(f'Ratio Train Set: {ratio:.2f}:1')\n",
    "\n",
    "\"\"\"----------------------------\"\"\"\n",
    "\n",
    "# Count on validation set survive and non-survive\n",
    "survival_counts = test_df['hospital_expire_flag'].value_counts()\n",
    "temp_survive = survival_counts.get(0, 0)/16\n",
    "temp_non_survive = survival_counts.get(1, 0)/16\n",
    "\n",
    "# Display the results\n",
    "print(f'\\nTest Set')\n",
    "print(f'Survive: {temp_survive}')\n",
    "print(f'Non-survive: {temp_non_survive}')\n",
    "\n",
    "# Check if temp_non_survive is not zero to avoid division by zero\n",
    "if temp_non_survive != 0:\n",
    "    ratio = temp_survive / temp_non_survive\n",
    "else:\n",
    "    ratio = float('inf')  # Set ratio to infinity if there are no non-survivors\n",
    "\n",
    "# Display the ratio\n",
    "print(f'Ratio Train Set: {ratio:.2f}:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73205561-9bcc-42fe-acc4-8bcd1616d9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mine unique subject_id from sets\n",
    "train_subjects = set(train_df['subject_id'].unique())\n",
    "val_subjects = set(val_df['subject_id'].unique())\n",
    "test_subjects = set(test_df['subject_id'].unique())\n",
    "\n",
    "# Check if there are overlaping subject_id\n",
    "train_val_overlap = train_subjects.intersection(val_subjects)\n",
    "train_test_overlap = train_subjects.intersection(test_subjects)\n",
    "val_test_overlap = val_subjects.intersection(test_subjects)\n",
    "\n",
    "# Display the results\n",
    "print(f'Overlap between training and validation sets: {len(train_val_overlap)}')\n",
    "print(f'Overlap between training and test sets: {len(train_test_overlap)}')\n",
    "print(f'Overlap between validation and test sets: {len(val_test_overlap)}')\n",
    "\n",
    "# print overlaping\n",
    "if train_val_overlap:\n",
    "    print(f'Subjects in both training and validation: {train_val_overlap}')\n",
    "if train_test_overlap:\n",
    "    print(f'Subjects in both training and test: {train_test_overlap}')\n",
    "if val_test_overlap:\n",
    "    print(f'Subjects in both validation and test: {val_test_overlap}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d473a75a-86eb-4dac-be9a-b73cf80b111b",
   "metadata": {},
   "source": [
    "# Split label from Train - Validation - Test Sets (Phase 04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee62e244-e475-4222-802b-57d374b63c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# External validation from eICU\n",
    "X_external = eicu_df.drop(columns=['hospital_expire_flag', 'los', 'subject_id', 'hadm_id', 'row_count', 'Time_Zone'])\n",
    "y_external = eicu_df['los']\n",
    "\n",
    "# Separate features and target for the training, validation, and test sets\n",
    "X_train = train_df.drop(columns=['hospital_expire_flag', 'los', 'subject_id', 'hadm_id', 'row_count', 'Time_Zone'])\n",
    "y_train = train_df['los']\n",
    "\n",
    "X_validate = val_df.drop(columns=['hospital_expire_flag', 'los', 'subject_id', 'hadm_id', 'row_count', 'Time_Zone'])\n",
    "y_validate = val_df['los']\n",
    "\n",
    "X_test = test_df.drop(columns=['hospital_expire_flag', 'los', 'subject_id', 'hadm_id', 'row_count', 'Time_Zone'])\n",
    "y_test = test_df['los']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b069035-3469-4e8c-8849-9225e0fad52e",
   "metadata": {},
   "source": [
    "# Load Train - Validation - Test & External Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0de75c-f5da-475a-86ec-fad496d7c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define subfolder\n",
    "subfolder = \"o2_interpolation_impute\"\n",
    "\n",
    "# Load CSV files into corresponding variables\n",
    "X_external = pd.read_csv(f\"CSV/exports/impute/{subfolder}/X_external.csv\")\n",
    "y_external = pd.read_csv(f\"CSV/exports/impute/{subfolder}/y_external.csv\")\n",
    "X_train = pd.read_csv(f\"CSV/exports/impute/{subfolder}/X_train.csv\")\n",
    "y_train = pd.read_csv(f\"CSV/exports/impute/{subfolder}/y_train.csv\")\n",
    "X_validate = pd.read_csv(f\"CSV/exports/impute/{subfolder}/X_validate.csv\")\n",
    "y_validate = pd.read_csv(f\"CSV/exports/impute/{subfolder}/y_validate.csv\")\n",
    "X_test = pd.read_csv(f\"CSV/exports/impute/{subfolder}/X_test.csv\")\n",
    "y_test = pd.read_csv(f\"CSV/exports/impute/{subfolder}/y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75bc50d-e5e2-44a3-9eb9-57a3adcdb72b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Fill Missing Values by Mean (Phase 05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa326f0e-f29f-44c5-8cc3-13cc5551b0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an imputer object with mean strategy\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Fit the imputer on X_train and transform the training set\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train_imputed, columns=X_train.columns)\n",
    "\n",
    "# Transform the validation, test, and external sets using the same imputer\n",
    "X_validate_imputed = imputer.transform(X_validate)\n",
    "X_validate = pd.DataFrame(X_validate_imputed, columns=X_validate.columns)\n",
    "\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test_imputed, columns=X_test.columns)\n",
    "\n",
    "X_external_imputed = imputer.transform(X_external)\n",
    "X_external = pd.DataFrame(X_external_imputed, columns=X_external.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59484a45-6411-421b-99db-fe39c8fc5ff0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Fill Missing Values by KNN (Phase 05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defbc94e-af36-4176-aa45-7f91932e350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KNN imputer object\n",
    "knn_imputer = KNNImputer(n_neighbors=5, verbose=2)\n",
    "\n",
    "# Fit the imputer on X_train and transform the training set\n",
    "X_train_imputed = knn_imputer.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train_imputed, columns=X_train.columns)\n",
    "\n",
    "# Transform the validation, test, and external sets using the same imputer\n",
    "X_validate_imputed = knn_imputer.transform(X_validate)\n",
    "X_validate = pd.DataFrame(X_validate_imputed, columns=X_validate.columns)\n",
    "\n",
    "X_test_imputed = knn_imputer.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test_imputed, columns=X_test.columns)\n",
    "\n",
    "X_external_imputed = knn_imputer.transform(X_external)\n",
    "X_external = pd.DataFrame(X_external_imputed, columns=X_external.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa0f63-07cd-433d-a8cf-443c4c9fc982",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Fill Missing Values by Regression Imputation (Phase 05)\n",
    "## Save the datasets and retrieve them for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c647bb-2c66-4ab3-9127-0b78c1a1427e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I should change the estimator and I'm gonna execute\n",
    "scale and normalization first.\n",
    "\n",
    "In the defult settings there is a big chagnes between\n",
    "round 1 and round 3. The number of imputation makes\n",
    "significant imcreasement. We expect from round to round\n",
    "the change to be smaller. This behavior of causing the\n",
    "model to make massive adjustments to certain predictions\n",
    "shows that maybe one or more features have high variance\n",
    "or outliers, thats why I'm gonna execute before imputation\n",
    "scale and normalization.\n",
    "\"\"\"\n",
    "\n",
    "# Change estimator\n",
    "#iter_imputer = IterativeImputer(estimator=RandomForestRegressor(), max_iter=20, random_state=0, verbose=2)\n",
    "\n",
    "#iter_imputer = IterativeImputer(max_iter=10, tol=1e-3, random_state=0, verbose=2)\n",
    "\n",
    "iter_imputer = IterativeImputer(max_iter=20, random_state=0, verbose=2)\n",
    "\n",
    "# Fit the imputer on X_train and transform the training set\n",
    "X_train_imputed = iter_imputer.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train_imputed, columns=X_train.columns)\n",
    "\n",
    "# Transform the validation, test, and external sets using the same imputer\n",
    "X_validate_imputed = iter_imputer.transform(X_validate)\n",
    "X_validate = pd.DataFrame(X_validate_imputed, columns=X_validate.columns)\n",
    "\n",
    "X_test_imputed = iter_imputer.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test_imputed, columns=X_test.columns)\n",
    "\n",
    "X_external_imputed = iter_imputer.transform(X_external)\n",
    "X_external = pd.DataFrame(X_external_imputed, columns=X_external.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab459737-2116-45fd-817b-7062b5618b9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Fill Missing Values Interpolation Imputation (Phase 05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a2135a-13a7-4f2b-acad-a2d7a29cdcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the interpolation method (you can use 'linear', 'polynomial', 'spline', etc.)\n",
    "interpolation_method = 'linear'\n",
    "\n",
    "# Interpolate missing values in X_train\n",
    "X_train = X_train.interpolate(method=interpolation_method, axis=0, limit_direction='both')\n",
    "\n",
    "# Interpolate missing values in X_validate\n",
    "X_validate = X_validate.interpolate(method=interpolation_method, axis=0, limit_direction='both')\n",
    "\n",
    "# Interpolate missing values in X_test\n",
    "X_test = X_test.interpolate(method=interpolation_method, axis=0, limit_direction='both')\n",
    "\n",
    "# Interpolate missing values in X_external\n",
    "X_external = X_external.interpolate(method=interpolation_method, axis=0, limit_direction='both')\n",
    "\n",
    "# Resetting indexes after interpolation to avoid misalignments\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_validate = X_validate.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "X_external = X_external.reset_index(drop=True)\n",
    "\n",
    "# Optionally, you can check if there are still any missing values\n",
    "print(f\"Missing values in X_train: {X_train.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in X_validate: {X_validate.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in X_test: {X_test.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in X_external: {X_external.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ea1845-e2ed-4c86-bdd8-bc7cf8ffe8e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Fill Missing Values by ANN (Phase 05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3216eb-3d59-4548-a39c-482e782e2778",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Feedforward MLP (Multilayer Perceptron)\n",
    "\"\"\"\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define a function to impute missing values for any dataset independently\n",
    "def impute_missing_values_ann(X, dataset_name):\n",
    "    print(f\"Imputing missing values for {dataset_name}\")\n",
    "    \n",
    "    # Step 1: Identify columns with missing values\n",
    "    missing_columns = X.columns[X.isnull().any()].tolist()\n",
    "    print(f\"Columns with missing values: {missing_columns}\")\n",
    "\n",
    "    # Step 2: Loop through each column with missing values and build an ANN to predict missing values\n",
    "    for col in missing_columns:\n",
    "        print(f\"Filling missing values in column: {col}\")\n",
    "\n",
    "        # Separate rows with and without missing values in the current column\n",
    "        missing_rows = X[X[col].isnull()]\n",
    "        non_missing_rows = X[~X[col].isnull()]\n",
    "\n",
    "        # Skip the column if no data is available for training\n",
    "        if len(missing_rows) == 0 or len(non_missing_rows) == 0:\n",
    "            print(f\"Skipping {col}, insufficient data\")\n",
    "            continue\n",
    "\n",
    "        # Separate features and target for non-missing rows\n",
    "        X_non_missing = non_missing_rows.drop(columns=missing_columns).copy()  # Exclude other missing columns from features\n",
    "        y_non_missing = non_missing_rows[col].copy()  # Target is the column we're filling\n",
    "\n",
    "        # Features for the rows with missing values (we'll predict the column for these rows)\n",
    "        X_missing = missing_rows.drop(columns=missing_columns).copy()\n",
    "\n",
    "        # Step 3: Ensure all data is numeric and convert to float if necessary\n",
    "        X_non_missing = X_non_missing.apply(pd.to_numeric, errors='coerce').astype(float)\n",
    "        y_non_missing = y_non_missing.astype(float)\n",
    "        X_missing = X_missing.apply(pd.to_numeric, errors='coerce').astype(float)\n",
    "\n",
    "        # Step 4: Build the ANN model for filling missing values\n",
    "        model_missing = Sequential()\n",
    "        model_missing.add(Input(shape=(X_non_missing.shape[1],)))  # Input layer\n",
    "        model_missing.add(Dense(units=128, activation='relu'))\n",
    "        model_missing.add(Dropout(0.4))\n",
    "        model_missing.add(Dense(units=64, activation='relu'))\n",
    "        model_missing.add(Dropout(0.4))\n",
    "        model_missing.add(Dense(units=32, activation='relu'))\n",
    "        model_missing.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "\n",
    "        # Compile the model\n",
    "        model_missing.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "        # Early stopping to avoid overfitting\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "        # Step 5: Train the model\n",
    "        model_missing.fit(X_non_missing, y_non_missing, \n",
    "                          epochs=50, batch_size=32, \n",
    "                          validation_split=0.1, \n",
    "                          callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "        # Step 6: Predict the missing values\n",
    "        predicted_values = model_missing.predict(X_missing)\n",
    "\n",
    "        # Step 7: Fill the missing values in the dataset\n",
    "        X.loc[X[col].isnull(), col] = predicted_values\n",
    "\n",
    "        print(f\"Filled missing values in column: {col}\")\n",
    "\n",
    "    # Verify if there are any remaining missing values in the dataset\n",
    "    print(X.isnull().sum())\n",
    "    return X\n",
    "\n",
    "# Impute missing values for each dataset independently to avoid data leakage\n",
    "\n",
    "# Impute missing values for X_train\n",
    "X_train_imputed = impute_missing_values_ann(X_train, \"X_train\")\n",
    "\n",
    "# Impute missing values for X_test\n",
    "X_test_imputed = impute_missing_values_ann(X_test, \"X_test\")\n",
    "\n",
    "# Impute missing values for X_validate\n",
    "X_validate_imputed = impute_missing_values_ann(X_validate, \"X_validate\")\n",
    "\n",
    "# Impute missing values for X_external\n",
    "\n",
    "X_external_imputed = impute_missing_values_ann(X_external, \"X_external\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd5b212-81cd-4a10-98c2-937b68168a73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RNN\n",
    "\"\"\"\n",
    "# Define a function to impute missing values for any dataset independently using an RNN\n",
    "def impute_missing_values_rnn(X, dataset_name):\n",
    "    print(f\"Imputing missing values for {dataset_name}\")\n",
    "    \n",
    "    # Step 1: Identify columns with missing values\n",
    "    missing_columns = X.columns[X.isnull().any()].tolist()\n",
    "    print(f\"Columns with missing values: {missing_columns}\")\n",
    "\n",
    "    # Step 2: Loop through each column with missing values and build an RNN to predict missing values\n",
    "    for col in missing_columns:\n",
    "        print(f\"Filling missing values in column: {col}\")\n",
    "\n",
    "        # Separate rows with and without missing values in the current column\n",
    "        missing_rows = X[X[col].isnull()]\n",
    "        non_missing_rows = X[~X[col].isnull()]\n",
    "\n",
    "        # Skip the column if no data is available for training\n",
    "        if len(missing_rows) == 0 or len(non_missing_rows) == 0:\n",
    "            print(f\"Skipping {col}, insufficient data\")\n",
    "            continue\n",
    "\n",
    "        # Separate features and target for non-missing rows\n",
    "        X_non_missing = non_missing_rows.drop(columns=missing_columns).copy()  # Exclude other missing columns from features\n",
    "        y_non_missing = non_missing_rows[col].copy()  # Target is the column we're filling\n",
    "\n",
    "        # Features for the rows with missing values (we'll predict the column for these rows)\n",
    "        X_missing = missing_rows.drop(columns=missing_columns).copy()\n",
    "\n",
    "        # Step 3: Ensure all data is numeric and convert to float if necessary\n",
    "        X_non_missing = X_non_missing.apply(pd.to_numeric, errors='coerce').astype(float)\n",
    "        y_non_missing = y_non_missing.astype(float)\n",
    "        X_missing = X_missing.apply(pd.to_numeric, errors='coerce').astype(float)\n",
    "\n",
    "        # Step 4: Reshape the data to 3D for RNN input (samples, timesteps=1, features)\n",
    "        X_non_missing_rnn = np.expand_dims(X_non_missing, axis=1)  # Add timestep dimension\n",
    "        X_missing_rnn = np.expand_dims(X_missing, axis=1)\n",
    "\n",
    "        # Step 5: Build the RNN model for filling missing values with Input layer\n",
    "        model_missing = Sequential()\n",
    "        model_missing.add(Input(shape=(1, X_non_missing.shape[1])))  # Input layer with timestep=1 and number of features\n",
    "        model_missing.add(LSTM(units=64, return_sequences=False))  # LSTM layer\n",
    "        model_missing.add(Dropout(0.3))\n",
    "        model_missing.add(Dense(units=32, activation='relu'))\n",
    "        model_missing.add(Dense(units=1, activation='linear'))  # Output layer for regression (predicting the missing value)\n",
    "\n",
    "        # Compile the model\n",
    "        model_missing.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "        # Early stopping to avoid overfitting\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "        # Step 6: Train the model\n",
    "        model_missing.fit(X_non_missing_rnn, y_non_missing, \n",
    "                          epochs=50, batch_size=32, \n",
    "                          validation_split=0.1, \n",
    "                          callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "        # Step 7: Predict the missing values\n",
    "        predicted_values = model_missing.predict(X_missing_rnn)\n",
    "\n",
    "        # Step 8: Fill the missing values in the dataset\n",
    "        X.loc[X[col].isnull(), col] = predicted_values.flatten()\n",
    "\n",
    "        print(f\"Filled missing values in column: {col}\")\n",
    "\n",
    "    # Verify if there are any remaining missing values in the dataset\n",
    "    print(X.isnull().sum())\n",
    "    return X\n",
    "\n",
    "# Impute missing values for each dataset independently to avoid data leakage\n",
    "\n",
    "# Impute missing values for X_train\n",
    "X_train_imputed = impute_missing_values_rnn(X_train, \"X_train\")\n",
    "\n",
    "# Impute missing values for X_test\n",
    "X_test_imputed = impute_missing_values_rnn(X_test, \"X_test\")\n",
    "\n",
    "# Impute missing values for X_validate\n",
    "X_validate_imputed = impute_missing_values_rnn(X_validate, \"X_validate\")\n",
    "\n",
    "# Impute missing values for X_external\n",
    "X_external_imputed = impute_missing_values_rnn(X_external, \"X_external\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deab85f8-775d-4aaa-8338-ecb29e51acdb",
   "metadata": {},
   "source": [
    "# Scale and Normalize (Phase 06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08718dd-5868-431f-b55d-f6bbd9468ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Just Scale\n",
    "\"\"\"\n",
    "\n",
    "# Identify binary categorical features\n",
    "def identify_binary_categorical_features(df):\n",
    "    binary_categorical_features = []\n",
    "    for col in df.columns:\n",
    "        unique_values = df[col].unique()\n",
    "        if set(unique_values) == {0.0, 1.0}:\n",
    "            binary_categorical_features.append(col)\n",
    "    return binary_categorical_features\n",
    "\n",
    "\n",
    "# Identify binary categorical features\n",
    "binary_categorical_features = identify_binary_categorical_features(X_train)\n",
    "\n",
    "# Exclude binary categorical features from scaling\n",
    "numerical_features = [col for col in X_train.columns if col not in binary_categorical_features]\n",
    "\n",
    "# Create scalers\n",
    "standard_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "\"\"\"---------------------\"\"\"\n",
    "# Fit and transform only numerical features\n",
    "X_train_scaled = X_train.copy()\n",
    "X_train_scaled[numerical_features] = standard_scaler.fit_transform(X_train[numerical_features])\n",
    "X_train = X_train_scaled\n",
    "\n",
    "\"\"\"---------------------\"\"\"\n",
    "\n",
    "# Fit and transform only numerical features\n",
    "X_test_scaled = X_test.copy()\n",
    "X_test_scaled[numerical_features] = standard_scaler.fit_transform(X_test[numerical_features])\n",
    "X_test = X_test_scaled\n",
    "\n",
    "\n",
    "\"\"\"---------------------\"\"\"\n",
    "\n",
    "# Fit and transform only numerical features\n",
    "X_validate_scaled = X_validate.copy()\n",
    "X_validate_scaled[numerical_features] = standard_scaler.fit_transform(X_validate[numerical_features])\n",
    "X_validate = X_validate_scaled\n",
    "\n",
    "\n",
    "\"\"\"---------------------\"\"\"\n",
    "\n",
    "# Fit and transform only numerical features\n",
    "X_external_scaled = X_external.copy()\n",
    "X_external_scaled[numerical_features] = standard_scaler.fit_transform(X_external[numerical_features])\n",
    "X_external = X_external_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676fe676-faa5-4fa8-a568-37b64f3e63ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Only Normalization\n",
    "\"\"\"\n",
    "\n",
    "# Identify binary categorical features\n",
    "def identify_binary_categorical_features(df):\n",
    "    binary_categorical_features = []\n",
    "    for col in df.columns:\n",
    "        unique_values = df[col].unique()\n",
    "        if set(unique_values) == {0.0, 1.0}:\n",
    "            binary_categorical_features.append(col)\n",
    "    return binary_categorical_features\n",
    "\n",
    "\n",
    "# Identify binary categorical features\n",
    "binary_categorical_features = identify_binary_categorical_features(X_train)\n",
    "\n",
    "# Exclude binary categorical features from normalization\n",
    "numerical_features = [col for col in X_train.columns if col not in binary_categorical_features]\n",
    "\n",
    "# Create the Min-Max scaler\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "\"\"\"---------------------\"\"\"\n",
    "# Fit and transform only numerical features (normalization)\n",
    "X_train_normalized = X_train.copy()\n",
    "X_train_normalized[numerical_features] = minmax_scaler.fit_transform(X_train[numerical_features])\n",
    "X_train = X_train_normalized\n",
    "\n",
    "\"\"\"---------------------\"\"\"\n",
    "\n",
    "# Fit and transform only numerical features (normalization)\n",
    "X_test_normalized = X_test.copy()\n",
    "X_test_normalized[numerical_features] = minmax_scaler.fit_transform(X_test[numerical_features])\n",
    "X_test = X_test_normalized\n",
    "\n",
    "\"\"\"---------------------\"\"\"\n",
    "\n",
    "# Fit and transform only numerical features (normalization)\n",
    "X_validate_normalized = X_validate.copy()\n",
    "X_validate_normalized[numerical_features] = minmax_scaler.fit_transform(X_validate[numerical_features])\n",
    "X_validate = X_validate_normalized\n",
    "\n",
    "\"\"\"---------------------\"\"\"\n",
    "\n",
    "# Fit and transform only numerical features (normalization)\n",
    "X_external_normalized = X_external.copy()\n",
    "X_external_normalized[numerical_features] = minmax_scaler.fit_transform(X_external[numerical_features])\n",
    "X_external = X_external_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7c33af-292e-4e18-9f4c-04aa7ae1d31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Scale and Normalize\n",
    "\"\"\"\n",
    "\n",
    "# Identify binary categorical features\n",
    "def identify_binary_categorical_features(df):\n",
    "    binary_categorical_features = []\n",
    "    for col in df.columns:\n",
    "        unique_values = df[col].unique()\n",
    "        if set(unique_values) == {0.0, 1.0}:\n",
    "            binary_categorical_features.append(col)\n",
    "    return binary_categorical_features\n",
    "\n",
    "\n",
    "# Identify binary categorical features\n",
    "binary_categorical_features = identify_binary_categorical_features(X_train)\n",
    "\n",
    "# Exclude binary categorical features from scaling\n",
    "numerical_features = [col for col in X_train.columns if col not in binary_categorical_features]\n",
    "\n",
    "# Create scalers\n",
    "standard_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "\"\"\"---------------------\"\"\"\n",
    "# Fit and transform only numerical features\n",
    "X_train_scaled = X_train.copy()\n",
    "X_train_scaled[numerical_features] = standard_scaler.fit_transform(X_train[numerical_features])\n",
    "X_train = X_train_scaled\n",
    "\n",
    "# Optionally, apply Min-Max normalization\n",
    "X_train_normalized = X_train_scaled.copy()\n",
    "X_train_normalized[numerical_features] = minmax_scaler.fit_transform(X_train_scaled[numerical_features])\n",
    "X_train = X_train_normalized\n",
    "\n",
    "\n",
    "\"\"\"---------------------\"\"\"\n",
    "\n",
    "# Fit and transform only numerical features\n",
    "X_test_scaled = X_test.copy()\n",
    "X_test_scaled[numerical_features] = standard_scaler.fit_transform(X_test[numerical_features])\n",
    "X_test = X_test_scaled\n",
    "\n",
    "# Optionally, apply Min-Max normalization\n",
    "X_test_normalized = X_test_scaled.copy()\n",
    "X_test_normalized[numerical_features] = minmax_scaler.fit_transform(X_test_scaled[numerical_features])\n",
    "X_test = X_test_normalized\n",
    "\n",
    "\n",
    "\"\"\"---------------------\"\"\"\n",
    "\n",
    "# Fit and transform only numerical features\n",
    "X_validate_scaled = X_validate.copy()\n",
    "X_validate_scaled[numerical_features] = standard_scaler.fit_transform(X_validate[numerical_features])\n",
    "X_validate = X_validate_scaled\n",
    "\n",
    "# Optionally, apply Min-Max normalization\n",
    "X_validate_normalized = X_validate_scaled.copy()\n",
    "X_validate_normalized[numerical_features] = minmax_scaler.fit_transform(X_validate_scaled[numerical_features])\n",
    "X_validate = X_validate_normalized\n",
    "\n",
    "\n",
    "\"\"\"---------------------\"\"\"\n",
    "\n",
    "# Fit and transform only numerical features\n",
    "X_external_scaled = X_external.copy()\n",
    "X_external_scaled[numerical_features] = standard_scaler.fit_transform(X_external[numerical_features])\n",
    "X_external = X_external_scaled\n",
    "\n",
    "# Optionally, apply Min-Max normalization\n",
    "X_external_normalized = X_external_scaled.copy()\n",
    "X_external_normalized[numerical_features] = minmax_scaler.fit_transform(X_external_scaled[numerical_features])\n",
    "X_external = X_external_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f727d0-6369-4e0e-9d2f-ae447500734d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# HP GridSearchCV\n",
    "## To slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3e5d12-f1bd-4242-9d64-35a14ba91996",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A smaller learning rate makes the boosting\n",
    "process more robust and can lead to better\n",
    "generalization but requires more trees\n",
    "(higher n_estimators) to achieve the same result.\n",
    "A larger learning rate speeds up training bu\n",
    "may risk overfitting.\n",
    "\"\"\"\n",
    "\n",
    "# Define the parameter grid\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300], # controls the total number of trees in the ensemble\n",
    "    'learning_rate': np.arange(0.01, 1.02, 0.2),\n",
    "    'max_depth': np.arange(1, 10, 1),\n",
    "    'reg_lambda': np.arange(0.1, 15.1, 1),\n",
    "    'reg_alpha': np.arange(0.1, 15.1, 1)\n",
    "}\n",
    "\n",
    "# Create an XGBoost Regressor\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \n",
    "                           scoring='neg_mean_squared_error', \n",
    "                           cv=3,  # Number of folds for cross-validation\n",
    "                           verbose=1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score (negative MSE):\", grid_search.best_score_)\n",
    "\n",
    "# Predict on the validation set with the best model\n",
    "y_pred_validate = grid_search.predict(X_validate)\n",
    "\n",
    "# Optionally: Evaluate the model on the validation set\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_validate, y_pred_validate)\n",
    "print(\"Validation MSE:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae09b09f-e87b-436b-bf5d-a35bb597659b",
   "metadata": {},
   "source": [
    "# HP RandomizedSearchCV & Train Model\n",
    "Choose randomly samples a subset of hyperparameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3316a365-114c-4f10-9553-469d66342b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_distributions = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': np.arange(0.01, 1.02, 0.2),\n",
    "    'max_depth': np.arange(1, 10, 1),\n",
    "    'reg_lambda': np.arange(0.1, 15.1, 1),\n",
    "    'reg_alpha': np.arange(0.1, 15.1, 1)\n",
    "}\n",
    "\n",
    "# Create an XGBoost Regressor\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Create RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_distributions, \n",
    "                                   scoring='neg_mean_squared_error', \n",
    "                                   cv=3,  # Number of folds for cross-validation\n",
    "                                   n_iter=50,  # The number of parameter settings sampled\n",
    "                                   verbose=1)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(\"Best score (negative MSE):\", random_search.best_score_)\n",
    "\n",
    "# Predict on the validation set with the best model\n",
    "y_pred_validate = random_search.predict(X_validate)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "mse_validate = mean_squared_error(y_validate, y_pred_validate)\n",
    "mae_validate = mean_absolute_error(y_validate, y_pred_validate)\n",
    "print(\"Validation MSE:\", mse_validate)\n",
    "print(\"Validation MAE:\", mae_validate)\n",
    "\n",
    "# Extract the best hyperparameters\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Initialize the XGBoost model with the best hyperparameters\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    reg_lambda=best_params['reg_lambda'],\n",
    "    reg_alpha=best_params['reg_alpha']\n",
    ")\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Predict on the external validation set (eICU data)\n",
    "y_pred_external = model.predict(X_external)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on the external validation set (eICU data)\n",
    "mse_external = mean_squared_error(y_external, y_pred_external)\n",
    "mae_external = mean_absolute_error(y_external, y_pred_external)\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Test Set - MSE: {mse_test}, MAE: {mae_test}\")\n",
    "print(f\"External Validation Set (eICU) - MSE: {mse_external}, MAE: {mae_external}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2110b1d7-7f38-42df-9eed-ed0829249eee",
   "metadata": {},
   "source": [
    "# HP Bayesian Optimization & Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09340dad-8d72-4555-9b84-07c6afa84bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter search space\n",
    "param_space = {\n",
    "    'n_estimators': (100, 300),\n",
    "    'learning_rate': (0.01, 1.0, 'log-uniform'),  # log-uniform means it searches over values on a log scale\n",
    "    'max_depth': (1, 10),\n",
    "    'reg_lambda': (0.1, 15.0),\n",
    "    'reg_alpha': (0.1, 15.0)\n",
    "}\n",
    "\n",
    "# Create an XGBoost Regressor\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Create BayesSearchCV for Bayesian Optimization\n",
    "bayes_search = BayesSearchCV(estimator=xgb_model, search_spaces=param_space, \n",
    "                             scoring='neg_mean_squared_error', \n",
    "                             n_iter=50,  # The number of parameter settings sampled\n",
    "                             cv=3,  # Number of folds for cross-validation\n",
    "                             verbose=1)\n",
    "\n",
    "# Fit BayesSearchCV\n",
    "bayes_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters:\", bayes_search.best_params_)\n",
    "print(\"Best score (negative MSE):\", bayes_search.best_score_)\n",
    "\n",
    "# Predict on the validation set with the best model\n",
    "y_pred_validate = bayes_search.predict(X_validate)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "mse_validate = mean_squared_error(y_validate, y_pred_validate)\n",
    "mae_validate = mean_absolute_error(y_validate, y_pred_validate)\n",
    "print(f\"Validation MSE: {mse_validate:.4f}\")\n",
    "print(f\"Validation MAE: {mae_validate:.4f}\")\n",
    "\n",
    "# Extract the best hyperparameters from the BayesSearchCV\n",
    "best_params = bayes_search.best_params_\n",
    "\n",
    "# Initialize the XGBoost model with the best hyperparameters\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    reg_lambda=best_params['reg_lambda'],\n",
    "    reg_alpha=best_params['reg_alpha']\n",
    ")\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Predict on the external validation set (eICU data)\n",
    "y_pred_external = model.predict(X_external)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on the external validation set (eICU data)\n",
    "mse_external = mean_squared_error(y_external, y_pred_external)\n",
    "mae_external = mean_absolute_error(y_external, y_pred_external)\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Test Set - MSE: {mse_test:.4f}, MAE: {mae_test:.4f}\")\n",
    "print(f\"External Validation Set (eICU) - MSE: {mse_external:.4f}, MAE: {mae_external:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63d430b-79c1-4340-835e-119a468f1483",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# HP HyperOpt & Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7b2115-569e-4929-90c0-da230a015f50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the objective function\n",
    "def objective(params):\n",
    "    model = xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        n_estimators=int(params['n_estimators']),\n",
    "        learning_rate=params['learning_rate'],\n",
    "        max_depth=int(params['max_depth']),\n",
    "        reg_lambda=params['reg_lambda'],\n",
    "        reg_alpha=params['reg_alpha']\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    \n",
    "    # Compute the MSE\n",
    "    mse = mean_squared_error(y_validate, y_pred_validate)\n",
    "\n",
    "    # Compute the MSE\n",
    "    mse = mean_squared_error(y_validate, y_pred_validate)\n",
    "    \n",
    "    return {'loss': mse, 'status': 'ok'}\n",
    "\n",
    "# Define the parameter search space\n",
    "param_space = {\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 100, 300, 50)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(1.0)),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 1, 10, 1)),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.1, 15.0),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.1, 15.0)\n",
    "}\n",
    "\n",
    "# Create a Trials object to keep track of the search\n",
    "trials = Trials()\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=param_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,  # The number of parameter settings sampled\n",
    "    trials=trials\n",
    ")\n",
    "\n",
    "print(\"Best parameters:\", best)\n",
    "\n",
    "# Initialize the XGBoost model with the best hyperparameters\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=int(best['n_estimators']),\n",
    "    learning_rate=best['learning_rate'],\n",
    "    max_depth=int(best['max_depth']),\n",
    "    reg_lambda=best['reg_lambda'],\n",
    "    reg_alpha=best['reg_alpha']\n",
    ")\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Predict on the external validation set (eICU data)\n",
    "y_pred_external = model.predict(X_external)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Evaluate the model on the external validation set (eICU data)\n",
    "mse_external = mean_squared_error(y_external, y_pred_external)\n",
    "mae_external = mean_absolute_error(y_external, y_pred_external)\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Test Set - MSE: {mse_test:.4f}, MAE: {mae_test:.4f}\")\n",
    "print(f\"External Validation Set (eICU) - MSE: {mse_external:.4f}, MAE: {mae_external:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885760ef-c400-4db8-ac5b-5822ed654b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_external)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2493f917-45cb-478c-af02-6116cb50953d",
   "metadata": {},
   "source": [
    "# Train Model without HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec099179-7c37-4f77-9229-a2da9069d928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default XGBoost Model\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Predict on the external validation set (eICU data)\n",
    "y_pred_external = model.predict(X_external)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddece62-f4c2-4e5c-897b-f0fa49d5a394",
   "metadata": {},
   "source": [
    "# Save dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a810c9c-58b5-41f7-b700-e62558004bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "save_path = 'CSV/exports/impute/o5_Regression_impute/'\n",
    "\n",
    "# Check if the directory exists, and if not, create it\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "# Save external validation set from eICU\n",
    "X_external.to_csv(save_path + 'X_external.csv', index=False)\n",
    "y_external.to_csv(save_path + 'y_external.csv', index=False)\n",
    "\n",
    "# Save training, validation, and test sets\n",
    "X_train.to_csv(save_path + 'X_train.csv', index=False)\n",
    "y_train.to_csv(save_path + 'y_train.csv', index=False)\n",
    "\n",
    "X_validate.to_csv(save_path + 'X_validate.csv', index=False)\n",
    "y_validate.to_csv(save_path + 'y_validate.csv', index=False)\n",
    "\n",
    "X_test.to_csv(save_path + 'X_test.csv', index=False)\n",
    "y_test.to_csv(save_path + 'y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1530e609-4239-4d84-88f6-48ed91bf5a28",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e03eb8-70ee-4578-bd93-2b7032252210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory and file path\n",
    "\n",
    "name = 'o19_Inter_scale_Bayes.json'\n",
    "directory = 'models/03_Interpolation_Imputation/'\n",
    "\n",
    "file_path = os.path.join(directory, name)\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Save the model as a JSON file\n",
    "model.save_model(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c859dc-94ca-4033-a6cd-b91249f23693",
   "metadata": {},
   "source": [
    "# Test Set Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693bfe86-fa9d-4eae-b671-86c3c19ba10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics calculation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred) * 100\n",
    "\n",
    "print(f\"Test Set MSE: {mse:.4f}\")\n",
    "print(f\"Test Set MAE: {mae:.4f}\")\n",
    "print(f\"Test Set RMSE: {rmse:.4f}\")\n",
    "print(f\"Test Set R2: {r2:.4f}\")\n",
    "\n",
    "# Initialize error metrics\n",
    "error_metrics = ['MSE', 'MAE', 'RMSE']\n",
    "values = [mse, mae, rmse]\n",
    "\n",
    "# Try to calculate MSLE\n",
    "try:\n",
    "    msle = mean_squared_log_error(y_test, y_pred)\n",
    "    print(f\"Test Set MSLE: {msle:.4f}\")\n",
    "    \n",
    "    # Add MSLE to the list of metrics if applicable\n",
    "    error_metrics.append('MSLE')\n",
    "    values.append(msle)\n",
    "except ValueError:\n",
    "    print(\"Mean Squared Logarithmic Error cannot be calculated because targets contain negative values.\")\n",
    "\n",
    "# Plot error metrics (with or without MSLE)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(error_metrics, values, color=['blue', 'green', 'red', 'orange'][:len(error_metrics)])\n",
    "plt.xlabel('Error Metric')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison of Error Metrics')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R-squared (R2) for the test set\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "if r2 >= 0:\n",
    "    plt.pie([r2, 100 - r2], \n",
    "            labels=['Explained Variance (R2)', 'Unexplained Variance'], \n",
    "            colors=['lightblue', 'lightgrey'], autopct='%1.1f%%')\n",
    "else:\n",
    "    plt.pie([100], labels=['Unexplained Variance'], colors=['lightgrey'], autopct='%1.1f%%')\n",
    "\n",
    "plt.title('Test Set Explained Variance by R-squared (R2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353110ac-0992-4807-9c0f-a88ec34b2c5a",
   "metadata": {},
   "source": [
    "# External Validation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077d35f0-0758-45ed-a510-b70a5e0af7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the external validation set (eICU data)\n",
    "y_pred_external = model.predict(X_external)\n",
    "\n",
    "# Metrics for external validation set\n",
    "mse_external = mean_squared_error(y_external, y_pred_external)\n",
    "mae_external = mean_absolute_error(y_external, y_pred_external)\n",
    "rmse_external = np.sqrt(mse_external)\n",
    "r2_external = r2_score(y_external, y_pred_external) * 100\n",
    "\n",
    "print(f\"External Validation Set MSE: {mse_external:.4f}\")\n",
    "print(f\"External Validation Set MAE: {mae_external:.4f}\")\n",
    "print(f\"External Validation Set RMSE: {rmse_external:.4f}\")\n",
    "print(f\"External Validation Set R2: {r2_external:.4f}\")\n",
    "\n",
    "# Initialize error metrics\n",
    "error_metrics = ['MSE', 'MAE', 'RMSE']\n",
    "values = [mse_external, mae_external, rmse_external]\n",
    "\n",
    "# Try to calculate MSLE\n",
    "try:\n",
    "    msle_external = mean_squared_log_error(y_external, y_pred_external)\n",
    "    print(f\"External Validation Set MSLE: {msle_external:.4f}\")\n",
    "    \n",
    "    # Add MSLE to the list of metrics if applicable\n",
    "    error_metrics.append('MSLE')\n",
    "    values.append(msle_external)\n",
    "except ValueError:\n",
    "    print(\"Mean Squared Logarithmic Error cannot be calculated because targets contain negative values.\")\n",
    "\n",
    "# Plot error metrics (with or without MSLE)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(error_metrics, values, color=['blue', 'green', 'red', 'orange'][:len(error_metrics)])\n",
    "plt.xlabel('Error Metric')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison of Error Metrics')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R-squared (R2) for the external validation set\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "if r2_external >= 0:\n",
    "    plt.pie([r2_external, 100 - r2_external], \n",
    "            labels=['Explained Variance (R2)', 'Unexplained Variance'], \n",
    "            colors=['lightblue', 'lightgrey'], autopct='%1.1f%%')\n",
    "else:\n",
    "    plt.pie([100], labels=['Unexplained Variance'], colors=['lightgrey'], autopct='%1.1f%%')\n",
    "\n",
    "plt.title('Validation Set Explained Variance by R-squared (R2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e5ee89-6e54-49fa-8e9b-40c5629f7ee6",
   "metadata": {},
   "source": [
    "# Most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f15d96-8eab-4129-9b21-4932c1701469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "most_important_df = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store feature importances along with their corresponding names\n",
    "most_important_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': most_important_df})\n",
    "\n",
    "# Sort the DataFrame by feature importance in descending order\n",
    "most_important_df = most_important_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Scale the importance\n",
    "most_important_df['Importance'] *= 100000\n",
    "\n",
    "# Print the top N most important features\n",
    "top_n = 20  # set features number\n",
    "print(f\"Top {top_n} most important features:\")\n",
    "print(most_important_df.head(top_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbf81e5-689e-4426-80ac-52c1c4ce470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seaborn style and remove gridlines\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Top 10 most important features\n",
    "top_10_features = most_important_df.head(20)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))  # Reduce figure size\n",
    "plot = sns.barplot(x='Importance', y='Feature', data=top_10_features, hue='Feature', palette=\"Blues\", legend=False)\n",
    "\n",
    "# Reduce font size slightly \n",
    "plt.xlabel('Importance', fontsize=18)\n",
    "plt.ylabel('Feature', fontsize=18)\n",
    "plt.title('Top 20 Features with Highest Importance', fontsize=20)\n",
    "\n",
    "# Rotate x-axis labels for readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.ylabel('')\n",
    "plt.xlabel('')\n",
    "\n",
    "# Save the plot in high resolution\n",
    "plt.savefig('plots/19_most_important_features.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f11674-d136-4426-926e-b759f5035a26",
   "metadata": {},
   "source": [
    "# Shap plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e76068-a999-43e9-a02f-7b565c2b6a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain the model's predictions using SHAP values\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# Mean absolute SHAP values to rank feature importance\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Mean Absolute SHAP Value': mean_abs_shap\n",
    "}).sort_values(by='Mean Absolute SHAP Value', ascending=False)\n",
    "\n",
    "# Display the top N most important features\n",
    "top_n = 20\n",
    "print(f\"Top {top_n} features by SHAP importance:\")\n",
    "print(feature_importance_df.head(top_n))\n",
    "\n",
    "# Create a Matplotlib figure\n",
    "plt.figure()\n",
    "\n",
    "# SHAP Summary Plot with Bee Swarm (distribution of feature impacts)\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"dot\", show=False)\n",
    "\n",
    "# Add grid to the plot\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the plot as a PNG image\n",
    "plt.savefig(\"plots/19_shap_plot.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a20b9d-5a4b-45e5-b4e3-a828f0bbee44",
   "metadata": {},
   "source": [
    "# Create Shap by saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d72135-8af6-497a-8eed-594ef923aaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the XGBoost model from the JSON file\n",
    "model = xgb.Booster()  # Initialize the Booster object\n",
    "model.load_model(\"models\\\\02_Mean_Impute\\\\o11_Mean_Scale_Norm_Bayes_.json\")\n",
    "\n",
    "# I must load training - test set\n",
    "\n",
    "# Create a SHAP explainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# Generate SHAP summary plot\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"dot\", show=False)\n",
    "\n",
    "# Add grid to the plot\n",
    "plt.grid(True)\n",
    "\n",
    "# If i want to save the plot I must change in line 14 the show=True to False\n",
    "# plt.savefig(\"shap_summary_plot.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a306affa-01a0-4b8b-b5f5-14b0c2c8d5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
