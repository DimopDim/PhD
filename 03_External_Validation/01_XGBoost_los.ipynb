{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6243b02-165d-496a-a198-f00704a71eb6",
   "metadata": {},
   "source": [
    "# Imports | Reads | Filter Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6671463d-f9c0-4542-b28c-eec0dfb36e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, ParameterGrid, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, root_mean_squared_error, mean_squared_log_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a182eba9-001e-43e2-b928-7bdd96cf667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read MIMICs CSV file\n",
    "mimic_df = pd.read_csv(\"CSV\\\\exports\\\\final\\\\mimic_mean_final.csv\")\n",
    "\n",
    "# Read eICUs CSV file\n",
    "eicu_df = pd.read_csv(\"CSV\\\\exports\\\\final\\\\eicu_mean_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abae581b-694b-43c7-9805-90856381db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "day = 10\n",
    "\n",
    "# Filter icu stay less than 10 days\n",
    "mimic_df = mimic_df[mimic_df['los'] < day]\n",
    "\n",
    "# Filter icu stay less than 10 days\n",
    "eicu_df = eicu_df[eicu_df['los'] < day]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51bc6cae-2821-43c1-a6b1-04c79b38273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Time Zone\n",
    "\n",
    "#time_zone = 16\n",
    "#mimic_df = mimic_df[mimic_df['Time_Zone'] == time_zone]\n",
    "#eicu_df = eicu_df[eicu_df['Time_Zone'] == time_zone]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "894f6245-e142-45de-971e-fb52f9a1ffda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count: 48992\n"
     ]
    }
   ],
   "source": [
    "row_count = mimic_df.shape[0]\n",
    "print(f\"Row count: {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee62e244-e475-4222-802b-57d374b63c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate dataframes\n",
    "df_combined = pd.concat([mimic_df, eicu_df], ignore_index=True)\n",
    "\n",
    "# Find all categorical columns in mimic\n",
    "categorical_columns = df_combined.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Apply one-hot encoding to all categorical columns\n",
    "df_encoded = pd.get_dummies(df_combined, columns=categorical_columns)\n",
    "\n",
    "# Split the concatenate dataframe\n",
    "mimic_df = df_encoded.iloc[:row_count, :]  # Rows from 0 to row_count\n",
    "eicu_df = df_encoded.iloc[row_count:, :]  # Rows from row_count to the end\n",
    "\n",
    "\n",
    "\"\"\"--------------------------\"\"\"\n",
    "\n",
    "# Group by `subject_id` and `hadm_id` to get unique patient admission records\n",
    "unique_patients = mimic_df[['subject_id', 'hadm_id']].drop_duplicates()\n",
    "\n",
    "# Split the unique patients into train, validation, and test sets\n",
    "train_patients, test_patients = train_test_split(unique_patients, test_size=0.10, random_state=42)\n",
    "train_patients, validate_patients = train_test_split(train_patients, test_size=0.11, random_state=42)  # 0.11 * 90% ~= 10%\n",
    "\n",
    "# Merge the patients back with the original data to get the full records\n",
    "train_set = mimic_df.merge(train_patients, on=['subject_id', 'hadm_id'])\n",
    "validate_set = mimic_df.merge(validate_patients, on=['subject_id', 'hadm_id'])\n",
    "test_set = mimic_df.merge(test_patients, on=['subject_id', 'hadm_id'])\n",
    "\n",
    "# External validation from eICU\n",
    "X_external = eicu_df.drop(columns=['hospital_expire_flag', 'los', 'subject_id', 'hadm_id', 'row_count', 'Time_Zone'])\n",
    "y_external = eicu_df['los']\n",
    "\n",
    "# Separate features and target for the training, validation, and test sets\n",
    "X_train = train_set.drop(columns=['hospital_expire_flag', 'los', 'subject_id', 'hadm_id', 'row_count', 'Time_Zone'])\n",
    "y_train = train_set['los']\n",
    "\n",
    "X_validate = validate_set.drop(columns=['hospital_expire_flag', 'los', 'subject_id', 'hadm_id', 'row_count', 'Time_Zone'])\n",
    "y_validate = validate_set['los']\n",
    "\n",
    "X_test = test_set.drop(columns=['hospital_expire_flag', 'los', 'subject_id', 'hadm_id', 'row_count', 'Time_Zone'])\n",
    "y_test = test_set['los']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2493f917-45cb-478c-af02-6116cb50953d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Train Model without HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec099179-7c37-4f77-9229-a2da9069d928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default XGBoost Model\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Predict on the external validation set (eICU data)\n",
    "y_pred_external = model.predict(X_external)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de097a08-e1d3-4b2d-8b49-ff8ec1e8c901",
   "metadata": {},
   "source": [
    "# Train Model with HP RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c9d4dd-5eed-4f18-99e7-582fdfd0c672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter distributions\n",
    "param_dist = {\n",
    "    'learning_rate': np.arange(0.01, 1.01, 0.1),\n",
    "    'max_depth': np.arange(1, 11, 1),\n",
    "    'min_child_weight': np.arange(1, 6, 1),\n",
    "    'reg_lambda': np.arange(0.1, 15.1, 1),\n",
    "    'reg_alpha': np.arange(0.1, 15.1, 1),\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost Regressor\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Set up RandomizedSearchCV with tqdm integration\n",
    "random_search = RandomizedSearchCV(estimator=xgb_model, \n",
    "                                    param_distributions=param_dist, \n",
    "                                    n_iter=100,  # Number of random samples to try\n",
    "                                    scoring='neg_mean_squared_error',  # Use negative MSE for minimization\n",
    "                                    cv=2,  # Number of folds for cross-validation\n",
    "                                    n_jobs=-1,  # Use all available cores\n",
    "                                    verbose=1,  # Print progress\n",
    "                                    random_state=42)  # Set seed for reproducibility\n",
    "\n",
    "# Perform the RandomizedSearchCV\n",
    "with tqdm(total=100, desc=\"Hyperparameter Tuning\") as pbar:\n",
    "    random_search.fit(X_train, y_train)\n",
    "    pbar.update(100)\n",
    "\n",
    "# Retrieve the best model and hyperparameters\n",
    "best_model = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "best_score = -random_search.best_score_  # Convert from negative MSE to positive MSE\n",
    "\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "print(f\"Best validation MSE: {best_score}\")\n",
    "\n",
    "# Predict on the test set with the best model\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "# Predict on the external validation set with the best model\n",
    "y_pred_external = best_model.predict(X_external)\n",
    "\n",
    "# Evaluation on the test set\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "r2_test = r2_score(y_test, y_pred_test) * 100\n",
    "\n",
    "print(f\"Test Set MSE: {mse_test}\")\n",
    "print(f\"Test Set RMSE: {rmse_test}\")\n",
    "print(f\"Test Set MAE: {mae_test}\")\n",
    "print(f\"Test Set R2 Score: {r2_test}\")\n",
    "\n",
    "# Evaluation on the external validation set\n",
    "mse_external = mean_squared_error(y_external, y_pred_external)\n",
    "rmse_external = np.sqrt(mse_external)\n",
    "mae_external = mean_absolute_error(y_external, y_pred_external)\n",
    "r2_external = r2_score(y_external, y_pred_external) * 100\n",
    "\n",
    "print(f\"External Validation Set MSE: {mse_external}\")\n",
    "print(f\"External Validation Set RMSE: {rmse_external}\")\n",
    "print(f\"External Validation Set MAE: {mae_external}\")\n",
    "print(f\"External Validation Set R2 Score: {r2_external}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40be9029-bb02-4cc2-8346-fd023e69f99b",
   "metadata": {},
   "source": [
    "# Train Model with HP gridsearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca65fe49-cf5b-4254-b2a9-d3208485b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': np.arange(0.01, 1.01, 0.3),\n",
    "    'max_depth': np.arange(1, 11, 1),\n",
    "    'min_child_weight': np.arange(1, 6, 1),\n",
    "    'reg_lambda': np.arange(0.1, 15.1, 1),\n",
    "    'reg_alpha': np.arange(0.1, 15.1, 1),\n",
    "    'n_estimators': [100, 200, 300]  # Keep n_estimators as is\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost Regressor\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Set up GridSearchCV with tqdm integration\n",
    "grid_search = GridSearchCV(estimator=xgb_model, \n",
    "                           param_grid=param_grid, \n",
    "                           scoring='neg_mean_squared_error',  # Use negative MSE for minimization\n",
    "                           cv=2,  # Number of folds for cross-validation\n",
    "                           n_jobs=-1,  # Use all available cores\n",
    "                           verbose=1)  # Disable default verbosity\n",
    "\n",
    "# Perform the GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best model and hyperparameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "best_score = -grid_search.best_score_  # Convert from negative MSE to positive MSE\n",
    "\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "print(f\"Best validation MSE: {best_score}\")\n",
    "\n",
    "# Predict on the test set with the best model\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "# Predict on the external validation set with the best model\n",
    "y_pred_external = best_model.predict(X_external)\n",
    "\n",
    "# Evaluation on the test set\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_test = root_mean_squared_error(y_test, y_pred_test)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "r2_test = r2_score(y_test, y_pred_test) * 100\n",
    "\n",
    "print(f\"Test Set MSE: {mse_test}\")\n",
    "print(f\"Test Set RMSE: {rmse_test}\")\n",
    "print(f\"Test Set MAE: {mae_test}\")\n",
    "print(f\"Test Set R2 Score: {r2_test}\")\n",
    "\n",
    "# Evaluation on the external validation set\n",
    "mse_external = mean_squared_error(y_external, y_pred_external)\n",
    "rmse_external = root_mean_squared_error(y_external, y_pred_external)\n",
    "mae_external = mean_absolute_error(y_external, y_pred_external)\n",
    "r2_external = r2_score(y_external, y_pred_external) * 100\n",
    "\n",
    "print(f\"External Validation Set MSE: {mse_external}\")\n",
    "print(f\"External Validation Set RMSE: {rmse_external}\")\n",
    "print(f\"External Validation Set MAE: {mae_external}\")\n",
    "print(f\"External Validation Set R2 Score: {r2_external}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c859dc-94ca-4033-a6cd-b91249f23693",
   "metadata": {},
   "source": [
    "# Test Set Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d1edc9-0621-4568-89e6-b0121161b1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred) * 100\n",
    "\n",
    "print(f\"Test Set MSE: {mse}\")\n",
    "print(f\"Test Set MAE: {mae}\")\n",
    "print(f\"Test Set RMSE: {rmse}\")\n",
    "print(f\"Test Set R2: {r2}\")\n",
    "\n",
    "# Plotting error metrics\n",
    "error_metrics = ['MSE', 'MAE', 'RMSE']\n",
    "values = [mse, mae, rmse]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(error_metrics, values, color=['blue', 'green', 'red'])\n",
    "plt.xlabel('Error Metric')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison of Error Metrics')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R-squared (R2)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie([r2, 100 - r2], labels=['Explained Variance (R2)', 'Unexplained Variance'], colors=['lightblue', 'lightgrey'], autopct='%1.1f%%')\n",
    "plt.title('Explained Variance by R-squared (R2)')\n",
    "plt.show()\n",
    "\n",
    "# Plotting MSLE if applicable\n",
    "try:\n",
    "    msle = mean_squared_log_error(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(msle_values, marker='o', linestyle='-')\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.ylabel('MSLE')\n",
    "    plt.title('Mean Squared Logarithmic Error Across Predictions')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "except ValueError:\n",
    "    print(\"Mean Squared Logarithmic Error cannot be calculated because targets contain negative values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353110ac-0992-4807-9c0f-a88ec34b2c5a",
   "metadata": {},
   "source": [
    "# External Validation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f72c8c-b4af-4f7f-8e33-427f61c40ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the external validation set (eICU data)\n",
    "y_pred_external = model.predict(X_external)\n",
    "\n",
    "# Metrics for external validation set\n",
    "mse_external = mean_squared_error(y_external, y_pred_external)\n",
    "mae_external = mean_absolute_error(y_external, y_pred_external)\n",
    "rmse_external = np.sqrt(mse_external)\n",
    "r2_external = r2_score(y_external, y_pred_external) * 100\n",
    "\n",
    "print(f\"External Validation Set MSE: {mse_external}\")\n",
    "print(f\"External Validation Set MAE: {mae_external}\")\n",
    "print(f\"External Validation Set RMSE: {rmse_external}\")\n",
    "print(f\"External Validation Set R2: {r2_external}\")\n",
    "\n",
    "# Plotting error metrics for the external validation set\n",
    "error_metrics_external = ['MSE', 'MAE', 'RMSE']\n",
    "values_external = [mse_external, mae_external, rmse_external]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(error_metrics_external, values_external, color=['blue', 'green', 'red'])\n",
    "plt.xlabel('Error Metric')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison of Error Metrics (External Validation Set)')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R-squared (R2) for the external validation set\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "if r2_external >= 0:\n",
    "    plt.pie([r2_external, 100 - r2_external], \n",
    "            labels=['Explained Variance (R2)', 'Unexplained Variance'], \n",
    "            colors=['lightblue', 'lightgrey'], autopct='%1.1f%%')\n",
    "else:\n",
    "    plt.pie([100], labels=['Unexplained Variance'], colors=['lightgrey'], autopct='%1.1f%%')\n",
    "\n",
    "plt.title('Explained Variance by R-squared (R2) - External Validation Set')\n",
    "plt.show()\n",
    "\n",
    "# Plotting MSLE for the external validation set if applicable\n",
    "try:\n",
    "    msle_external = mean_squared_log_error(y_external, y_pred_external)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(y_external, y_pred_external, marker='o', linestyle='-', label='MSLE')\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.ylabel('MSLE')\n",
    "    plt.title('Mean Squared Logarithmic Error (MSLE) - External Validation Set')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "except ValueError:\n",
    "    print(\"Mean Squared Logarithmic Error cannot be calculated because targets contain negative values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e5ee89-6e54-49fa-8e9b-40c5629f7ee6",
   "metadata": {},
   "source": [
    "# Most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f15d96-8eab-4129-9b21-4932c1701469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "most_important_df = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store feature importances along with their corresponding names\n",
    "most_important_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': most_important_df})\n",
    "\n",
    "# Sort the DataFrame by feature importance in descending order\n",
    "most_important_df = most_important_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Scale the importance\n",
    "most_important_df['Importance'] *= 100000\n",
    "\n",
    "# Print the top N most important features\n",
    "top_n = 20  # set features number\n",
    "print(f\"Top {top_n} most important features:\")\n",
    "print(most_important_df.head(top_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbf81e5-689e-4426-80ac-52c1c4ce470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seaborn style and remove gridlines\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Top 10 most important features\n",
    "top_10_features = most_important_df.head(20)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))  # Reduce figure size\n",
    "plot = sns.barplot(x='Importance', y='Feature', data=top_10_features, hue='Feature', palette=\"Blues\", legend=False)\n",
    "\n",
    "# Reduce font size slightly \n",
    "plt.xlabel('Importance', fontsize=18)\n",
    "plt.ylabel('Feature', fontsize=18)\n",
    "plt.title('Top 20 Features with Highest Importance', fontsize=20)\n",
    "\n",
    "# Rotate x-axis labels for readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.ylabel('')\n",
    "plt.xlabel('')\n",
    "\n",
    "# Save the plot in high resolution\n",
    "#plt.savefig('plots/top_20_most_important_features.jpeg', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482c292e-affe-47ca-841a-f2243d0f0af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcff82c6-4d25-40f7-9df5-72d8ba694839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46397f6e-dfc2-47e4-915c-78a9a4daf720",
   "metadata": {},
   "source": [
    "# Testing field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e865875-9f52-4d07-bc64-630ec48ae959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter distributions\n",
    "param_grid = {\n",
    "    'learning_rate': np.linspace(0.01, 0.5, 10),\n",
    "    'max_depth': np.arange(1, 11),\n",
    "    'min_child_weight': np.arange(1, 6),\n",
    "    'reg_lambda': np.linspace(0.1, 15, 15),\n",
    "    'reg_alpha': np.linspace(0.1, 15, 15),\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost Regressor\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Set up GridSearchCV with tqdm integration\n",
    "grid_search = GridSearchCV(estimator=xgb_model, \n",
    "                           param_grid=param_grid, \n",
    "                           scoring='neg_mean_squared_error',  # Use negative MSE for minimization\n",
    "                           cv=2,  # Number of folds for cross-validation\n",
    "                           n_jobs=-1,  # Use all available cores\n",
    "                           verbose=1)  # Disable default verbosity\n",
    "\n",
    "# Perform the GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve best model and parameters\n",
    "best_model = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "best_score = -random_search.best_score_\n",
    "\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "print(f\"Best validation MSE: {best_score}\")\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "y_pred_external = best_model.predict(X_external)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "r2_test = r2_score(y_test, y_pred_test) * 100\n",
    "\n",
    "print(f\"Test Set MSE: {mse_test}\")\n",
    "print(f\"Test Set RMSE: {rmse_test}\")\n",
    "print(f\"Test Set MAE: {mae_test}\")\n",
    "print(f\"Test Set R2 Score: {r2_test}\")\n",
    "\n",
    "mse_external = mean_squared_error(y_external, y_pred_external)\n",
    "rmse_external = np.sqrt(mse_external)\n",
    "mae_external = mean_absolute_error(y_external, y_pred_external)\n",
    "r2_external = r2_score(y_external, y_pred_external) * 100\n",
    "\n",
    "print(f\"External Validation Set MSE: {mse_external}\")\n",
    "print(f\"External Validation Set RMSE: {rmse_external}\")\n",
    "print(f\"External Validation Set MAE: {mae_external}\")\n",
    "print(f\"External Validation Set R2 Score: {r2_external}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
