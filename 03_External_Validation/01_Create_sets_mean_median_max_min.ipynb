{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e450989-ef24-43cc-8be2-71a2bd108411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c5d778a-4513-4361-bb2c-1fdec1ebae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read MIMICs CSV file\n",
    "mimic_mean_df = pd.read_csv('..\\\\01_MimicIV\\\\CSV\\\\Exports\\\\datasets\\\\whole_set\\\\o01_final_mean_with_los.csv', low_memory=False)\n",
    "mimic_median_df = pd.read_csv('..\\\\01_MimicIV\\\\CSV\\\\Exports\\\\datasets\\\\whole_set\\\\o02_final_median_with_los.csv', low_memory=False)\n",
    "mimic_min_df = pd.read_csv('..\\\\01_MimicIV\\\\CSV\\\\Exports\\\\datasets\\\\whole_set\\\\o03_final_min_with_los.csv', low_memory=False)\n",
    "mimic_max_df = pd.read_csv('..\\\\01_MimicIV\\\\CSV\\\\Exports\\\\datasets\\\\whole_set\\\\o04_final_max_with_los.csv', low_memory=False)\n",
    "\n",
    "# Read eICUs CSV file\n",
    "eicu_meam_df = pd.read_csv('..\\\\02_eICU\\\\CSV\\\\Exports\\\\datasets\\\\whole_set\\\\o01_final_mean_table.csv', low_memory=False)\n",
    "eicu_median_df = pd.read_csv('..\\\\02_eICU\\\\CSV\\\\Exports\\\\datasets\\\\whole_set\\\\o02_final_median_table.csv', low_memory=False)\n",
    "eicu_min_df = pd.read_csv('..\\\\02_eICU\\\\CSV\\\\Exports\\\\datasets\\\\whole_set\\\\o03_final_min_table.csv', low_memory=False)\n",
    "eicu_max_df = pd.read_csv('..\\\\02_eICU\\\\CSV\\\\Exports\\\\datasets\\\\whole_set\\\\o04_final_max_table.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3c91cf4c-e5f4-402c-8eea-0f11f90d99da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to keep\n",
    "mimic_columns_to_keep = pd.read_csv('CSV\\\\imports\\\\mimic_features.csv')\n",
    "eicu_columns_to_keep = pd.read_csv(\"CSV\\\\imports\\\\eicu_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bb54d7-8c78-4bad-b607-d37839e6d877",
   "metadata": {},
   "source": [
    "# MIMIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c645a68-5a3f-4a24-a713-e0af73caf54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge mimics dataframes\n",
    "merged_mimic_df = mimic_mean_df.merge(mimic_median_df, on=['row_count','subject_id', 'hadm_id', 'Time_Zone', 'gender', 'age', 'language', 'marital_status', 'race', 'hospital_expire_flag', 'los'], suffixes=('_mean', '_median'))\n",
    "merged_mimic_df = merged_mimic_df.merge(mimic_min_df, on=['row_count','subject_id', 'hadm_id', 'Time_Zone', 'gender', 'age', 'language', 'marital_status', 'race', 'hospital_expire_flag', 'los'], suffixes=('', '_min'))\n",
    "merged_mimic_df = merged_mimic_df.merge(mimic_max_df, on=['row_count','subject_id', 'hadm_id', 'Time_Zone', 'gender', 'age', 'language', 'marital_status', 'race', 'hospital_expire_flag', 'los'], suffixes=('', '_max'))\n",
    "\n",
    "# Rename columns to replace suffixes\n",
    "merged_mimic_df.columns = merged_mimic_df.columns.str.replace(r'\\s*-\\s*Mean', ' (Mean)', regex=True)\n",
    "merged_mimic_df.columns = merged_mimic_df.columns.str.replace(r'\\s*-\\s*Median', ' (Median)', regex=True)\n",
    "merged_mimic_df.columns = merged_mimic_df.columns.str.replace(r'\\s*-\\s*Min', ' (Min)', regex=True)\n",
    "merged_mimic_df.columns = merged_mimic_df.columns.str.replace(r'\\s*-\\s*Max', ' (Max)', regex=True)\n",
    "\n",
    "# Move the 'hospital_expire_flag' and 'LOS' columns to the end of the dataframe\n",
    "hospital_expire_flag_column = merged_mimic_df.pop('hospital_expire_flag')\n",
    "los_column = merged_mimic_df.pop('los')\n",
    "merged_mimic_df = pd.concat([merged_mimic_df, hospital_expire_flag_column, los_column], axis=1)\n",
    "\n",
    "# Rename the last two columns to preserve their original names\n",
    "merged_mimic_df.columns = list(merged_mimic_df.columns[:-2]) + ['hospital_expire_flag', 'los']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75174a78-89da-4c51-83cb-f9c371c3bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize GCS components for Mean, Median, Min, and Max while handling NaNs\n",
    "merged_mimic_df['GCS (Mean)'] = merged_mimic_df.apply(lambda row: row[['GCS - Eye Opening (Mean)', 'GCS - Verbal Response (Mean)', 'GCS - Motor Response (Mean)']].sum() if not all(row[['GCS - Eye Opening (Mean)', 'GCS - Verbal Response (Mean)', 'GCS - Motor Response (Mean)']].isna()) else np.nan, axis=1)\n",
    "merged_mimic_df['GCS (Median)'] = merged_mimic_df.apply(lambda row: row[['GCS - Eye Opening (Median)', 'GCS - Verbal Response (Median)', 'GCS - Motor Response (Median)']].sum() if not all(row[['GCS - Eye Opening (Median)', 'GCS - Verbal Response (Median)', 'GCS - Motor Response (Median)']].isna()) else np.nan, axis=1)\n",
    "merged_mimic_df['GCS (Min)'] = merged_mimic_df.apply(lambda row: row[['GCS - Eye Opening (Min)', 'GCS - Verbal Response (Min)', 'GCS - Motor Response (Min)']].sum() if not all(row[['GCS - Eye Opening (Min)', 'GCS - Verbal Response (Min)', 'GCS - Motor Response (Min)']].isna()) else np.nan, axis=1)\n",
    "merged_mimic_df['GCS (Max)'] = merged_mimic_df.apply(lambda row: row[['GCS - Eye Opening (Max)', 'GCS - Verbal Response (Max)', 'GCS - Motor Response (Max)']].sum() if not all(row[['GCS - Eye Opening (Max)', 'GCS - Verbal Response (Max)', 'GCS - Motor Response (Max)']].isna()) else np.nan, axis=1)\n",
    "\n",
    "# Drop the original GCS component columns\n",
    "merged_mimic_df.drop(columns=[\n",
    "    'GCS - Eye Opening (Mean)', 'GCS - Verbal Response (Mean)', 'GCS - Motor Response (Mean)',\n",
    "    'GCS - Eye Opening (Median)', 'GCS - Verbal Response (Median)', 'GCS - Motor Response (Median)',\n",
    "    'GCS - Eye Opening (Min)', 'GCS - Verbal Response (Min)', 'GCS - Motor Response (Min)',\n",
    "    'GCS - Eye Opening (Max)', 'GCS - Verbal Response (Max)', 'GCS - Motor Response (Max)'\n",
    "], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb9f0b0f-b335-4d14-8119-c5b1c32d76a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize Braden components for Mean, Median, Min, and Max while handling NaNs\n",
    "merged_mimic_df['Braden (Mean)'] = merged_mimic_df.apply(lambda row: row[['Braden Sensory Perception (Mean)', 'Braden Moisture (Mean)', 'Braden Activity (Mean)', 'Braden Mobility (Mean)', 'Braden Nutrition (Mean)', 'Braden Friction/Shear (Mean)']].sum() if not all(row[['Braden Sensory Perception (Mean)', 'Braden Moisture (Mean)', 'Braden Activity (Mean)', 'Braden Mobility (Mean)', 'Braden Nutrition (Mean)', 'Braden Friction/Shear (Mean)']].isna()) else np.nan, axis=1)\n",
    "merged_mimic_df['Braden (Median)'] = merged_mimic_df.apply(lambda row: row[['Braden Sensory Perception (Median)', 'Braden Moisture (Median)', 'Braden Activity (Median)', 'Braden Mobility (Median)', 'Braden Nutrition (Median)', 'Braden Friction/Shear (Median)']].sum() if not all(row[['Braden Sensory Perception (Median)', 'Braden Moisture (Median)', 'Braden Activity (Median)', 'Braden Mobility (Median)', 'Braden Nutrition (Median)', 'Braden Friction/Shear (Median)']].isna()) else np.nan, axis=1)\n",
    "merged_mimic_df['Braden (Min)'] = merged_mimic_df.apply(lambda row: row[['Braden Sensory Perception (Min)', 'Braden Moisture (Min)', 'Braden Activity (Min)', 'Braden Mobility (Min)', 'Braden Nutrition (Min)', 'Braden Friction/Shear (Min)']].sum() if not all(row[['Braden Sensory Perception (Min)', 'Braden Moisture (Min)', 'Braden Activity (Min)', 'Braden Mobility (Min)', 'Braden Nutrition (Min)', 'Braden Friction/Shear (Min)']].isna()) else np.nan, axis=1)\n",
    "merged_mimic_df['Braden (Max)'] = merged_mimic_df.apply(lambda row: row[['Braden Sensory Perception (Max)', 'Braden Moisture (Max)', 'Braden Activity (Max)', 'Braden Mobility (Max)', 'Braden Nutrition (Max)', 'Braden Friction/Shear (Max)']].sum() if not all(row[['Braden Sensory Perception (Max)', 'Braden Moisture (Max)', 'Braden Activity (Max)', 'Braden Mobility (Max)', 'Braden Nutrition (Max)', 'Braden Friction/Shear (Max)']].isna()) else np.nan, axis=1)\n",
    "\n",
    "# Drop the original Braden component columns\n",
    "merged_mimic_df.drop(columns=[\n",
    "    'Braden Sensory Perception (Mean)', 'Braden Moisture (Mean)', 'Braden Activity (Mean)', 'Braden Mobility (Mean)', 'Braden Nutrition (Mean)', 'Braden Friction/Shear (Mean)',\n",
    "    'Braden Sensory Perception (Median)', 'Braden Moisture (Median)', 'Braden Activity (Median)', 'Braden Mobility (Median)', 'Braden Nutrition (Median)', 'Braden Friction/Shear (Median)',\n",
    "    'Braden Sensory Perception (Min)', 'Braden Moisture (Min)', 'Braden Activity (Min)', 'Braden Mobility (Min)', 'Braden Nutrition (Min)', 'Braden Friction/Shear (Min)',\n",
    "    'Braden Sensory Perception (Max)', 'Braden Moisture (Max)', 'Braden Activity (Max)', 'Braden Mobility (Max)', 'Braden Nutrition (Max)', 'Braden Friction/Shear (Max)'\n",
    "], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baff4a04-b710-49ea-bb59-e33f71e14fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove spaces and commas\n",
    "merged_mimic_df.columns = merged_mimic_df.columns.str.replace(r'[ ,]+', '_', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffbd9287-8565-4962-8ebf-f6a18f011ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop second column from the column_names_df\n",
    "mimic_columns_to_keep.drop(columns=['Unnamed: 1'], inplace=True)\n",
    "\n",
    "# Extract column names from columns_to_keep DataFrame\n",
    "columns_to_keep_names = mimic_columns_to_keep['column'].tolist()\n",
    "\n",
    "# Select only the desired columns\n",
    "mimic_temp = merged_mimic_df[columns_to_keep_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aace7894-9469-4cbb-88fc-f53fe5e8df70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Duplicate Columns\n",
    "df_mimic_unique = mimic_temp.loc[:, ~mimic_temp.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ab4b571-cee1-4183-996f-4251c49784e5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dimopoulos\\AppData\\Local\\Temp\\ipykernel_5436\\1272433173.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique.loc[:, 'Glucose (Min)'] = df_unique.apply(lambda row: row[['Glucose_(Min)', 'Glucose_(Min).1', 'Glucose_(Min).2']].mean() if not all(row[['Glucose_(Min)', 'Glucose_(Min).1', 'Glucose_(Min).2']].isna()) else np.nan, axis=1)\n",
      "C:\\Users\\Dimopoulos\\AppData\\Local\\Temp\\ipykernel_5436\\1272433173.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique.drop(columns=[\n"
     ]
    }
   ],
   "source": [
    "# Glucose merge\n",
    "df_mimic_unique.loc[:, 'Glucose (Max)'] = df_mimic_unique.apply(lambda row: row[['Glucose_(Max)', 'Glucose_(Max).1', 'Glucose_(Max).2']].mean() if not all(row[['Glucose_(Max)', 'Glucose_(Max).1', 'Glucose_(Max).2']].isna()) else np.nan, axis=1)\n",
    "df_mimic_unique.loc[:, 'Glucose (Mean)'] = df_mimic_unique.apply(lambda row: row[['Glucose_(Mean)', 'Glucose_(Mean).1', 'Glucose_(Mean).2']].mean() if not all(row[['Glucose_(Mean)', 'Glucose_(Mean).1', 'Glucose_(Mean).2']].isna()) else np.nan, axis=1)\n",
    "df_mimic_unique.loc[:, 'Glucose (Median)'] = df_mimic_unique.apply(lambda row: row[['Glucose_(Median)', 'Glucose_(Median).1', 'Glucose_(Median).2']].mean() if not all(row[['Glucose_(Median)', 'Glucose_(Median).1', 'Glucose_(Median).2']].isna()) else np.nan, axis=1)\n",
    "df_mimic_unique.loc[:, 'Glucose (Min)'] = df_mimic_unique.apply(lambda row: row[['Glucose_(Min)', 'Glucose_(Min).1', 'Glucose_(Min).2']].mean() if not all(row[['Glucose_(Min)', 'Glucose_(Min).1', 'Glucose_(Min).2']].isna()) else np.nan, axis=1)\n",
    "\n",
    "# Drop original Glucose columns to keep only the summarized columns\n",
    "df_mimic_unique.drop(columns=[\n",
    "    'Glucose_(Max)', 'Glucose_(Max).1', 'Glucose_(Max).2',\n",
    "    'Glucose_(Mean)', 'Glucose_(Mean).1', 'Glucose_(Mean).2',\n",
    "    'Glucose_(Median)', 'Glucose_(Median).1', 'Glucose_(Median).2',\n",
    "    'Glucose_(Min)', 'Glucose_(Min).1', 'Glucose_(Min).2'\n",
    "], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9a1c826-fd28-4504-9e94-e96bb66a4d2f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dimopoulos\\AppData\\Local\\Temp\\ipykernel_5436\\2086266188.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique.loc[:, 'pH (Max)'] = df_unique.apply(lambda row: row[['pH_(Max)', 'pH_(Max).1', 'pH_(Max).3']].mean() if not all(row[['pH_(Max)', 'pH_(Max).1', 'pH_(Max).3']].isna()) else np.nan, axis=1)\n",
      "C:\\Users\\Dimopoulos\\AppData\\Local\\Temp\\ipykernel_5436\\2086266188.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique.loc[:, 'pH (Mean)'] = df_unique.apply(lambda row: row[['pH_(Mean)', 'pH_(Mean).1', 'pH_(Mean).2', 'pH_(Mean).3']].mean() if not all(row[['pH_(Mean)', 'pH_(Mean).1', 'pH_(Mean).2', 'pH_(Mean).3']].isna()) else np.nan, axis=1)\n",
      "C:\\Users\\Dimopoulos\\AppData\\Local\\Temp\\ipykernel_5436\\2086266188.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique.loc[:, 'pH (Median)'] = df_unique.apply(lambda row: row[['pH_(Median)', 'pH_(Median).1', 'pH_(Median).3']].mean() if not all(row[['pH_(Median)', 'pH_(Median).1', 'pH_(Median).3']].isna()) else np.nan, axis=1)\n",
      "C:\\Users\\Dimopoulos\\AppData\\Local\\Temp\\ipykernel_5436\\2086266188.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique.loc[:, 'pH (Min)'] = df_unique.apply(lambda row: row[['pH_(Min)', 'pH_(Min).1', 'pH_(Min).3']].mean() if not all(row[['pH_(Min)', 'pH_(Min).1', 'pH_(Min).3']].isna()) else np.nan, axis=1)\n",
      "C:\\Users\\Dimopoulos\\AppData\\Local\\Temp\\ipykernel_5436\\2086266188.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique.drop(columns=[\n"
     ]
    }
   ],
   "source": [
    "# pH merge\n",
    "df_mimic_unique.loc[:, 'pH (Max)'] = df_mimic_unique.apply(lambda row: row[['pH_(Max)', 'pH_(Max).1', 'pH_(Max).3']].mean() if not all(row[['pH_(Max)', 'pH_(Max).1', 'pH_(Max).3']].isna()) else np.nan, axis=1)\n",
    "df_mimic_unique.loc[:, 'pH (Mean)'] = df_mimic_unique.apply(lambda row: row[['pH_(Mean)', 'pH_(Mean).1', 'pH_(Mean).2', 'pH_(Mean).3']].mean() if not all(row[['pH_(Mean)', 'pH_(Mean).1', 'pH_(Mean).2', 'pH_(Mean).3']].isna()) else np.nan, axis=1)\n",
    "df_mimic_unique.loc[:, 'pH (Median)'] = df_mimic_unique.apply(lambda row: row[['pH_(Median)', 'pH_(Median).1', 'pH_(Median).3']].mean() if not all(row[['pH_(Median)', 'pH_(Median).1', 'pH_(Median).3']].isna()) else np.nan, axis=1)\n",
    "df_mimic_unique.loc[:, 'pH (Min)'] = df_mimic_unique.apply(lambda row: row[['pH_(Min)', 'pH_(Min).1', 'pH_(Min).3']].mean() if not all(row[['pH_(Min)', 'pH_(Min).1', 'pH_(Min).3']].isna()) else np.nan, axis=1)\n",
    "\n",
    "# Drop original pH columns to keep only the summarized columns\n",
    "df_mimic_unique.drop(columns=[\n",
    "    'pH_(Max)', 'pH_(Max).1', 'pH_(Max).3',\n",
    "    'pH_(Mean)', 'pH_(Mean).1', 'pH_(Mean).2', 'pH_(Mean).3',\n",
    "    'pH_(Median)', 'pH_(Median).1', 'pH_(Median).3',\n",
    "    'pH_(Min)', 'pH_(Min).1', 'pH_(Min).3'\n",
    "], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f4c528-593c-4a86-b3f0-d7fce5631a83",
   "metadata": {},
   "source": [
    "# eICU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638bd02c-ab55-435d-8497-96cba4d5ede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge eICU dataframes\n",
    "merged_eicu_df = eicu_meam_df.merge(eicu_median_df, on=['row_count', 'uniquepid', 'patientunitstayid', 'Time_Zone', 'gender', 'age', 'ethnicity', 'unitdischargestatus', 'LOS'], suffixes=('_mean', '_median'))\n",
    "merged_eicu_df = merged_eicu_df.merge(eicu_min_df, on=['row_count', 'uniquepid', 'patientunitstayid', 'Time_Zone', 'gender', 'age', 'ethnicity', 'unitdischargestatus', 'LOS'], suffixes=('', '_min'))\n",
    "merged_eicu_df = merged_eicu_df.merge(eicu_max_df, on=['row_count', 'uniquepid', 'patientunitstayid', 'Time_Zone', 'gender', 'age', 'ethnicity', 'unitdischargestatus', 'LOS'], suffixes=('', '_max'))\n",
    "\n",
    "# Move the 'unitdischargestatus' and 'LOS' columns to the end of the dataframe\n",
    "unitdischargestatus_column = merged_eicu_df.pop('unitdischargestatus')\n",
    "los_column = merged_eicu_df.pop('LOS')\n",
    "merged_eicu_df = pd.concat([merged_eicu_df, unitdischargestatus_column, los_column], axis=1)\n",
    "\n",
    "# Rename the last two columns to preserve their original names\n",
    "merged_eicu_df.columns = list(merged_eicu_df.columns[:-2]) + ['unitdischargestatus', 'LOS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2d6d9f87-4ba1-478a-8382-134c371ea70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop second column from the column_names_df\n",
    "#eicu_columns_to_keep.drop(columns=['Unnamed: 1'], inplace=True)\n",
    "\n",
    "# Extract column names from columns_to_keep DataFrame\n",
    "columns_to_keep_names = eicu_columns_to_keep['column'].tolist()\n",
    "\n",
    "# Select only the desired columns\n",
    "eicu_temp = merged_eicu_df[columns_to_keep_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4c69a3-07f1-4b19-bc57-77d227f982eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed90bd15-ad41-4f26-b573-51fd5631e512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf296c0-b15d-4008-86bc-5c3c9413370c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2685112d-9768-4a53-b4fa-4eec82632040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d939060-7c74-4faf-9e04-5ee040ea0181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "002b9f6f-70f1-49e5-a5ca-898948b8b864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_count</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>Time_Zone</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>Alanine_Aminotransferase_(ALT)_(Max)</th>\n",
       "      <th>Alanine_Aminotransferase_(ALT)_(Mean)</th>\n",
       "      <th>Alanine_Aminotransferase_(ALT)_(Median)</th>\n",
       "      <th>...</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "      <th>los</th>\n",
       "      <th>Glucose (Max)</th>\n",
       "      <th>Glucose (Mean)</th>\n",
       "      <th>Glucose (Median)</th>\n",
       "      <th>Glucose (Min)</th>\n",
       "      <th>pH (Max)</th>\n",
       "      <th>pH (Mean)</th>\n",
       "      <th>pH (Median)</th>\n",
       "      <th>pH (Min)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Survive</td>\n",
       "      <td>8.357373</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>6.715</td>\n",
       "      <td>6.715</td>\n",
       "      <td>6.715</td>\n",
       "      <td>6.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Survive</td>\n",
       "      <td>8.357373</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>6.715</td>\n",
       "      <td>6.715</td>\n",
       "      <td>6.715</td>\n",
       "      <td>6.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Survive</td>\n",
       "      <td>8.357373</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>6.715</td>\n",
       "      <td>6.715</td>\n",
       "      <td>6.715</td>\n",
       "      <td>6.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Survive</td>\n",
       "      <td>8.357373</td>\n",
       "      <td>94.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>6.715</td>\n",
       "      <td>6.715</td>\n",
       "      <td>6.715</td>\n",
       "      <td>6.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10004733</td>\n",
       "      <td>27411876</td>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Survive</td>\n",
       "      <td>8.357373</td>\n",
       "      <td>94.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>6.715</td>\n",
       "      <td>6.715</td>\n",
       "      <td>6.715</td>\n",
       "      <td>6.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58139</th>\n",
       "      <td>58140</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>12</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Survive</td>\n",
       "      <td>1.937847</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>6.445</td>\n",
       "      <td>6.445</td>\n",
       "      <td>6.445</td>\n",
       "      <td>6.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58140</th>\n",
       "      <td>58141</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>13</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Survive</td>\n",
       "      <td>1.937847</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>6.445</td>\n",
       "      <td>6.445</td>\n",
       "      <td>6.445</td>\n",
       "      <td>6.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58141</th>\n",
       "      <td>58142</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>14</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Survive</td>\n",
       "      <td>1.937847</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>6.445</td>\n",
       "      <td>6.445</td>\n",
       "      <td>6.445</td>\n",
       "      <td>6.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58142</th>\n",
       "      <td>58143</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>15</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Survive</td>\n",
       "      <td>1.937847</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>6.445</td>\n",
       "      <td>6.445</td>\n",
       "      <td>6.445</td>\n",
       "      <td>6.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58143</th>\n",
       "      <td>58144</td>\n",
       "      <td>19999987</td>\n",
       "      <td>23865745</td>\n",
       "      <td>16</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Survive</td>\n",
       "      <td>1.937847</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>6.445</td>\n",
       "      <td>6.445</td>\n",
       "      <td>6.445</td>\n",
       "      <td>6.445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58144 rows × 317 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_count  subject_id   hadm_id  Time_Zone gender  age     race  \\\n",
       "0              1    10004733  27411876          1      M   51  UNKNOWN   \n",
       "1              2    10004733  27411876          2      M   51  UNKNOWN   \n",
       "2              3    10004733  27411876          3      M   51  UNKNOWN   \n",
       "3              4    10004733  27411876          4      M   51  UNKNOWN   \n",
       "4              5    10004733  27411876          5      M   51  UNKNOWN   \n",
       "...          ...         ...       ...        ...    ...  ...      ...   \n",
       "58139      58140    19999987  23865745         12      F   57  UNKNOWN   \n",
       "58140      58141    19999987  23865745         13      F   57  UNKNOWN   \n",
       "58141      58142    19999987  23865745         14      F   57  UNKNOWN   \n",
       "58142      58143    19999987  23865745         15      F   57  UNKNOWN   \n",
       "58143      58144    19999987  23865745         16      F   57  UNKNOWN   \n",
       "\n",
       "       Alanine_Aminotransferase_(ALT)_(Max)  \\\n",
       "0                                      46.0   \n",
       "1                                      46.0   \n",
       "2                                      46.0   \n",
       "3                                      46.0   \n",
       "4                                      46.0   \n",
       "...                                     ...   \n",
       "58139                                  63.0   \n",
       "58140                                  63.0   \n",
       "58141                                  63.0   \n",
       "58142                                  63.0   \n",
       "58143                                  63.0   \n",
       "\n",
       "       Alanine_Aminotransferase_(ALT)_(Mean)  \\\n",
       "0                                       46.0   \n",
       "1                                       46.0   \n",
       "2                                       46.0   \n",
       "3                                       46.0   \n",
       "4                                       46.0   \n",
       "...                                      ...   \n",
       "58139                                   63.0   \n",
       "58140                                   63.0   \n",
       "58141                                   63.0   \n",
       "58142                                   63.0   \n",
       "58143                                   63.0   \n",
       "\n",
       "       Alanine_Aminotransferase_(ALT)_(Median)  ...  hospital_expire_flag  \\\n",
       "0                                         46.0  ...               Survive   \n",
       "1                                         46.0  ...               Survive   \n",
       "2                                         46.0  ...               Survive   \n",
       "3                                         46.0  ...               Survive   \n",
       "4                                         46.0  ...               Survive   \n",
       "...                                        ...  ...                   ...   \n",
       "58139                                     63.0  ...               Survive   \n",
       "58140                                     63.0  ...               Survive   \n",
       "58141                                     63.0  ...               Survive   \n",
       "58142                                     63.0  ...               Survive   \n",
       "58143                                     63.0  ...               Survive   \n",
       "\n",
       "            los  Glucose (Max)  Glucose (Mean)  Glucose (Median)  \\\n",
       "0      8.357373           86.0            86.0              86.0   \n",
       "1      8.357373           86.0            86.0              86.0   \n",
       "2      8.357373           86.0            86.0              86.0   \n",
       "3      8.357373           94.0            90.0              90.0   \n",
       "4      8.357373           94.0            90.0              90.0   \n",
       "...         ...            ...             ...               ...   \n",
       "58139  1.937847          113.0           113.0             113.0   \n",
       "58140  1.937847          113.0           113.0             113.0   \n",
       "58141  1.937847          113.0           113.0             113.0   \n",
       "58142  1.937847          113.0           113.0             113.0   \n",
       "58143  1.937847          113.0           113.0             113.0   \n",
       "\n",
       "       Glucose (Min)  pH (Max)  pH (Mean)  pH (Median)  pH (Min)  \n",
       "0               86.0     6.715      6.715        6.715     6.715  \n",
       "1               86.0     6.715      6.715        6.715     6.715  \n",
       "2               86.0     6.715      6.715        6.715     6.715  \n",
       "3               86.0     6.715      6.715        6.715     6.715  \n",
       "4               86.0     6.715      6.715        6.715     6.715  \n",
       "...              ...       ...        ...          ...       ...  \n",
       "58139          113.0     6.445      6.445        6.445     6.445  \n",
       "58140          113.0     6.445      6.445        6.445     6.445  \n",
       "58141          113.0     6.445      6.445        6.445     6.445  \n",
       "58142          113.0     6.445      6.445        6.445     6.445  \n",
       "58143          113.0     6.445      6.445        6.445     6.445  \n",
       "\n",
       "[58144 rows x 317 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8b81670f-34ff-4a59-82ab-c97db0ebb461",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'column_names.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m columns_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(column_names, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn_Name\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Export to CSV\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m columns_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_names.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3968\u001b[0m     path_or_buf,\n\u001b[0;32m   3969\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3970\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3971\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3972\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3973\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3974\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3975\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3976\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3977\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3978\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3979\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3980\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3981\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3982\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3983\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3984\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    254\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    255\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    256\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    257\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'column_names.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "column_names = merged_eicu_df.columns\n",
    "\n",
    "# Create a dataframe from the column names\n",
    "columns_df = pd.DataFrame(column_names, columns=['Column_Name'])\n",
    "\n",
    "# Export to CSV\n",
    "columns_df.to_csv('column_names.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1043fa-7186-4a55-b273-aebd30812013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f2ad9d-9d0d-4e3d-aab3-75fb31cb23a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da77610-827b-4790-8b62-1c3b0c16b556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113604ef-5f3f-4a63-908a-b81618546b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ab8579f3-8211-4412-9d16-14992bdd2b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "braden_columns = [col for col in merged_eicu_df.columns if col.startswith('free T4')]\n",
    "braden_df = merged_eicu_df[braden_columns]\n",
    "\n",
    "# Count the missing values for each GCS column\n",
    "missing_values_count = braden_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3aedf85a-4b29-4b89-bf63-3775c80ab778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>free T4 (Mean)</th>\n",
       "      <th>free T4 (Median)</th>\n",
       "      <th>free T4 (Min)</th>\n",
       "      <th>free T4 (Max)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86267</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86268</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86269</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86270</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86271</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86272 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       free T4 (Mean)  free T4 (Median)  free T4 (Min)  free T4 (Max)\n",
       "0                 NaN               NaN            NaN            NaN\n",
       "1                 NaN               NaN            NaN            NaN\n",
       "2                 NaN               NaN            NaN            NaN\n",
       "3                 NaN               NaN            NaN            NaN\n",
       "4                 NaN               NaN            NaN            NaN\n",
       "...               ...               ...            ...            ...\n",
       "86267             NaN               NaN            NaN            NaN\n",
       "86268             NaN               NaN            NaN            NaN\n",
       "86269             NaN               NaN            NaN            NaN\n",
       "86270             NaN               NaN            NaN            NaN\n",
       "86271             NaN               NaN            NaN            NaN\n",
       "\n",
       "[86272 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(braden_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5824de4f-0930-4e74-ad1d-fd0561510d27",
   "metadata": {},
   "source": [
    "# I stop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc242ce-70d7-445f-9bfd-c09711e2123c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3070725a-a9d7-44c5-8b98-91fa3abf35f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148fc069-f258-406e-8f99-1818dc489baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9078c2f6-1df6-4fd3-a32b-248bf27eb9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90152c62-0c9f-4bfe-bc76-2064e410f218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mimic -> columns to keep\n",
    "# Read the CSV file to get the columns to keep\n",
    "columns_to_keep = pd.read_csv('CSV\\\\imports\\\\mimic_features.csv')\n",
    "\n",
    "# Drop second column from the column_names_df\n",
    "columns_to_keep.drop(columns=['Unnamed: 1'], inplace=True)\n",
    "\n",
    "# Extract column names from columns_to_keep DataFrame\n",
    "columns_to_keep_names = columns_to_keep['column'].tolist()\n",
    "\n",
    "# Select only the desired columns\n",
    "mimic_temp = mimic_df[columns_to_keep_names]\n",
    "\n",
    "\"\"\"------------------------------------------------------------------------------\"\"\"\n",
    "# eICU -> columns to keep\n",
    "# Read the CSV file to get the columns to keep\n",
    "columns_to_keep = pd.read_csv(\"CSV\\\\imports\\\\eicu_features.csv\")\n",
    "\n",
    "# Drop second column from the column_names_df\n",
    "columns_to_keep.drop(columns=['Unnamed: 1'], inplace=True)\n",
    "\n",
    "# Extract column names from columns_to_keep DataFrame\n",
    "columns_to_keep_names = columns_to_keep['column'].tolist()\n",
    "\n",
    "# Select only the desired columns\n",
    "eicu_temp = eicu_df[columns_to_keep_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163c36d4-c0fd-40e7-9bb5-8defc2d9016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"--------Replace Block----------\"\"\"\n",
    "\n",
    "# Replace 'Alive' with 0 and 'Expired' with 1 in the 'unitdischargestatus' column\n",
    "eicu_temp.loc[:, 'unitdischargestatus'] = eicu_temp['unitdischargestatus'].replace({'Alive': 0, 'Expired': 1})\n",
    "\n",
    "# Replace 'Female' with 'F' and 'Male' with 'M' in the 'gender' column\n",
    "eicu_temp.loc[:, 'gender'] = eicu_temp['gender'].replace({'Female': 'F', 'Male': 'M'})\n",
    "\n",
    "# Multiply values by 4 in 'Ionized Calcium' column, leaving NaN values unchanged\n",
    "mimic_temp.loc[:, 'Ionized Calcium'] = mimic_temp['Ionized Calcium'].apply(lambda x: x * 4 if pd.notna(x) else x)\n",
    "\n",
    "# Replace values in the 'ethnicity' column for standardization\n",
    "eicu_temp.loc[:, 'ethnicity'] = eicu_temp['ethnicity'].replace({\n",
    "    'African American': 'BLACK/AFRICAN AMERICAN',\n",
    "    'Caucasian': 'WHITE',\n",
    "    'Hispanic': 'HISPANIC OR LATINO',\n",
    "    'Asian': 'ASIAN',\n",
    "    'Native American': 'AMERICAN INDIAN/ALASKA NATIVE',\n",
    "    'Other/Unknown': 'UNKNOWN'\n",
    "})\n",
    "\n",
    "# Replace age values higher than 89 with 90, and convert age to integer\n",
    "eicu_temp.loc[:, 'age'] = eicu_temp['age'].replace('> 89', 90)\n",
    "eicu_temp.loc[:, 'age'] = eicu_temp['age'].astype(np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a725b058-fc38-4cfc-8803-3c9c8cec8b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_eicu_mapping = {\n",
    "    'column': 'column',\n",
    "    'row_count': 'row_count',\n",
    "    'uniquepid': 'subject_id',\n",
    "    'patientunitstayid': 'hadm_id',\n",
    "    'Time_Zone': 'Time_Zone',\n",
    "    'gender': 'gender',\n",
    "    'age': 'age',\n",
    "    'ethnicity': 'race',\n",
    "    'Base Excess': 'Base Excess',\n",
    "    'lactate': 'Lactate',\n",
    "    'paCO2': 'pCO2',\n",
    "    'Total CO2': 'Calculated Total CO2',\n",
    "    'BUN': 'BUN',\n",
    "    'pH': 'pH',\n",
    "    'paO2': 'pO2',\n",
    "    'ALT (SGPT)': 'Alanine Aminotransferase (ALT)',\n",
    "    'alkaline phos.': 'Alkaline Phosphatase',\n",
    "    'anion gap': 'Anion Gap',\n",
    "    'AST (SGOT)': 'Asparate Aminotransferase (AST)',\n",
    "    'bicarbonate': 'Bicarbonate',\n",
    "    'chloride': 'Chloride',\n",
    "    'creatinine': 'Creatinine',\n",
    "    'glucose': 'Glucose',\n",
    "    'magnesium': 'Magnesium',\n",
    "    'phosphate': 'Phosphate',\n",
    "    'potassium': 'Potassium',\n",
    "    'sodium': 'Sodium',\n",
    "    'Hct': 'Hematocrit',\n",
    "    'Hgb': 'Hemoglobin',\n",
    "    'PT - INR': 'INR(PT)',\n",
    "    'MCH': 'MCH',\n",
    "    'MCHC': 'MCHC',\n",
    "    'MCV': 'MCV',\n",
    "    'platelets x 1000': 'Platelet Count',\n",
    "    'PT': 'PT',\n",
    "    'PTT': 'PTT',\n",
    "    'RDW': 'RDW',\n",
    "    'RBC': 'Red Blood Cells',\n",
    "    'WBC x 1000': 'White Blood Cells',\n",
    "    'Heart Rate': 'Heart Rate (bpm)',\n",
    "    'Non-Invasive BP Diastolic': 'Non Invasive Blood Pressure systolic (mmHg)',\n",
    "    'Non-Invasive BP Systolic': 'Non Invasive Blood Pressure diastolic (mmHg)',\n",
    "    'Non-Invasive BP Mean': 'Non Invasive Blood Pressure mean (mmHg)',\n",
    "    'Respiratory Rate': 'Respiratory Rate (insp/min)',\n",
    "    'O2 Saturation': 'O2 saturation pulseoxymetry (%)',\n",
    "    'CI': 'Chloride (serum)',\n",
    "    'calcium': 'Calcium non-ionized',\n",
    "    'CPK': 'CK (CPK)',\n",
    "    'Temperature (F)': 'Temperature Fahrenheit (F)',\n",
    "    'Pain Score': 'Pain Level',\n",
    "    'LPM O2': 'O2 Flow (L/min)',\n",
    "    'O2 L/%': 'Inspired O2 Fraction',\n",
    "    'ionized calcium': 'Ionized Calcium',\n",
    "    'albumin': 'Albumin',\n",
    "    'GCS Total': 'GCS',\n",
    "    'total bilirubin': 'Total Bilirubin',\n",
    "    'LDH': 'LDH',\n",
    "    'ethanol': 'ETOH',\n",
    "    'Invasive BP Systolic': 'Arterial Blood Pressure systolic (mmHg)',\n",
    "    'Invasive BP Diastolic': 'Arterial Blood Pressure diastolic (mmHg)',\n",
    "    'Invasive BP Mean': 'Arterial Blood Pressure mean (mmHg)',\n",
    "    'serum osmolality':\t'Serum Osmolality',\n",
    "    'troponin - I':\t'Troponin-T',\n",
    "    'uric acid': 'Uric Acid',\n",
    "    'ammonia': 'Ammonia',\n",
    "    'CRP': 'C Reactive Protein (CRP)',\n",
    "    'fibrinogen': 'Fibrinogen',\n",
    "    'PA Systolic': 'Pulmonary Artery Pressure systolic (mmHg)',\n",
    "    'PA Diastolic': 'Pulmonary Artery Pressure diastolic (mmHg)',\n",
    "    'PA Mean': 'Pulmonary Artery Pressure mean (mmHg)',\n",
    "    'Bedside Glucose': 'Glucose finger stick (range 70-100)',\n",
    "    'reticulocyte count': 'Reticulocyte Count Automated',\n",
    "    '-basos': 'Differential-Basos',\n",
    "    '-eos': 'Differential-Eos',\n",
    "    '-lymphs': 'Differential-Lymphs',\n",
    "    '-monos': 'Differential-Monos',\n",
    "    '-polys': 'Differential-Neuts',\n",
    "    'haptoglobin': 'Haptoglobin',\n",
    "    'direct bilirubin': 'Bilirubin Direct',\n",
    "    'free T4': 'Thyroxine (T4) Free',\n",
    "    'ESR': 'Sedimentation Rate',\n",
    "    'CPK-MB INDEX': 'CK-MB',\n",
    "    'amylase': 'Amylase',\n",
    "    'PEEP': 'PEEP set (cmH2O)',\n",
    "    'CVP': 'Central Venous Pressure (mmHg)',\n",
    "    'unitdischargestatus': 'hospital_expire_flag',\n",
    "    'LOS': 'los'\n",
    "}\n",
    "\n",
    "# Replace the DataFrame and column names mapping\n",
    "eicu_temp.rename(columns=column_eicu_mapping, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "column_mimic_mapping = {\n",
    "    'Temperature Fahrenheit (°F)': 'Temperature Fahrenheit (F)',\n",
    "}\n",
    "\n",
    "# Replace the DataFrame and column names mapping\n",
    "mimic_temp.rename(columns=column_mimic_mapping, inplace=True)\n",
    "\n",
    "# Remove \"-\" from the 'subject_id' column in eicu\n",
    "eicu_temp['subject_id'] = eicu_temp['subject_id'].str.replace('-', '')\n",
    "\n",
    "# Convert 'subject_id' in eicu to int64\n",
    "eicu_temp['subject_id'] = eicu_temp['subject_id'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca93eff-e225-4e99-a7a8-10133e02b8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate columns\n",
    "mimic_temp = mimic_temp.loc[:, ~mimic_temp.columns.duplicated()]\n",
    "\n",
    "# Remove duplicate columns\n",
    "eicu_temp = eicu_temp.loc[:, ~eicu_temp.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3501679-8efe-452c-b6c7-28134e018449",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(mimic_temp)\n",
    "\n",
    "display(eicu_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c9b177-5a2e-47de-b486-a08a2eef7a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'Survive' with 0 and 'Death' with 1 in the 'hospital_expire_flag' column\n",
    "mimic_temp['hospital_expire_flag'] = mimic_temp['hospital_expire_flag'].replace({'Survive': 0, 'Death': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e75d7d-3528-4de0-aec1-90d21e2a7294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if mimic and eicu datasets have the same dtype and header names\n",
    "\n",
    "# Get the column names and dtypes of mimic_df\n",
    "mimic_info = mimic_temp.dtypes\n",
    "\n",
    "# Get the column names and dtypes of eicu_df\n",
    "eicu_info = eicu_temp.dtypes\n",
    "\n",
    "# Check if the column names are the same\n",
    "if all(mimic_info.index == eicu_info.index):\n",
    "    print(\"The column names are the same.\")\n",
    "else:\n",
    "    print(\"The column names are different.\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Check if the number of columns is the same\n",
    "if len(mimic_info) != len(eicu_info):\n",
    "    print(\"Number of columns is different between mimic_df and eicu_df.\")\n",
    "else:\n",
    "    # Iterate over the columns and compare the data type.\n",
    "    for column_name in mimic_info.index:\n",
    "        mimic_dtype = mimic_info[column_name]\n",
    "        eicu_dtype = eicu_info[column_name]\n",
    "        if mimic_dtype != eicu_dtype:\n",
    "            print(f\"Column '{column_name}' has different data types: mimic_df has '{mimic_dtype}' and eicu_df has '{eicu_dtype}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f832d9-7945-45cc-a629-2949d58ab207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the merged DataFrame to a CSV file\n",
    "mimic_temp.to_csv('CSV\\\\exports\\\\final\\\\mimic_mean_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa6918-6452-46ba-ae14-4ccfbc73c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the merged DataFrame to a CSV file\n",
    "eicu_temp.to_csv('CSV\\\\exports\\\\final\\\\eicu_mean_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
