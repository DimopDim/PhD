{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bed96430-8fa8-472d-8b11-77f38f7bbde1",
   "metadata": {},
   "source": [
    "# Sprint 1: Foundational Setup\n",
    "\n",
    "## Task 1 (CIR-8): Load and Validate all Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175f0647-a0e3-45de-8b58-b76fd775d953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c2be1f-1abc-468d-86a6-708f3725f1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"logs/CIR-8_data_logs.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493510c5-0c04-42a5-96aa-e19fa8dcffa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CSVs Directory \n",
    "data_path = \"../04_ANN/CSV/exports/split_set/without_multiple_rows\"\n",
    "all_files = os.listdir(data_path)\n",
    "\n",
    "logging.info(\"++++++++++++++++++++++++++++++++++++++++++\")\n",
    "logging.info(\"Start Loading Dataframes.\")\n",
    "\n",
    "# Load CSVs into a dictionary of dataframes\n",
    "dataframes = {}\n",
    "for file in all_files:\n",
    "    if file.endswith(\".csv\"):\n",
    "        var_name = file.replace(\".csv\", \"\").replace(\"-\", \"_\")\n",
    "        logging.info(f\"Loading... -> {file}\")\n",
    "        dataframes[var_name] = pd.read_csv(os.path.join(data_path, file)).astype('float32')\n",
    "\n",
    "# Log loaded datasets\n",
    "for var_name, df in dataframes.items():\n",
    "    globals()[var_name] = df\n",
    "    logging.info(f\"{var_name} loaded successfully with shape {df.shape}\")\n",
    "logging.info(\"Load Complete.\")\n",
    "logging.info(\"++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cceb6a9-3c44-4c6a-b426-a426744ff4a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logging.info(\"++++++++++++++++++++++++++++++++++++++++++\")\n",
    "logging.info(\"Check Datatypes...\")\n",
    "for name, df in dataframes.items():\n",
    "    logging.info(f\"{name} types:\\n{df.dtypes.value_counts()}\")\n",
    "logging.info(\"Check Complete.\")\n",
    "logging.info(\"++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f3d906-97b9-454f-9d49-32d2870f43b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logging.info(\"++++++++++++++++++++++++++++++++++++++++++\")\n",
    "logging.info(\"Calculate missing values...\")\n",
    "for name, df in dataframes.items():\n",
    "    missing_total = df.isnull().sum().sum()\n",
    "    missing_cols = df.columns[df.isnull().any()].tolist()\n",
    "    logging.info(f\"{name}: {missing_total} missing values across {len(missing_cols)} columns\")\n",
    "logging.info(\"Missing values calculation complete.\")\n",
    "logging.info(\"++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecba4ed-379f-4f2b-90f7-909708c44cf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logging.info(\"++++++++++++++++++++++++++++++++++++++++++\")\n",
    "logging.info(\"Calculate unique values.\")\n",
    "for name, df in dataframes.items():\n",
    "    if 'y_' in name:\n",
    "        unique_vals = df.nunique()\n",
    "        logging.info(f\"{name} unique target values: {unique_vals.to_dict()}\")\n",
    "\n",
    "logging.info(\"Unique values calculation complete.\")\n",
    "logging.info(\"++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c37687-5e03-43e7-adfa-cfd53a0f6d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = []\n",
    "for name, df in dataframes.items():\n",
    "    missing_values = df.isnull().sum().sum()\n",
    "    missing_cols = df.isnull().any().sum()\n",
    "    total_cells = df.shape[0] * df.shape[1]\n",
    "    summary.append({\n",
    "        'Dataset': name,\n",
    "        'Shape': df.shape,\n",
    "        'Total Missing Values': missing_values,\n",
    "        'Accross Missing Columns': missing_cols,\n",
    "        'Missing %': 100 * missing_values / total_cells\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "# Save to file\n",
    "summary_df.to_csv(\"CSV/exports/01_dataset_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc958b38-0239-4a55-87dc-25e87da0c8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = 7\n",
    "\n",
    "# Dictionary of datasets for iteration\n",
    "datasets = {\n",
    "    \"o1_X_train\": o1_X_train,\n",
    "    \"o2_X_train\": o2_X_train,\n",
    "    \"o3_X_train\": o3_X_train,\n",
    "    \"o4_X_train\": o4_X_train\n",
    "}\n",
    "\n",
    "# Loop through each dataset\n",
    "for name, df in datasets.items():\n",
    "    missing_percentage_per_row = df.isnull().mean(axis=1) * 100\n",
    "    missing_rows = (missing_percentage_per_row <= percent).sum()\n",
    "    total_rows, total_columns = df.shape\n",
    "    percent_between = (missing_rows * 100) / total_rows\n",
    "\n",
    "    print(f\"\\nDataset: {name}\")\n",
    "    print(f\"Total Rows: {total_rows}, Total Columns: {total_columns}\")\n",
    "    print(f\"Number of rows with missing values up to {percent}%: {missing_rows}\")\n",
    "    print(f\"The percentage between total and missing values sets is {percent_between:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827415dc-b41c-476b-89f1-3b52753d8542",
   "metadata": {},
   "source": [
    "## Task 2 (CIR-9): Analyze Missingness (per row/column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd81108-8d6e-4e89-8b79-1259af686fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingness_summary = []\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        continue\n",
    "    \n",
    "    total_cells = df.shape[0] * df.shape[1]\n",
    "    total_missing = df.isnull().sum().sum()\n",
    "    \n",
    "    col_missing = df.isnull().mean() * 100\n",
    "    row_missing = df.isnull().mean(axis=1) * 100\n",
    "    \n",
    "    summary = {\n",
    "        'Dataset': name,\n",
    "        'Shape': df.shape,\n",
    "        'Total Missing Cells': total_missing,\n",
    "        'Total Missing %': round(100 * total_missing / total_cells, 2),\n",
    "        'Columns with Missing (%)': (col_missing > 0).sum(),\n",
    "        'Max % Missing in Row': round(row_missing.max(), 2),\n",
    "        'Mean % Missing in Row': round(row_missing.mean(), 2),\n",
    "        'Min % Missing in Row': round(row_missing.min(), 2)\n",
    "    }\n",
    "    missingness_summary.append(summary)\n",
    "\n",
    "# Create DataFrame for summary\n",
    "missingness_df = pd.DataFrame(missingness_summary)\n",
    "\n",
    "# Sort by most missing\n",
    "missingness_df.sort_values(\"Total Missing %\", ascending=False, inplace=True)\n",
    "\n",
    "# Save to file\n",
    "missingness_df.to_csv(\"CSV/exports/02_missingness_summary.csv\", index=False)\n",
    "\n",
    "# Show top rows, I have leave out the y_ files which are labels\n",
    "display(missingness_df.head(16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4558adc-5cb9-4ac5-ad59-61f951801734",
   "metadata": {},
   "source": [
    "## Task 3 (CIR-10): Visualize Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196c2e23-1a91-4e17-8934-7eb06a927d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folder\n",
    "output_dir = \"figures/task3_missingness\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Functions for plotting\n",
    "def plot_missing_heatmap(df, title, max_rows=200, save_path=None, suffix_filter='(Min)'):\n",
    "    filtered_cols = [col for col in df.columns if col.endswith(suffix_filter)]\n",
    "    df_filtered = df[filtered_cols].head(max_rows)\n",
    "    \n",
    "    plt.figure(figsize=(16, 6))\n",
    "    sns.heatmap(df_filtered.isnull(), cbar=False, yticklabels=False)\n",
    "    plt.title(f\"Missing Data Heatmap ({suffix_filter}) Rows: {title}\")\n",
    "    plt.xlabel(\"Filtered Features\")\n",
    "    plt.ylabel(\"Rows\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def plot_column_missing_bar(df, title, save_path=None, top_n=60, suffix_filter='(Min)'):\n",
    "    filtered_cols = [col for col in df.columns if col.endswith(suffix_filter)]\n",
    "    missing_perc = df[filtered_cols].isnull().mean() * 100\n",
    "    missing_perc = missing_perc[missing_perc > 0].sort_values(ascending=False).head(top_n)\n",
    "\n",
    "    plt.figure(figsize=(10, 0.4 * len(missing_perc)))\n",
    "    missing_perc.plot(kind='barh')\n",
    "    plt.title(f\"Top {len(missing_perc)} ({suffix_filter}) Missing: {title}\")\n",
    "    plt.xlabel(\"Percentage Missing\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Filter only X datasets from the summary\n",
    "top_datasets = missingness_df[\n",
    "    (~missingness_df['Dataset'].str.startswith('y_')) &\n",
    "    (missingness_df['Dataset'].isin(dataframes.keys()))\n",
    "].head(16)['Dataset'].tolist()\n",
    "\n",
    "# Generate plots\n",
    "for dataset_name in top_datasets:\n",
    "    df = dataframes.get(dataset_name)\n",
    "    if df is not None:\n",
    "        print(f\"Generating plots for: {dataset_name}\")\n",
    "        heatmap_path = os.path.join(output_dir, f\"{dataset_name}_heatmap.png\")\n",
    "        barplot_path = os.path.join(output_dir, f\"{dataset_name}_barplot.png\")\n",
    "        \n",
    "        plot_missing_heatmap(df, dataset_name, save_path=heatmap_path)\n",
    "        plot_column_missing_bar(df, dataset_name, save_path=barplot_path)\n",
    "    else:\n",
    "        print(f\"Dataset not found in dataframes: {dataset_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
